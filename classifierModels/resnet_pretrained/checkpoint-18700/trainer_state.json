{
  "best_metric": 1.365744709968567,
  "best_model_checkpoint": "./resnet_pretrained\\checkpoint-15708",
  "epoch": 100.0,
  "eval_steps": 500,
  "global_step": 18700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 2.0052926540374756,
      "learning_rate": 6.249995590021662e-05,
      "loss": 1.5908,
      "step": 10
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.062933921813965,
      "learning_rate": 6.249982360099095e-05,
      "loss": 1.5523,
      "step": 20
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5822515487670898,
      "learning_rate": 6.249960310269639e-05,
      "loss": 1.5253,
      "step": 30
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2643836736679077,
      "learning_rate": 6.249929440595527e-05,
      "loss": 1.5277,
      "step": 40
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9379568099975586,
      "learning_rate": 6.249889751163886e-05,
      "loss": 1.4703,
      "step": 50
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1610867977142334,
      "learning_rate": 6.249841242086734e-05,
      "loss": 1.4248,
      "step": 60
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.581230640411377,
      "learning_rate": 6.24978391350098e-05,
      "loss": 1.4372,
      "step": 70
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3902597427368164,
      "learning_rate": 6.249717765568432e-05,
      "loss": 1.4102,
      "step": 80
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.179716944694519,
      "learning_rate": 6.249642798475783e-05,
      "loss": 1.3949,
      "step": 90
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2574124336242676,
      "learning_rate": 6.249559012434618e-05,
      "loss": 1.3869,
      "step": 100
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5459258556365967,
      "learning_rate": 6.249466407681414e-05,
      "loss": 1.4088,
      "step": 110
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1853243112564087,
      "learning_rate": 6.249364984477539e-05,
      "loss": 1.3959,
      "step": 120
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1101195812225342,
      "learning_rate": 6.249254743109248e-05,
      "loss": 1.3261,
      "step": 130
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1654784679412842,
      "learning_rate": 6.249135683887683e-05,
      "loss": 1.3437,
      "step": 140
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8464702367782593,
      "learning_rate": 6.249007807148875e-05,
      "loss": 1.3685,
      "step": 150
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.086714744567871,
      "learning_rate": 6.248871113253745e-05,
      "loss": 1.3954,
      "step": 160
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.122036099433899,
      "learning_rate": 6.248725602588092e-05,
      "loss": 1.3601,
      "step": 170
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2370027303695679,
      "learning_rate": 6.248571275562605e-05,
      "loss": 1.3167,
      "step": 180
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.21212121212121213,
      "eval_loss": 1.641159176826477,
      "eval_runtime": 1.312,
      "eval_samples_per_second": 25.153,
      "eval_steps_per_second": 2.287,
      "step": 187
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.232736349105835,
      "learning_rate": 6.248408132612854e-05,
      "loss": 1.2964,
      "step": 190
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.115671157836914,
      "learning_rate": 6.248236174199293e-05,
      "loss": 1.3447,
      "step": 200
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2013906240463257,
      "learning_rate": 6.248055400807253e-05,
      "loss": 1.2859,
      "step": 210
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.079064130783081,
      "learning_rate": 6.247865812946947e-05,
      "loss": 1.3189,
      "step": 220
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.6338940858840942,
      "learning_rate": 6.247667411153465e-05,
      "loss": 1.2289,
      "step": 230
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.6652097702026367,
      "learning_rate": 6.247460195986773e-05,
      "loss": 1.3337,
      "step": 240
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0914860963821411,
      "learning_rate": 6.247244168031715e-05,
      "loss": 1.2797,
      "step": 250
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9771454930305481,
      "learning_rate": 6.247019327898002e-05,
      "loss": 1.3077,
      "step": 260
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2525469064712524,
      "learning_rate": 6.246785676220221e-05,
      "loss": 1.2236,
      "step": 270
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8941634893417358,
      "learning_rate": 6.246543213657828e-05,
      "loss": 1.2746,
      "step": 280
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1334812641143799,
      "learning_rate": 6.246291940895145e-05,
      "loss": 1.2995,
      "step": 290
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.068611741065979,
      "learning_rate": 6.24603185864136e-05,
      "loss": 1.2216,
      "step": 300
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.6694972515106201,
      "learning_rate": 6.245762967630527e-05,
      "loss": 1.2989,
      "step": 310
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.5503795146942139,
      "learning_rate": 6.245485268621559e-05,
      "loss": 1.2639,
      "step": 320
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4898182153701782,
      "learning_rate": 6.245198762398231e-05,
      "loss": 1.2817,
      "step": 330
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.5465725660324097,
      "learning_rate": 6.244903449769174e-05,
      "loss": 1.2147,
      "step": 340
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.2531675100326538,
      "learning_rate": 6.244599331567874e-05,
      "loss": 1.1885,
      "step": 350
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.3355146646499634,
      "learning_rate": 6.244286408652669e-05,
      "loss": 1.2007,
      "step": 360
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.4864712953567505,
      "learning_rate": 6.243964681906751e-05,
      "loss": 1.2791,
      "step": 370
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.21212121212121213,
      "eval_loss": 1.695709228515625,
      "eval_runtime": 1.2723,
      "eval_samples_per_second": 25.938,
      "eval_steps_per_second": 2.358,
      "step": 374
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.4911391735076904,
      "learning_rate": 6.243634152238155e-05,
      "loss": 1.3229,
      "step": 380
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.230425477027893,
      "learning_rate": 6.243294820579763e-05,
      "loss": 1.2861,
      "step": 390
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.343379020690918,
      "learning_rate": 6.2429466878893e-05,
      "loss": 1.2418,
      "step": 400
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.7887375354766846,
      "learning_rate": 6.242589755149333e-05,
      "loss": 1.2094,
      "step": 410
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.9855335354804993,
      "learning_rate": 6.242224023367263e-05,
      "loss": 1.2269,
      "step": 420
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.8749347925186157,
      "learning_rate": 6.241849493575324e-05,
      "loss": 1.2685,
      "step": 430
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.1664984226226807,
      "learning_rate": 6.241466166830588e-05,
      "loss": 1.2654,
      "step": 440
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.4321980476379395,
      "learning_rate": 6.241074044214948e-05,
      "loss": 1.2216,
      "step": 450
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.04952871799469,
      "learning_rate": 6.240673126835125e-05,
      "loss": 1.2183,
      "step": 460
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.9882920384407043,
      "learning_rate": 6.240263415822665e-05,
      "loss": 1.2311,
      "step": 470
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.9715321063995361,
      "learning_rate": 6.239844912333929e-05,
      "loss": 1.2289,
      "step": 480
    },
    {
      "epoch": 2.62,
      "grad_norm": 1.205985188484192,
      "learning_rate": 6.239417617550096e-05,
      "loss": 1.1401,
      "step": 490
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.264358639717102,
      "learning_rate": 6.238981532677157e-05,
      "loss": 1.2013,
      "step": 500
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.5308908224105835,
      "learning_rate": 6.23853665894591e-05,
      "loss": 1.1779,
      "step": 510
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.1719449758529663,
      "learning_rate": 6.238082997611965e-05,
      "loss": 1.1371,
      "step": 520
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.974747359752655,
      "learning_rate": 6.237620549955724e-05,
      "loss": 1.1775,
      "step": 530
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.7949556112289429,
      "learning_rate": 6.237149317282397e-05,
      "loss": 1.1407,
      "step": 540
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.9081698656082153,
      "learning_rate": 6.236669300921983e-05,
      "loss": 1.1936,
      "step": 550
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.0872644186019897,
      "learning_rate": 6.236180502229273e-05,
      "loss": 1.2034,
      "step": 560
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.21212121212121213,
      "eval_loss": 1.7106926441192627,
      "eval_runtime": 1.3542,
      "eval_samples_per_second": 24.368,
      "eval_steps_per_second": 2.215,
      "step": 561
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.1925407648086548,
      "learning_rate": 6.235682922583846e-05,
      "loss": 1.2017,
      "step": 570
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.5231595039367676,
      "learning_rate": 6.235176563390065e-05,
      "loss": 1.1958,
      "step": 580
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.1486811637878418,
      "learning_rate": 6.234661426077071e-05,
      "loss": 1.2653,
      "step": 590
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.9325311183929443,
      "learning_rate": 6.234137512098778e-05,
      "loss": 1.1652,
      "step": 600
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.1330525875091553,
      "learning_rate": 6.233604822933876e-05,
      "loss": 1.2253,
      "step": 610
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.8337156176567078,
      "learning_rate": 6.233063360085818e-05,
      "loss": 1.1785,
      "step": 620
    },
    {
      "epoch": 3.37,
      "grad_norm": 1.2290414571762085,
      "learning_rate": 6.232513125082822e-05,
      "loss": 1.0746,
      "step": 630
    },
    {
      "epoch": 3.42,
      "grad_norm": 1.160011649131775,
      "learning_rate": 6.231954119477865e-05,
      "loss": 1.2301,
      "step": 640
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.775794506072998,
      "learning_rate": 6.231386344848675e-05,
      "loss": 1.1907,
      "step": 650
    },
    {
      "epoch": 3.53,
      "grad_norm": 1.4087872505187988,
      "learning_rate": 6.230809802797731e-05,
      "loss": 1.2758,
      "step": 660
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.9198004007339478,
      "learning_rate": 6.230224494952257e-05,
      "loss": 1.1334,
      "step": 670
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.3636187314987183,
      "learning_rate": 6.22963042296422e-05,
      "loss": 1.1044,
      "step": 680
    },
    {
      "epoch": 3.69,
      "grad_norm": 1.3507426977157593,
      "learning_rate": 6.229027588510318e-05,
      "loss": 1.178,
      "step": 690
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.1203862428665161,
      "learning_rate": 6.228415993291984e-05,
      "loss": 1.1729,
      "step": 700
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.9894842505455017,
      "learning_rate": 6.227795639035375e-05,
      "loss": 1.1219,
      "step": 710
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.9402174353599548,
      "learning_rate": 6.227166527491373e-05,
      "loss": 1.1624,
      "step": 720
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.8367493152618408,
      "learning_rate": 6.22652866043557e-05,
      "loss": 1.1835,
      "step": 730
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.577548861503601,
      "learning_rate": 6.225882039668274e-05,
      "loss": 1.1787,
      "step": 740
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.24242424242424243,
      "eval_loss": 1.681297779083252,
      "eval_runtime": 1.2233,
      "eval_samples_per_second": 26.977,
      "eval_steps_per_second": 2.452,
      "step": 748
    },
    {
      "epoch": 4.01,
      "grad_norm": 1.098828673362732,
      "learning_rate": 6.2252266670145e-05,
      "loss": 1.1227,
      "step": 750
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.251626968383789,
      "learning_rate": 6.224562544323962e-05,
      "loss": 1.2196,
      "step": 760
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.9416984915733337,
      "learning_rate": 6.223889673471071e-05,
      "loss": 1.0676,
      "step": 770
    },
    {
      "epoch": 4.17,
      "grad_norm": 0.9439180493354797,
      "learning_rate": 6.223208056354928e-05,
      "loss": 1.1769,
      "step": 780
    },
    {
      "epoch": 4.22,
      "grad_norm": 1.1572061777114868,
      "learning_rate": 6.222517694899319e-05,
      "loss": 1.1139,
      "step": 790
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.7759181261062622,
      "learning_rate": 6.22181859105271e-05,
      "loss": 1.1085,
      "step": 800
    },
    {
      "epoch": 4.33,
      "grad_norm": 1.5479985475540161,
      "learning_rate": 6.221110746788246e-05,
      "loss": 1.1218,
      "step": 810
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.8068081140518188,
      "learning_rate": 6.220394164103731e-05,
      "loss": 1.1938,
      "step": 820
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.2225768566131592,
      "learning_rate": 6.219668845021643e-05,
      "loss": 1.1048,
      "step": 830
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.9584769010543823,
      "learning_rate": 6.21893479158911e-05,
      "loss": 1.1294,
      "step": 840
    },
    {
      "epoch": 4.55,
      "grad_norm": 1.4713521003723145,
      "learning_rate": 6.218192005877916e-05,
      "loss": 1.2218,
      "step": 850
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.825203776359558,
      "learning_rate": 6.217440489984486e-05,
      "loss": 1.1439,
      "step": 860
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.8537580966949463,
      "learning_rate": 6.216680246029891e-05,
      "loss": 1.0571,
      "step": 870
    },
    {
      "epoch": 4.71,
      "grad_norm": 1.1299959421157837,
      "learning_rate": 6.215911276159832e-05,
      "loss": 1.203,
      "step": 880
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.5112755298614502,
      "learning_rate": 6.215133582544639e-05,
      "loss": 1.1907,
      "step": 890
    },
    {
      "epoch": 4.81,
      "grad_norm": 1.607550024986267,
      "learning_rate": 6.214347167379263e-05,
      "loss": 1.208,
      "step": 900
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.0085384845733643,
      "learning_rate": 6.213552032883271e-05,
      "loss": 1.1755,
      "step": 910
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.5090059041976929,
      "learning_rate": 6.21274818130084e-05,
      "loss": 1.0883,
      "step": 920
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.9835525751113892,
      "learning_rate": 6.211935614900754e-05,
      "loss": 1.1498,
      "step": 930
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.3333333333333333,
      "eval_loss": 1.6521172523498535,
      "eval_runtime": 1.1307,
      "eval_samples_per_second": 29.185,
      "eval_steps_per_second": 2.653,
      "step": 935
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.0585260391235352,
      "learning_rate": 6.211114335976381e-05,
      "loss": 1.1166,
      "step": 940
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.7182326316833496,
      "learning_rate": 6.210284346845693e-05,
      "loss": 1.1711,
      "step": 950
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.1989320516586304,
      "learning_rate": 6.209445649851238e-05,
      "loss": 1.0949,
      "step": 960
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.8658525943756104,
      "learning_rate": 6.208598247360142e-05,
      "loss": 1.1387,
      "step": 970
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.1961669921875,
      "learning_rate": 6.207742141764104e-05,
      "loss": 1.1331,
      "step": 980
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.7824951410293579,
      "learning_rate": 6.206877335479383e-05,
      "loss": 1.1583,
      "step": 990
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.8305114507675171,
      "learning_rate": 6.206003830946797e-05,
      "loss": 1.0672,
      "step": 1000
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.1560842990875244,
      "learning_rate": 6.205121630631713e-05,
      "loss": 1.1914,
      "step": 1010
    },
    {
      "epoch": 5.45,
      "grad_norm": 1.0500112771987915,
      "learning_rate": 6.204230737024041e-05,
      "loss": 1.1341,
      "step": 1020
    },
    {
      "epoch": 5.51,
      "grad_norm": 1.4855127334594727,
      "learning_rate": 6.203331152638227e-05,
      "loss": 1.0359,
      "step": 1030
    },
    {
      "epoch": 5.56,
      "grad_norm": 1.1412464380264282,
      "learning_rate": 6.202422880013243e-05,
      "loss": 1.1582,
      "step": 1040
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.6135625839233398,
      "learning_rate": 6.201505921712588e-05,
      "loss": 1.1559,
      "step": 1050
    },
    {
      "epoch": 5.67,
      "grad_norm": 1.4331034421920776,
      "learning_rate": 6.200580280324273e-05,
      "loss": 1.1376,
      "step": 1060
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.9785715341567993,
      "learning_rate": 6.199645958460813e-05,
      "loss": 1.1018,
      "step": 1070
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.033153772354126,
      "learning_rate": 6.198702958759227e-05,
      "loss": 1.0752,
      "step": 1080
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.8546909689903259,
      "learning_rate": 6.197751283881022e-05,
      "loss": 1.0594,
      "step": 1090
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.3077850341796875,
      "learning_rate": 6.196790936512194e-05,
      "loss": 1.1168,
      "step": 1100
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.30109441280365,
      "learning_rate": 6.195821919363212e-05,
      "loss": 1.1416,
      "step": 1110
    },
    {
      "epoch": 5.99,
      "grad_norm": 1.561470866203308,
      "learning_rate": 6.19484423516902e-05,
      "loss": 1.0828,
      "step": 1120
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.2727272727272727,
      "eval_loss": 1.6797469854354858,
      "eval_runtime": 1.3944,
      "eval_samples_per_second": 23.666,
      "eval_steps_per_second": 2.151,
      "step": 1122
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.7296724319458008,
      "learning_rate": 6.193857886689016e-05,
      "loss": 1.157,
      "step": 1130
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.8531715273857117,
      "learning_rate": 6.19286287670706e-05,
      "loss": 1.0824,
      "step": 1140
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.9110846519470215,
      "learning_rate": 6.191859208031453e-05,
      "loss": 1.0744,
      "step": 1150
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.2733683586120605,
      "learning_rate": 6.190846883494936e-05,
      "loss": 1.0098,
      "step": 1160
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.295547366142273,
      "learning_rate": 6.189825905954679e-05,
      "loss": 1.1697,
      "step": 1170
    },
    {
      "epoch": 6.31,
      "grad_norm": 1.6942133903503418,
      "learning_rate": 6.188796278292273e-05,
      "loss": 1.2905,
      "step": 1180
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.9604594111442566,
      "learning_rate": 6.187758003413729e-05,
      "loss": 1.1194,
      "step": 1190
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.3628507852554321,
      "learning_rate": 6.186711084249458e-05,
      "loss": 1.0346,
      "step": 1200
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.8541753888130188,
      "learning_rate": 6.185655523754268e-05,
      "loss": 1.0596,
      "step": 1210
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.468558430671692,
      "learning_rate": 6.184591324907362e-05,
      "loss": 1.0869,
      "step": 1220
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.2052544355392456,
      "learning_rate": 6.183518490712316e-05,
      "loss": 1.1526,
      "step": 1230
    },
    {
      "epoch": 6.63,
      "grad_norm": 1.0075918436050415,
      "learning_rate": 6.182437024197085e-05,
      "loss": 1.0543,
      "step": 1240
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.2610619068145752,
      "learning_rate": 6.181346928413985e-05,
      "loss": 1.1529,
      "step": 1250
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.7998071908950806,
      "learning_rate": 6.180248206439687e-05,
      "loss": 1.1538,
      "step": 1260
    },
    {
      "epoch": 6.79,
      "grad_norm": 1.3710436820983887,
      "learning_rate": 6.179140861375208e-05,
      "loss": 1.1101,
      "step": 1270
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.9242292046546936,
      "learning_rate": 6.178024896345903e-05,
      "loss": 1.032,
      "step": 1280
    },
    {
      "epoch": 6.9,
      "grad_norm": 1.3946539163589478,
      "learning_rate": 6.176900314501459e-05,
      "loss": 1.1449,
      "step": 1290
    },
    {
      "epoch": 6.95,
      "grad_norm": 1.2564913034439087,
      "learning_rate": 6.175767119015876e-05,
      "loss": 1.0781,
      "step": 1300
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.30303030303030304,
      "eval_loss": 1.6409409046173096,
      "eval_runtime": 1.1878,
      "eval_samples_per_second": 27.783,
      "eval_steps_per_second": 2.526,
      "step": 1309
    },
    {
      "epoch": 7.01,
      "grad_norm": 1.1621081829071045,
      "learning_rate": 6.174625313087473e-05,
      "loss": 1.0823,
      "step": 1310
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.0531953573226929,
      "learning_rate": 6.173474899938865e-05,
      "loss": 1.052,
      "step": 1320
    },
    {
      "epoch": 7.11,
      "grad_norm": 0.916122317314148,
      "learning_rate": 6.172315882816963e-05,
      "loss": 1.0986,
      "step": 1330
    },
    {
      "epoch": 7.17,
      "grad_norm": 0.9480997323989868,
      "learning_rate": 6.171148264992959e-05,
      "loss": 1.067,
      "step": 1340
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.8952083587646484,
      "learning_rate": 6.169972049762325e-05,
      "loss": 1.0778,
      "step": 1350
    },
    {
      "epoch": 7.27,
      "grad_norm": 0.9355630278587341,
      "learning_rate": 6.168787240444793e-05,
      "loss": 1.0302,
      "step": 1360
    },
    {
      "epoch": 7.33,
      "grad_norm": 2.086176872253418,
      "learning_rate": 6.16759384038435e-05,
      "loss": 1.1081,
      "step": 1370
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.045988917350769,
      "learning_rate": 6.166391852949236e-05,
      "loss": 1.102,
      "step": 1380
    },
    {
      "epoch": 7.43,
      "grad_norm": 1.0754213333129883,
      "learning_rate": 6.165181281531918e-05,
      "loss": 1.1679,
      "step": 1390
    },
    {
      "epoch": 7.49,
      "grad_norm": 1.3677705526351929,
      "learning_rate": 6.163962129549103e-05,
      "loss": 0.9924,
      "step": 1400
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.9308065176010132,
      "learning_rate": 6.162734400441703e-05,
      "loss": 1.0601,
      "step": 1410
    },
    {
      "epoch": 7.59,
      "grad_norm": 1.1657780408859253,
      "learning_rate": 6.161498097674846e-05,
      "loss": 1.0711,
      "step": 1420
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.8938654065132141,
      "learning_rate": 6.160253224737856e-05,
      "loss": 1.1555,
      "step": 1430
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.8441882133483887,
      "learning_rate": 6.158999785144243e-05,
      "loss": 1.0179,
      "step": 1440
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.7546092867851257,
      "learning_rate": 6.157737782431701e-05,
      "loss": 1.0963,
      "step": 1450
    },
    {
      "epoch": 7.81,
      "grad_norm": 0.7920321226119995,
      "learning_rate": 6.156467220162087e-05,
      "loss": 1.0589,
      "step": 1460
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.417655110359192,
      "learning_rate": 6.155188101921417e-05,
      "loss": 1.1085,
      "step": 1470
    },
    {
      "epoch": 7.91,
      "grad_norm": 1.7144948244094849,
      "learning_rate": 6.153900431319858e-05,
      "loss": 1.1515,
      "step": 1480
    },
    {
      "epoch": 7.97,
      "grad_norm": 0.7725760340690613,
      "learning_rate": 6.152604211991715e-05,
      "loss": 1.0291,
      "step": 1490
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.6304222345352173,
      "eval_runtime": 1.2579,
      "eval_samples_per_second": 26.235,
      "eval_steps_per_second": 2.385,
      "step": 1496
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.3403220176696777,
      "learning_rate": 6.151299447595419e-05,
      "loss": 1.1167,
      "step": 1500
    },
    {
      "epoch": 8.07,
      "grad_norm": 1.0039482116699219,
      "learning_rate": 6.149986141813516e-05,
      "loss": 1.0957,
      "step": 1510
    },
    {
      "epoch": 8.13,
      "grad_norm": 1.7657798528671265,
      "learning_rate": 6.148664298352664e-05,
      "loss": 1.1449,
      "step": 1520
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.81331467628479,
      "learning_rate": 6.147333920943616e-05,
      "loss": 1.1015,
      "step": 1530
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.2491381168365479,
      "learning_rate": 6.145995013341212e-05,
      "loss": 1.1749,
      "step": 1540
    },
    {
      "epoch": 8.29,
      "grad_norm": 1.1974366903305054,
      "learning_rate": 6.144647579324362e-05,
      "loss": 1.0468,
      "step": 1550
    },
    {
      "epoch": 8.34,
      "grad_norm": 0.9605641961097717,
      "learning_rate": 6.14329162269605e-05,
      "loss": 1.0277,
      "step": 1560
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.241775631904602,
      "learning_rate": 6.141927147283307e-05,
      "loss": 1.0718,
      "step": 1570
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.8093850612640381,
      "learning_rate": 6.140554156937208e-05,
      "loss": 1.0182,
      "step": 1580
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.8055657148361206,
      "learning_rate": 6.139172655532865e-05,
      "loss": 1.0024,
      "step": 1590
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.5881825685501099,
      "learning_rate": 6.137782646969405e-05,
      "loss": 0.9487,
      "step": 1600
    },
    {
      "epoch": 8.61,
      "grad_norm": 1.0324654579162598,
      "learning_rate": 6.136384135169972e-05,
      "loss": 1.1144,
      "step": 1610
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.7203543186187744,
      "learning_rate": 6.134977124081704e-05,
      "loss": 1.0716,
      "step": 1620
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.0728001594543457,
      "learning_rate": 6.133561617675733e-05,
      "loss": 0.995,
      "step": 1630
    },
    {
      "epoch": 8.77,
      "grad_norm": 1.0875564813613892,
      "learning_rate": 6.13213761994716e-05,
      "loss": 1.1513,
      "step": 1640
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.8991859555244446,
      "learning_rate": 6.13070513491506e-05,
      "loss": 1.0505,
      "step": 1650
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.0350563526153564,
      "learning_rate": 6.129264166622457e-05,
      "loss": 1.0003,
      "step": 1660
    },
    {
      "epoch": 8.93,
      "grad_norm": 0.8610043525695801,
      "learning_rate": 6.127814719136322e-05,
      "loss": 1.0871,
      "step": 1670
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.0006284713745117,
      "learning_rate": 6.126356796547551e-05,
      "loss": 1.0096,
      "step": 1680
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.659263253211975,
      "eval_runtime": 1.1801,
      "eval_samples_per_second": 27.965,
      "eval_steps_per_second": 2.542,
      "step": 1683
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.3595631122589111,
      "learning_rate": 6.12489040297097e-05,
      "loss": 1.0233,
      "step": 1690
    },
    {
      "epoch": 9.09,
      "grad_norm": 0.9640988111495972,
      "learning_rate": 6.123415542545304e-05,
      "loss": 1.0889,
      "step": 1700
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.383855938911438,
      "learning_rate": 6.121932219433181e-05,
      "loss": 1.1331,
      "step": 1710
    },
    {
      "epoch": 9.2,
      "grad_norm": 1.1474223136901855,
      "learning_rate": 6.120440437821111e-05,
      "loss": 1.0135,
      "step": 1720
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.9308556914329529,
      "learning_rate": 6.118940201919478e-05,
      "loss": 1.0432,
      "step": 1730
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.7744925022125244,
      "learning_rate": 6.117431515962524e-05,
      "loss": 1.0246,
      "step": 1740
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.1592639684677124,
      "learning_rate": 6.115914384208347e-05,
      "loss": 1.1821,
      "step": 1750
    },
    {
      "epoch": 9.41,
      "grad_norm": 1.2475773096084595,
      "learning_rate": 6.114388810938877e-05,
      "loss": 0.9815,
      "step": 1760
    },
    {
      "epoch": 9.47,
      "grad_norm": 1.129069447517395,
      "learning_rate": 6.112854800459872e-05,
      "loss": 1.0629,
      "step": 1770
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.9685847759246826,
      "learning_rate": 6.111312357100901e-05,
      "loss": 1.0148,
      "step": 1780
    },
    {
      "epoch": 9.57,
      "grad_norm": 0.9212011098861694,
      "learning_rate": 6.109761485215335e-05,
      "loss": 1.1074,
      "step": 1790
    },
    {
      "epoch": 9.63,
      "grad_norm": 1.3802639245986938,
      "learning_rate": 6.108202189180332e-05,
      "loss": 1.0045,
      "step": 1800
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.1319383382797241,
      "learning_rate": 6.10663447339683e-05,
      "loss": 1.0088,
      "step": 1810
    },
    {
      "epoch": 9.73,
      "grad_norm": 0.9136784076690674,
      "learning_rate": 6.105058342289526e-05,
      "loss": 1.1072,
      "step": 1820
    },
    {
      "epoch": 9.79,
      "grad_norm": 0.8087581992149353,
      "learning_rate": 6.103473800306873e-05,
      "loss": 1.069,
      "step": 1830
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.4578654766082764,
      "learning_rate": 6.101880851921058e-05,
      "loss": 1.0237,
      "step": 1840
    },
    {
      "epoch": 9.89,
      "grad_norm": 0.9455026984214783,
      "learning_rate": 6.100279501627997e-05,
      "loss": 1.0564,
      "step": 1850
    },
    {
      "epoch": 9.95,
      "grad_norm": 1.0071755647659302,
      "learning_rate": 6.09866975394732e-05,
      "loss": 1.0003,
      "step": 1860
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.7454018592834473,
      "learning_rate": 6.097051613422355e-05,
      "loss": 1.0486,
      "step": 1870
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.6413871049880981,
      "eval_runtime": 1.2519,
      "eval_samples_per_second": 26.361,
      "eval_steps_per_second": 2.396,
      "step": 1870
    },
    {
      "epoch": 10.05,
      "grad_norm": 0.9226913452148438,
      "learning_rate": 6.095425084620121e-05,
      "loss": 1.0104,
      "step": 1880
    },
    {
      "epoch": 10.11,
      "grad_norm": 0.9692054986953735,
      "learning_rate": 6.0937901721313086e-05,
      "loss": 1.0287,
      "step": 1890
    },
    {
      "epoch": 10.16,
      "grad_norm": 0.8821343183517456,
      "learning_rate": 6.0921468805702735e-05,
      "loss": 0.9903,
      "step": 1900
    },
    {
      "epoch": 10.21,
      "grad_norm": 1.1308180093765259,
      "learning_rate": 6.0904952145750175e-05,
      "loss": 1.0793,
      "step": 1910
    },
    {
      "epoch": 10.27,
      "grad_norm": 0.9086804389953613,
      "learning_rate": 6.088835178807182e-05,
      "loss": 1.1135,
      "step": 1920
    },
    {
      "epoch": 10.32,
      "grad_norm": 1.3180919885635376,
      "learning_rate": 6.087166777952027e-05,
      "loss": 1.0447,
      "step": 1930
    },
    {
      "epoch": 10.37,
      "grad_norm": 1.01375412940979,
      "learning_rate": 6.085490016718426e-05,
      "loss": 1.0083,
      "step": 1940
    },
    {
      "epoch": 10.43,
      "grad_norm": 1.2095006704330444,
      "learning_rate": 6.0838048998388445e-05,
      "loss": 1.0282,
      "step": 1950
    },
    {
      "epoch": 10.48,
      "grad_norm": 1.091147541999817,
      "learning_rate": 6.082111432069334e-05,
      "loss": 1.021,
      "step": 1960
    },
    {
      "epoch": 10.53,
      "grad_norm": 0.7905974388122559,
      "learning_rate": 6.080409618189514e-05,
      "loss": 1.06,
      "step": 1970
    },
    {
      "epoch": 10.59,
      "grad_norm": 1.0393966436386108,
      "learning_rate": 6.0786994630025616e-05,
      "loss": 1.1246,
      "step": 1980
    },
    {
      "epoch": 10.64,
      "grad_norm": 1.4098217487335205,
      "learning_rate": 6.076980971335193e-05,
      "loss": 1.0398,
      "step": 1990
    },
    {
      "epoch": 10.7,
      "grad_norm": 1.253040075302124,
      "learning_rate": 6.075254148037657e-05,
      "loss": 0.9865,
      "step": 2000
    },
    {
      "epoch": 10.75,
      "grad_norm": 0.7345857620239258,
      "learning_rate": 6.073518997983716e-05,
      "loss": 1.0092,
      "step": 2010
    },
    {
      "epoch": 10.8,
      "grad_norm": 1.120549201965332,
      "learning_rate": 6.071775526070632e-05,
      "loss": 1.0726,
      "step": 2020
    },
    {
      "epoch": 10.86,
      "grad_norm": 0.8904083371162415,
      "learning_rate": 6.070023737219157e-05,
      "loss": 1.1471,
      "step": 2030
    },
    {
      "epoch": 10.91,
      "grad_norm": 0.8770462870597839,
      "learning_rate": 6.068263636373515e-05,
      "loss": 0.9666,
      "step": 2040
    },
    {
      "epoch": 10.96,
      "grad_norm": 0.8671191930770874,
      "learning_rate": 6.0664952285013906e-05,
      "loss": 0.9507,
      "step": 2050
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.6163409948349,
      "eval_runtime": 1.2095,
      "eval_samples_per_second": 27.284,
      "eval_steps_per_second": 2.48,
      "step": 2057
    },
    {
      "epoch": 11.02,
      "grad_norm": 0.8654122948646545,
      "learning_rate": 6.064718518593913e-05,
      "loss": 1.0522,
      "step": 2060
    },
    {
      "epoch": 11.07,
      "grad_norm": 1.0942763090133667,
      "learning_rate": 6.062933511665644e-05,
      "loss": 1.0426,
      "step": 2070
    },
    {
      "epoch": 11.12,
      "grad_norm": 1.470097303390503,
      "learning_rate": 6.061140212754564e-05,
      "loss": 1.1923,
      "step": 2080
    },
    {
      "epoch": 11.18,
      "grad_norm": 0.7496054172515869,
      "learning_rate": 6.059338626922052e-05,
      "loss": 1.0698,
      "step": 2090
    },
    {
      "epoch": 11.23,
      "grad_norm": 1.1910609006881714,
      "learning_rate": 6.0575287592528814e-05,
      "loss": 1.0747,
      "step": 2100
    },
    {
      "epoch": 11.28,
      "grad_norm": 1.3729209899902344,
      "learning_rate": 6.055710614855195e-05,
      "loss": 1.0752,
      "step": 2110
    },
    {
      "epoch": 11.34,
      "grad_norm": 0.8975418210029602,
      "learning_rate": 6.0538841988605014e-05,
      "loss": 1.0177,
      "step": 2120
    },
    {
      "epoch": 11.39,
      "grad_norm": 1.4066100120544434,
      "learning_rate": 6.0520495164236494e-05,
      "loss": 0.9544,
      "step": 2130
    },
    {
      "epoch": 11.44,
      "grad_norm": 1.5366413593292236,
      "learning_rate": 6.050206572722823e-05,
      "loss": 1.0253,
      "step": 2140
    },
    {
      "epoch": 11.5,
      "grad_norm": 1.1782400608062744,
      "learning_rate": 6.04835537295952e-05,
      "loss": 1.0634,
      "step": 2150
    },
    {
      "epoch": 11.55,
      "grad_norm": 1.0203306674957275,
      "learning_rate": 6.046495922358541e-05,
      "loss": 0.9765,
      "step": 2160
    },
    {
      "epoch": 11.6,
      "grad_norm": 1.0157294273376465,
      "learning_rate": 6.044628226167974e-05,
      "loss": 1.0455,
      "step": 2170
    },
    {
      "epoch": 11.66,
      "grad_norm": 0.8430471420288086,
      "learning_rate": 6.042752289659178e-05,
      "loss": 0.9873,
      "step": 2180
    },
    {
      "epoch": 11.71,
      "grad_norm": 1.1216386556625366,
      "learning_rate": 6.040868118126771e-05,
      "loss": 1.0374,
      "step": 2190
    },
    {
      "epoch": 11.76,
      "grad_norm": 1.1120299100875854,
      "learning_rate": 6.0389757168886116e-05,
      "loss": 1.0608,
      "step": 2200
    },
    {
      "epoch": 11.82,
      "grad_norm": 1.3302961587905884,
      "learning_rate": 6.037075091285789e-05,
      "loss": 0.8996,
      "step": 2210
    },
    {
      "epoch": 11.87,
      "grad_norm": 1.6409673690795898,
      "learning_rate": 6.0351662466825996e-05,
      "loss": 1.0685,
      "step": 2220
    },
    {
      "epoch": 11.93,
      "grad_norm": 1.022127628326416,
      "learning_rate": 6.033249188466543e-05,
      "loss": 1.0091,
      "step": 2230
    },
    {
      "epoch": 11.98,
      "grad_norm": 1.3638091087341309,
      "learning_rate": 6.031323922048295e-05,
      "loss": 1.0282,
      "step": 2240
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.556739330291748,
      "eval_runtime": 1.2043,
      "eval_samples_per_second": 27.402,
      "eval_steps_per_second": 2.491,
      "step": 2244
    },
    {
      "epoch": 12.03,
      "grad_norm": 1.0884746313095093,
      "learning_rate": 6.029390452861702e-05,
      "loss": 1.0407,
      "step": 2250
    },
    {
      "epoch": 12.09,
      "grad_norm": 1.498975157737732,
      "learning_rate": 6.027448786363761e-05,
      "loss": 0.9849,
      "step": 2260
    },
    {
      "epoch": 12.14,
      "grad_norm": 0.984626293182373,
      "learning_rate": 6.025498928034605e-05,
      "loss": 1.1156,
      "step": 2270
    },
    {
      "epoch": 12.19,
      "grad_norm": 0.934543788433075,
      "learning_rate": 6.023540883377485e-05,
      "loss": 0.9667,
      "step": 2280
    },
    {
      "epoch": 12.25,
      "grad_norm": 0.9239253401756287,
      "learning_rate": 6.021574657918762e-05,
      "loss": 1.0496,
      "step": 2290
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.7866042852401733,
      "learning_rate": 6.01960025720788e-05,
      "loss": 0.985,
      "step": 2300
    },
    {
      "epoch": 12.35,
      "grad_norm": 0.9717099666595459,
      "learning_rate": 6.017617686817364e-05,
      "loss": 1.0537,
      "step": 2310
    },
    {
      "epoch": 12.41,
      "grad_norm": 1.0496538877487183,
      "learning_rate": 6.01562695234279e-05,
      "loss": 1.0788,
      "step": 2320
    },
    {
      "epoch": 12.46,
      "grad_norm": 1.0134536027908325,
      "learning_rate": 6.013628059402781e-05,
      "loss": 1.0844,
      "step": 2330
    },
    {
      "epoch": 12.51,
      "grad_norm": 1.4201215505599976,
      "learning_rate": 6.011621013638985e-05,
      "loss": 1.0368,
      "step": 2340
    },
    {
      "epoch": 12.57,
      "grad_norm": 1.169602870941162,
      "learning_rate": 6.009605820716059e-05,
      "loss": 1.0483,
      "step": 2350
    },
    {
      "epoch": 12.62,
      "grad_norm": 0.8666238188743591,
      "learning_rate": 6.0075824863216566e-05,
      "loss": 0.9959,
      "step": 2360
    },
    {
      "epoch": 12.67,
      "grad_norm": 0.960211992263794,
      "learning_rate": 6.005551016166408e-05,
      "loss": 1.088,
      "step": 2370
    },
    {
      "epoch": 12.73,
      "grad_norm": 1.1082956790924072,
      "learning_rate": 6.003511415983907e-05,
      "loss": 0.9644,
      "step": 2380
    },
    {
      "epoch": 12.78,
      "grad_norm": 0.7894381284713745,
      "learning_rate": 6.0014636915306925e-05,
      "loss": 0.9433,
      "step": 2390
    },
    {
      "epoch": 12.83,
      "grad_norm": 0.7877436876296997,
      "learning_rate": 5.999407848586233e-05,
      "loss": 1.0503,
      "step": 2400
    },
    {
      "epoch": 12.89,
      "grad_norm": 1.2964129447937012,
      "learning_rate": 5.9973438929529126e-05,
      "loss": 1.0057,
      "step": 2410
    },
    {
      "epoch": 12.94,
      "grad_norm": 1.8563449382781982,
      "learning_rate": 5.99527183045601e-05,
      "loss": 1.0438,
      "step": 2420
    },
    {
      "epoch": 12.99,
      "grad_norm": 0.8587952852249146,
      "learning_rate": 5.9931916669436855e-05,
      "loss": 1.0438,
      "step": 2430
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.5915850400924683,
      "eval_runtime": 1.2133,
      "eval_samples_per_second": 27.199,
      "eval_steps_per_second": 2.473,
      "step": 2431
    },
    {
      "epoch": 13.05,
      "grad_norm": 1.1802880764007568,
      "learning_rate": 5.991103408286965e-05,
      "loss": 1.0765,
      "step": 2440
    },
    {
      "epoch": 13.1,
      "grad_norm": 1.1363961696624756,
      "learning_rate": 5.9890070603797186e-05,
      "loss": 1.0237,
      "step": 2450
    },
    {
      "epoch": 13.16,
      "grad_norm": 1.0722339153289795,
      "learning_rate": 5.986902629138652e-05,
      "loss": 0.9378,
      "step": 2460
    },
    {
      "epoch": 13.21,
      "grad_norm": 1.2664152383804321,
      "learning_rate": 5.984790120503281e-05,
      "loss": 1.0283,
      "step": 2470
    },
    {
      "epoch": 13.26,
      "grad_norm": 1.2204331159591675,
      "learning_rate": 5.9826695404359225e-05,
      "loss": 1.0747,
      "step": 2480
    },
    {
      "epoch": 13.32,
      "grad_norm": 0.921057403087616,
      "learning_rate": 5.98054089492167e-05,
      "loss": 0.9699,
      "step": 2490
    },
    {
      "epoch": 13.37,
      "grad_norm": 1.1832259893417358,
      "learning_rate": 5.978404189968385e-05,
      "loss": 0.97,
      "step": 2500
    },
    {
      "epoch": 13.42,
      "grad_norm": 0.8819677233695984,
      "learning_rate": 5.976259431606673e-05,
      "loss": 1.0398,
      "step": 2510
    },
    {
      "epoch": 13.48,
      "grad_norm": 1.4544191360473633,
      "learning_rate": 5.974106625889871e-05,
      "loss": 1.0469,
      "step": 2520
    },
    {
      "epoch": 13.53,
      "grad_norm": 0.738027036190033,
      "learning_rate": 5.971945778894026e-05,
      "loss": 0.9687,
      "step": 2530
    },
    {
      "epoch": 13.58,
      "grad_norm": 0.8834028244018555,
      "learning_rate": 5.9697768967178854e-05,
      "loss": 0.9635,
      "step": 2540
    },
    {
      "epoch": 13.64,
      "grad_norm": 1.4542644023895264,
      "learning_rate": 5.96759998548287e-05,
      "loss": 1.0962,
      "step": 2550
    },
    {
      "epoch": 13.69,
      "grad_norm": 1.0733888149261475,
      "learning_rate": 5.965415051333065e-05,
      "loss": 1.0715,
      "step": 2560
    },
    {
      "epoch": 13.74,
      "grad_norm": 1.212406873703003,
      "learning_rate": 5.9632221004351986e-05,
      "loss": 1.08,
      "step": 2570
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.8377901315689087,
      "learning_rate": 5.961021138978624e-05,
      "loss": 1.0045,
      "step": 2580
    },
    {
      "epoch": 13.85,
      "grad_norm": 1.1891801357269287,
      "learning_rate": 5.958812173175304e-05,
      "loss": 0.9581,
      "step": 2590
    },
    {
      "epoch": 13.9,
      "grad_norm": 1.2912256717681885,
      "learning_rate": 5.956595209259794e-05,
      "loss": 1.0211,
      "step": 2600
    },
    {
      "epoch": 13.96,
      "grad_norm": 1.0796087980270386,
      "learning_rate": 5.954370253489223e-05,
      "loss": 0.9505,
      "step": 2610
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.5645827054977417,
      "eval_runtime": 1.3704,
      "eval_samples_per_second": 24.08,
      "eval_steps_per_second": 2.189,
      "step": 2618
    },
    {
      "epoch": 14.01,
      "grad_norm": 0.7626702785491943,
      "learning_rate": 5.9521373121432726e-05,
      "loss": 1.0046,
      "step": 2620
    },
    {
      "epoch": 14.06,
      "grad_norm": 0.8702317476272583,
      "learning_rate": 5.949896391524169e-05,
      "loss": 1.0539,
      "step": 2630
    },
    {
      "epoch": 14.12,
      "grad_norm": 1.349564552307129,
      "learning_rate": 5.947647497956653e-05,
      "loss": 1.0453,
      "step": 2640
    },
    {
      "epoch": 14.17,
      "grad_norm": 1.9622607231140137,
      "learning_rate": 5.945390637787971e-05,
      "loss": 1.0379,
      "step": 2650
    },
    {
      "epoch": 14.22,
      "grad_norm": 1.303244709968567,
      "learning_rate": 5.9431258173878544e-05,
      "loss": 1.0833,
      "step": 2660
    },
    {
      "epoch": 14.28,
      "grad_norm": 1.0407469272613525,
      "learning_rate": 5.9408530431485e-05,
      "loss": 0.9558,
      "step": 2670
    },
    {
      "epoch": 14.33,
      "grad_norm": 1.1852959394454956,
      "learning_rate": 5.938572321484556e-05,
      "loss": 0.9909,
      "step": 2680
    },
    {
      "epoch": 14.39,
      "grad_norm": 1.0929759740829468,
      "learning_rate": 5.9362836588330984e-05,
      "loss": 0.9544,
      "step": 2690
    },
    {
      "epoch": 14.44,
      "grad_norm": 1.1430131196975708,
      "learning_rate": 5.9339870616536175e-05,
      "loss": 1.0282,
      "step": 2700
    },
    {
      "epoch": 14.49,
      "grad_norm": 0.8593870997428894,
      "learning_rate": 5.931682536427996e-05,
      "loss": 1.0276,
      "step": 2710
    },
    {
      "epoch": 14.55,
      "grad_norm": 0.9199268817901611,
      "learning_rate": 5.929370089660495e-05,
      "loss": 0.9806,
      "step": 2720
    },
    {
      "epoch": 14.6,
      "grad_norm": 1.689336895942688,
      "learning_rate": 5.9270497278777326e-05,
      "loss": 1.0345,
      "step": 2730
    },
    {
      "epoch": 14.65,
      "grad_norm": 2.4409971237182617,
      "learning_rate": 5.9247214576286654e-05,
      "loss": 1.1098,
      "step": 2740
    },
    {
      "epoch": 14.71,
      "grad_norm": 0.7769487500190735,
      "learning_rate": 5.9223852854845704e-05,
      "loss": 1.0076,
      "step": 2750
    },
    {
      "epoch": 14.76,
      "grad_norm": 1.9340248107910156,
      "learning_rate": 5.920041218039028e-05,
      "loss": 1.0064,
      "step": 2760
    },
    {
      "epoch": 14.81,
      "grad_norm": 1.5659323930740356,
      "learning_rate": 5.917689261907901e-05,
      "loss": 0.9964,
      "step": 2770
    },
    {
      "epoch": 14.87,
      "grad_norm": 1.0273085832595825,
      "learning_rate": 5.9153294237293195e-05,
      "loss": 1.0577,
      "step": 2780
    },
    {
      "epoch": 14.92,
      "grad_norm": 1.0701388120651245,
      "learning_rate": 5.9129617101636564e-05,
      "loss": 1.0232,
      "step": 2790
    },
    {
      "epoch": 14.97,
      "grad_norm": 0.9076281785964966,
      "learning_rate": 5.9105861278935145e-05,
      "loss": 1.0094,
      "step": 2800
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.5774353742599487,
      "eval_runtime": 1.2503,
      "eval_samples_per_second": 26.394,
      "eval_steps_per_second": 2.399,
      "step": 2805
    },
    {
      "epoch": 15.03,
      "grad_norm": 1.1688965559005737,
      "learning_rate": 5.908202683623704e-05,
      "loss": 0.9722,
      "step": 2810
    },
    {
      "epoch": 15.08,
      "grad_norm": 0.944387674331665,
      "learning_rate": 5.905811384081224e-05,
      "loss": 0.9757,
      "step": 2820
    },
    {
      "epoch": 15.13,
      "grad_norm": 0.7908613085746765,
      "learning_rate": 5.903412236015247e-05,
      "loss": 1.0215,
      "step": 2830
    },
    {
      "epoch": 15.19,
      "grad_norm": 1.017225980758667,
      "learning_rate": 5.9010052461970944e-05,
      "loss": 1.1164,
      "step": 2840
    },
    {
      "epoch": 15.24,
      "grad_norm": 0.8720032572746277,
      "learning_rate": 5.89859042142022e-05,
      "loss": 0.9739,
      "step": 2850
    },
    {
      "epoch": 15.29,
      "grad_norm": 1.3409477472305298,
      "learning_rate": 5.896167768500193e-05,
      "loss": 0.9695,
      "step": 2860
    },
    {
      "epoch": 15.35,
      "grad_norm": 0.9116384387016296,
      "learning_rate": 5.893737294274676e-05,
      "loss": 0.9903,
      "step": 2870
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.9694006443023682,
      "learning_rate": 5.891299005603404e-05,
      "loss": 0.9735,
      "step": 2880
    },
    {
      "epoch": 15.45,
      "grad_norm": 0.8141915798187256,
      "learning_rate": 5.88885290936817e-05,
      "loss": 1.0473,
      "step": 2890
    },
    {
      "epoch": 15.51,
      "grad_norm": 1.3830217123031616,
      "learning_rate": 5.886399012472802e-05,
      "loss": 0.9874,
      "step": 2900
    },
    {
      "epoch": 15.56,
      "grad_norm": 1.129196047782898,
      "learning_rate": 5.8839373218431444e-05,
      "loss": 0.9679,
      "step": 2910
    },
    {
      "epoch": 15.61,
      "grad_norm": 1.366754412651062,
      "learning_rate": 5.88146784442704e-05,
      "loss": 1.0415,
      "step": 2920
    },
    {
      "epoch": 15.67,
      "grad_norm": 1.1562473773956299,
      "learning_rate": 5.878990587194305e-05,
      "loss": 1.0685,
      "step": 2930
    },
    {
      "epoch": 15.72,
      "grad_norm": 1.2788714170455933,
      "learning_rate": 5.876505557136718e-05,
      "loss": 1.0484,
      "step": 2940
    },
    {
      "epoch": 15.78,
      "grad_norm": 1.6327944993972778,
      "learning_rate": 5.874012761267993e-05,
      "loss": 1.0544,
      "step": 2950
    },
    {
      "epoch": 15.83,
      "grad_norm": 0.9764304757118225,
      "learning_rate": 5.871512206623762e-05,
      "loss": 0.9116,
      "step": 2960
    },
    {
      "epoch": 15.88,
      "grad_norm": 1.433944821357727,
      "learning_rate": 5.869003900261556e-05,
      "loss": 0.9891,
      "step": 2970
    },
    {
      "epoch": 15.94,
      "grad_norm": 1.316521167755127,
      "learning_rate": 5.866487849260785e-05,
      "loss": 1.0411,
      "step": 2980
    },
    {
      "epoch": 15.99,
      "grad_norm": 1.1827503442764282,
      "learning_rate": 5.863964060722714e-05,
      "loss": 0.861,
      "step": 2990
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.555235505104065,
      "eval_runtime": 1.1853,
      "eval_samples_per_second": 27.841,
      "eval_steps_per_second": 2.531,
      "step": 2992
    },
    {
      "epoch": 16.04,
      "grad_norm": 0.9463890790939331,
      "learning_rate": 5.861432541770452e-05,
      "loss": 0.9875,
      "step": 3000
    },
    {
      "epoch": 16.1,
      "grad_norm": 1.2110930681228638,
      "learning_rate": 5.8588932995489205e-05,
      "loss": 1.0956,
      "step": 3010
    },
    {
      "epoch": 16.15,
      "grad_norm": 1.1247398853302002,
      "learning_rate": 5.856346341224843e-05,
      "loss": 1.0151,
      "step": 3020
    },
    {
      "epoch": 16.2,
      "grad_norm": 0.7903183698654175,
      "learning_rate": 5.853791673986718e-05,
      "loss": 1.0061,
      "step": 3030
    },
    {
      "epoch": 16.26,
      "grad_norm": 1.0505646467208862,
      "learning_rate": 5.851229305044804e-05,
      "loss": 0.9483,
      "step": 3040
    },
    {
      "epoch": 16.31,
      "grad_norm": 1.0607824325561523,
      "learning_rate": 5.8486592416310956e-05,
      "loss": 0.8687,
      "step": 3050
    },
    {
      "epoch": 16.36,
      "grad_norm": 1.8155044317245483,
      "learning_rate": 5.846081490999304e-05,
      "loss": 1.0209,
      "step": 3060
    },
    {
      "epoch": 16.42,
      "grad_norm": 0.9640676379203796,
      "learning_rate": 5.8434960604248364e-05,
      "loss": 1.0131,
      "step": 3070
    },
    {
      "epoch": 16.47,
      "grad_norm": 0.9724032282829285,
      "learning_rate": 5.840902957204776e-05,
      "loss": 0.985,
      "step": 3080
    },
    {
      "epoch": 16.52,
      "grad_norm": 1.2584251165390015,
      "learning_rate": 5.838302188657862e-05,
      "loss": 0.9951,
      "step": 3090
    },
    {
      "epoch": 16.58,
      "grad_norm": 1.665282130241394,
      "learning_rate": 5.835693762124468e-05,
      "loss": 0.9607,
      "step": 3100
    },
    {
      "epoch": 16.63,
      "grad_norm": 0.957298755645752,
      "learning_rate": 5.83307768496658e-05,
      "loss": 1.0261,
      "step": 3110
    },
    {
      "epoch": 16.68,
      "grad_norm": 1.0657998323440552,
      "learning_rate": 5.8304539645677777e-05,
      "loss": 0.9468,
      "step": 3120
    },
    {
      "epoch": 16.74,
      "grad_norm": 1.1207679510116577,
      "learning_rate": 5.8278226083332136e-05,
      "loss": 0.9459,
      "step": 3130
    },
    {
      "epoch": 16.79,
      "grad_norm": 1.1433930397033691,
      "learning_rate": 5.8251836236895913e-05,
      "loss": 1.1018,
      "step": 3140
    },
    {
      "epoch": 16.84,
      "grad_norm": 0.7374584674835205,
      "learning_rate": 5.8225370180851446e-05,
      "loss": 1.038,
      "step": 3150
    },
    {
      "epoch": 16.9,
      "grad_norm": 1.5086162090301514,
      "learning_rate": 5.819882798989616e-05,
      "loss": 0.9964,
      "step": 3160
    },
    {
      "epoch": 16.95,
      "grad_norm": 0.7611446976661682,
      "learning_rate": 5.817220973894236e-05,
      "loss": 0.9865,
      "step": 3170
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.5531063079833984,
      "eval_runtime": 1.1973,
      "eval_samples_per_second": 27.563,
      "eval_steps_per_second": 2.506,
      "step": 3179
    },
    {
      "epoch": 17.01,
      "grad_norm": 1.5334727764129639,
      "learning_rate": 5.814551550311705e-05,
      "loss": 0.9965,
      "step": 3180
    },
    {
      "epoch": 17.06,
      "grad_norm": 0.803563117980957,
      "learning_rate": 5.811874535776164e-05,
      "loss": 0.9544,
      "step": 3190
    },
    {
      "epoch": 17.11,
      "grad_norm": 1.6280512809753418,
      "learning_rate": 5.8091899378431847e-05,
      "loss": 0.9451,
      "step": 3200
    },
    {
      "epoch": 17.17,
      "grad_norm": 1.3039013147354126,
      "learning_rate": 5.806497764089737e-05,
      "loss": 1.0692,
      "step": 3210
    },
    {
      "epoch": 17.22,
      "grad_norm": 1.5216233730316162,
      "learning_rate": 5.8037980221141764e-05,
      "loss": 1.0012,
      "step": 3220
    },
    {
      "epoch": 17.27,
      "grad_norm": 1.2413262128829956,
      "learning_rate": 5.8010907195362155e-05,
      "loss": 1.0247,
      "step": 3230
    },
    {
      "epoch": 17.33,
      "grad_norm": 1.6931750774383545,
      "learning_rate": 5.7983758639969086e-05,
      "loss": 1.0091,
      "step": 3240
    },
    {
      "epoch": 17.38,
      "grad_norm": 0.8734577298164368,
      "learning_rate": 5.7956534631586274e-05,
      "loss": 1.0099,
      "step": 3250
    },
    {
      "epoch": 17.43,
      "grad_norm": 1.1168947219848633,
      "learning_rate": 5.792923524705036e-05,
      "loss": 0.9635,
      "step": 3260
    },
    {
      "epoch": 17.49,
      "grad_norm": 1.3972443342208862,
      "learning_rate": 5.790186056341076e-05,
      "loss": 1.0533,
      "step": 3270
    },
    {
      "epoch": 17.54,
      "grad_norm": 0.7751558423042297,
      "learning_rate": 5.787441065792941e-05,
      "loss": 0.9881,
      "step": 3280
    },
    {
      "epoch": 17.59,
      "grad_norm": 0.8096771240234375,
      "learning_rate": 5.784688560808053e-05,
      "loss": 1.0056,
      "step": 3290
    },
    {
      "epoch": 17.65,
      "grad_norm": 0.9537692666053772,
      "learning_rate": 5.781928549155045e-05,
      "loss": 1.0595,
      "step": 3300
    },
    {
      "epoch": 17.7,
      "grad_norm": 1.5258909463882446,
      "learning_rate": 5.779161038623733e-05,
      "loss": 0.9665,
      "step": 3310
    },
    {
      "epoch": 17.75,
      "grad_norm": 0.7218195199966431,
      "learning_rate": 5.776386037025104e-05,
      "loss": 0.8978,
      "step": 3320
    },
    {
      "epoch": 17.81,
      "grad_norm": 1.0576934814453125,
      "learning_rate": 5.7736035521912815e-05,
      "loss": 1.0565,
      "step": 3330
    },
    {
      "epoch": 17.86,
      "grad_norm": 0.7265868782997131,
      "learning_rate": 5.770813591975513e-05,
      "loss": 0.9345,
      "step": 3340
    },
    {
      "epoch": 17.91,
      "grad_norm": 1.3245649337768555,
      "learning_rate": 5.768016164252144e-05,
      "loss": 1.043,
      "step": 3350
    },
    {
      "epoch": 17.97,
      "grad_norm": 0.9261439442634583,
      "learning_rate": 5.765211276916594e-05,
      "loss": 0.9802,
      "step": 3360
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.5407655239105225,
      "eval_runtime": 1.1588,
      "eval_samples_per_second": 28.478,
      "eval_steps_per_second": 2.589,
      "step": 3366
    },
    {
      "epoch": 18.02,
      "grad_norm": 1.384734869003296,
      "learning_rate": 5.762398937885341e-05,
      "loss": 1.0096,
      "step": 3370
    },
    {
      "epoch": 18.07,
      "grad_norm": 1.108248233795166,
      "learning_rate": 5.7595791550958886e-05,
      "loss": 1.0074,
      "step": 3380
    },
    {
      "epoch": 18.13,
      "grad_norm": 0.9194536209106445,
      "learning_rate": 5.756751936506755e-05,
      "loss": 0.9458,
      "step": 3390
    },
    {
      "epoch": 18.18,
      "grad_norm": 0.8934748768806458,
      "learning_rate": 5.7539172900974414e-05,
      "loss": 0.9821,
      "step": 3400
    },
    {
      "epoch": 18.24,
      "grad_norm": 0.8750630617141724,
      "learning_rate": 5.751075223868415e-05,
      "loss": 0.9668,
      "step": 3410
    },
    {
      "epoch": 18.29,
      "grad_norm": 1.1184829473495483,
      "learning_rate": 5.748225745841084e-05,
      "loss": 0.9705,
      "step": 3420
    },
    {
      "epoch": 18.34,
      "grad_norm": 0.8882964253425598,
      "learning_rate": 5.745368864057776e-05,
      "loss": 0.9688,
      "step": 3430
    },
    {
      "epoch": 18.4,
      "grad_norm": 0.9568749070167542,
      "learning_rate": 5.742504586581713e-05,
      "loss": 0.9285,
      "step": 3440
    },
    {
      "epoch": 18.45,
      "grad_norm": 1.0645840167999268,
      "learning_rate": 5.739632921496995e-05,
      "loss": 0.9856,
      "step": 3450
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.523555040359497,
      "learning_rate": 5.736753876908568e-05,
      "loss": 1.029,
      "step": 3460
    },
    {
      "epoch": 18.56,
      "grad_norm": 0.8208881616592407,
      "learning_rate": 5.733867460942207e-05,
      "loss": 0.969,
      "step": 3470
    },
    {
      "epoch": 18.61,
      "grad_norm": 1.3355834484100342,
      "learning_rate": 5.7309736817444924e-05,
      "loss": 1.0097,
      "step": 3480
    },
    {
      "epoch": 18.66,
      "grad_norm": 0.9081286787986755,
      "learning_rate": 5.728072547482788e-05,
      "loss": 1.0177,
      "step": 3490
    },
    {
      "epoch": 18.72,
      "grad_norm": 0.9765159487724304,
      "learning_rate": 5.725164066345214e-05,
      "loss": 1.0638,
      "step": 3500
    },
    {
      "epoch": 18.77,
      "grad_norm": 1.0717499256134033,
      "learning_rate": 5.722248246540626e-05,
      "loss": 1.0097,
      "step": 3510
    },
    {
      "epoch": 18.82,
      "grad_norm": 1.395092248916626,
      "learning_rate": 5.7193250962985954e-05,
      "loss": 1.0364,
      "step": 3520
    },
    {
      "epoch": 18.88,
      "grad_norm": 1.0932279825210571,
      "learning_rate": 5.716394623869381e-05,
      "loss": 0.9678,
      "step": 3530
    },
    {
      "epoch": 18.93,
      "grad_norm": 1.1672444343566895,
      "learning_rate": 5.713456837523906e-05,
      "loss": 1.0111,
      "step": 3540
    },
    {
      "epoch": 18.98,
      "grad_norm": 0.952109158039093,
      "learning_rate": 5.7105117455537385e-05,
      "loss": 0.9904,
      "step": 3550
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.5071613788604736,
      "eval_runtime": 1.2099,
      "eval_samples_per_second": 27.275,
      "eval_steps_per_second": 2.48,
      "step": 3553
    },
    {
      "epoch": 19.04,
      "grad_norm": 1.0293827056884766,
      "learning_rate": 5.707559356271065e-05,
      "loss": 0.932,
      "step": 3560
    },
    {
      "epoch": 19.09,
      "grad_norm": 0.8220043778419495,
      "learning_rate": 5.704599678008669e-05,
      "loss": 0.8198,
      "step": 3570
    },
    {
      "epoch": 19.14,
      "grad_norm": 0.8770788311958313,
      "learning_rate": 5.7016327191199045e-05,
      "loss": 1.018,
      "step": 3580
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.6821789145469666,
      "learning_rate": 5.698658487978675e-05,
      "loss": 1.0569,
      "step": 3590
    },
    {
      "epoch": 19.25,
      "grad_norm": 0.9270236492156982,
      "learning_rate": 5.69567699297941e-05,
      "loss": 1.0363,
      "step": 3600
    },
    {
      "epoch": 19.3,
      "grad_norm": 0.9778266549110413,
      "learning_rate": 5.692688242537039e-05,
      "loss": 1.0172,
      "step": 3610
    },
    {
      "epoch": 19.36,
      "grad_norm": 0.9843189716339111,
      "learning_rate": 5.689692245086971e-05,
      "loss": 1.0487,
      "step": 3620
    },
    {
      "epoch": 19.41,
      "grad_norm": 1.2915652990341187,
      "learning_rate": 5.686689009085066e-05,
      "loss": 0.9213,
      "step": 3630
    },
    {
      "epoch": 19.47,
      "grad_norm": 1.0578609704971313,
      "learning_rate": 5.683678543007617e-05,
      "loss": 0.9211,
      "step": 3640
    },
    {
      "epoch": 19.52,
      "grad_norm": 0.9123139381408691,
      "learning_rate": 5.68066085535132e-05,
      "loss": 0.9619,
      "step": 3650
    },
    {
      "epoch": 19.57,
      "grad_norm": 1.0170131921768188,
      "learning_rate": 5.6776359546332573e-05,
      "loss": 0.9902,
      "step": 3660
    },
    {
      "epoch": 19.63,
      "grad_norm": 1.0017545223236084,
      "learning_rate": 5.674603849390865e-05,
      "loss": 1.0388,
      "step": 3670
    },
    {
      "epoch": 19.68,
      "grad_norm": 1.1501137018203735,
      "learning_rate": 5.6715645481819153e-05,
      "loss": 1.0213,
      "step": 3680
    },
    {
      "epoch": 19.73,
      "grad_norm": 0.8732913136482239,
      "learning_rate": 5.668518059584489e-05,
      "loss": 1.0925,
      "step": 3690
    },
    {
      "epoch": 19.79,
      "grad_norm": 0.7725433707237244,
      "learning_rate": 5.665464392196955e-05,
      "loss": 0.9054,
      "step": 3700
    },
    {
      "epoch": 19.84,
      "grad_norm": 1.3976534605026245,
      "learning_rate": 5.662403554637941e-05,
      "loss": 0.9916,
      "step": 3710
    },
    {
      "epoch": 19.89,
      "grad_norm": 1.1035668849945068,
      "learning_rate": 5.659335555546312e-05,
      "loss": 0.8854,
      "step": 3720
    },
    {
      "epoch": 19.95,
      "grad_norm": 1.0208549499511719,
      "learning_rate": 5.6562604035811466e-05,
      "loss": 1.0436,
      "step": 3730
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.7789844274520874,
      "learning_rate": 5.653178107421711e-05,
      "loss": 1.0174,
      "step": 3740
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.5425658226013184,
      "eval_runtime": 1.1683,
      "eval_samples_per_second": 28.246,
      "eval_steps_per_second": 2.568,
      "step": 3740
    },
    {
      "epoch": 20.05,
      "grad_norm": 1.1887118816375732,
      "learning_rate": 5.650088675767435e-05,
      "loss": 0.9713,
      "step": 3750
    },
    {
      "epoch": 20.11,
      "grad_norm": 1.2065529823303223,
      "learning_rate": 5.646992117337887e-05,
      "loss": 0.9241,
      "step": 3760
    },
    {
      "epoch": 20.16,
      "grad_norm": 0.6987655758857727,
      "learning_rate": 5.6438884408727525e-05,
      "loss": 0.9981,
      "step": 3770
    },
    {
      "epoch": 20.21,
      "grad_norm": 0.7427438497543335,
      "learning_rate": 5.640777655131804e-05,
      "loss": 1.0442,
      "step": 3780
    },
    {
      "epoch": 20.27,
      "grad_norm": 0.7896525859832764,
      "learning_rate": 5.6376597688948786e-05,
      "loss": 0.9053,
      "step": 3790
    },
    {
      "epoch": 20.32,
      "grad_norm": 0.9269031882286072,
      "learning_rate": 5.634534790961857e-05,
      "loss": 0.9827,
      "step": 3800
    },
    {
      "epoch": 20.37,
      "grad_norm": 0.8161773681640625,
      "learning_rate": 5.631402730152634e-05,
      "loss": 1.0158,
      "step": 3810
    },
    {
      "epoch": 20.43,
      "grad_norm": 1.3086122274398804,
      "learning_rate": 5.628263595307092e-05,
      "loss": 0.9839,
      "step": 3820
    },
    {
      "epoch": 20.48,
      "grad_norm": 0.8361477255821228,
      "learning_rate": 5.625117395285084e-05,
      "loss": 1.0239,
      "step": 3830
    },
    {
      "epoch": 20.53,
      "grad_norm": 1.1107203960418701,
      "learning_rate": 5.621964138966401e-05,
      "loss": 0.9062,
      "step": 3840
    },
    {
      "epoch": 20.59,
      "grad_norm": 1.724586009979248,
      "learning_rate": 5.618803835250749e-05,
      "loss": 1.0337,
      "step": 3850
    },
    {
      "epoch": 20.64,
      "grad_norm": 1.07479989528656,
      "learning_rate": 5.6156364930577255e-05,
      "loss": 0.9837,
      "step": 3860
    },
    {
      "epoch": 20.7,
      "grad_norm": 0.9614300727844238,
      "learning_rate": 5.6124621213267946e-05,
      "loss": 0.9419,
      "step": 3870
    },
    {
      "epoch": 20.75,
      "grad_norm": 0.8604556918144226,
      "learning_rate": 5.6092807290172575e-05,
      "loss": 1.0187,
      "step": 3880
    },
    {
      "epoch": 20.8,
      "grad_norm": 0.8256429433822632,
      "learning_rate": 5.6060923251082324e-05,
      "loss": 0.9309,
      "step": 3890
    },
    {
      "epoch": 20.86,
      "grad_norm": 1.2736109495162964,
      "learning_rate": 5.602896918598626e-05,
      "loss": 0.9112,
      "step": 3900
    },
    {
      "epoch": 20.91,
      "grad_norm": 1.0060676336288452,
      "learning_rate": 5.5996945185071104e-05,
      "loss": 0.9611,
      "step": 3910
    },
    {
      "epoch": 20.96,
      "grad_norm": 0.89015793800354,
      "learning_rate": 5.5964851338720936e-05,
      "loss": 0.9774,
      "step": 3920
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.3333333333333333,
      "eval_loss": 1.5318901538848877,
      "eval_runtime": 1.2663,
      "eval_samples_per_second": 26.06,
      "eval_steps_per_second": 2.369,
      "step": 3927
    },
    {
      "epoch": 21.02,
      "grad_norm": 1.0609492063522339,
      "learning_rate": 5.5932687737516986e-05,
      "loss": 1.0288,
      "step": 3930
    },
    {
      "epoch": 21.07,
      "grad_norm": 1.1518796682357788,
      "learning_rate": 5.5900454472237374e-05,
      "loss": 0.9788,
      "step": 3940
    },
    {
      "epoch": 21.12,
      "grad_norm": 1.0148097276687622,
      "learning_rate": 5.586815163385679e-05,
      "loss": 0.9738,
      "step": 3950
    },
    {
      "epoch": 21.18,
      "grad_norm": 0.973421573638916,
      "learning_rate": 5.5835779313546356e-05,
      "loss": 0.9222,
      "step": 3960
    },
    {
      "epoch": 21.23,
      "grad_norm": 0.8531836271286011,
      "learning_rate": 5.580333760267323e-05,
      "loss": 0.996,
      "step": 3970
    },
    {
      "epoch": 21.28,
      "grad_norm": 1.593512773513794,
      "learning_rate": 5.5770826592800456e-05,
      "loss": 0.9817,
      "step": 3980
    },
    {
      "epoch": 21.34,
      "grad_norm": 1.2227098941802979,
      "learning_rate": 5.573824637568666e-05,
      "loss": 0.9269,
      "step": 3990
    },
    {
      "epoch": 21.39,
      "grad_norm": 0.869446337223053,
      "learning_rate": 5.570559704328578e-05,
      "loss": 0.9298,
      "step": 4000
    },
    {
      "epoch": 21.44,
      "grad_norm": 0.9704768061637878,
      "learning_rate": 5.567287868774686e-05,
      "loss": 0.9242,
      "step": 4010
    },
    {
      "epoch": 21.5,
      "grad_norm": 1.2201048135757446,
      "learning_rate": 5.564009140141373e-05,
      "loss": 1.1323,
      "step": 4020
    },
    {
      "epoch": 21.55,
      "grad_norm": 1.244606375694275,
      "learning_rate": 5.560723527682476e-05,
      "loss": 0.9108,
      "step": 4030
    },
    {
      "epoch": 21.6,
      "grad_norm": 1.7978646755218506,
      "learning_rate": 5.5574310406712636e-05,
      "loss": 1.011,
      "step": 4040
    },
    {
      "epoch": 21.66,
      "grad_norm": 0.8430303931236267,
      "learning_rate": 5.5541316884004045e-05,
      "loss": 1.0073,
      "step": 4050
    },
    {
      "epoch": 21.71,
      "grad_norm": 0.7540463209152222,
      "learning_rate": 5.550825480181945e-05,
      "loss": 1.0121,
      "step": 4060
    },
    {
      "epoch": 21.76,
      "grad_norm": 1.5040547847747803,
      "learning_rate": 5.5475124253472806e-05,
      "loss": 0.9302,
      "step": 4070
    },
    {
      "epoch": 21.82,
      "grad_norm": 0.6753092408180237,
      "learning_rate": 5.544192533247133e-05,
      "loss": 0.8624,
      "step": 4080
    },
    {
      "epoch": 21.87,
      "grad_norm": 1.1261370182037354,
      "learning_rate": 5.540865813251518e-05,
      "loss": 0.9616,
      "step": 4090
    },
    {
      "epoch": 21.93,
      "grad_norm": 1.1124688386917114,
      "learning_rate": 5.537532274749725e-05,
      "loss": 1.0434,
      "step": 4100
    },
    {
      "epoch": 21.98,
      "grad_norm": 0.7168576717376709,
      "learning_rate": 5.5341919271502864e-05,
      "loss": 0.9876,
      "step": 4110
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.3333333333333333,
      "eval_loss": 1.5243587493896484,
      "eval_runtime": 1.1961,
      "eval_samples_per_second": 27.589,
      "eval_steps_per_second": 2.508,
      "step": 4114
    },
    {
      "epoch": 22.03,
      "grad_norm": 0.8676560521125793,
      "learning_rate": 5.5308447798809534e-05,
      "loss": 0.9949,
      "step": 4120
    },
    {
      "epoch": 22.09,
      "grad_norm": 0.900026261806488,
      "learning_rate": 5.527490842388667e-05,
      "loss": 1.0004,
      "step": 4130
    },
    {
      "epoch": 22.14,
      "grad_norm": 1.3137016296386719,
      "learning_rate": 5.5241301241395356e-05,
      "loss": 1.0005,
      "step": 4140
    },
    {
      "epoch": 22.19,
      "grad_norm": 1.0220136642456055,
      "learning_rate": 5.5207626346188025e-05,
      "loss": 0.993,
      "step": 4150
    },
    {
      "epoch": 22.25,
      "grad_norm": 1.2312891483306885,
      "learning_rate": 5.517388383330824e-05,
      "loss": 1.0471,
      "step": 4160
    },
    {
      "epoch": 22.3,
      "grad_norm": 1.6769410371780396,
      "learning_rate": 5.5140073797990394e-05,
      "loss": 0.9255,
      "step": 4170
    },
    {
      "epoch": 22.35,
      "grad_norm": 1.2034671306610107,
      "learning_rate": 5.510619633565947e-05,
      "loss": 0.9307,
      "step": 4180
    },
    {
      "epoch": 22.41,
      "grad_norm": 0.9897595643997192,
      "learning_rate": 5.507225154193074e-05,
      "loss": 0.9801,
      "step": 4190
    },
    {
      "epoch": 22.46,
      "grad_norm": 0.6904630064964294,
      "learning_rate": 5.503823951260953e-05,
      "loss": 0.9202,
      "step": 4200
    },
    {
      "epoch": 22.51,
      "grad_norm": 1.0203937292099,
      "learning_rate": 5.500416034369092e-05,
      "loss": 0.955,
      "step": 4210
    },
    {
      "epoch": 22.57,
      "grad_norm": 1.493366003036499,
      "learning_rate": 5.4970014131359464e-05,
      "loss": 0.9631,
      "step": 4220
    },
    {
      "epoch": 22.62,
      "grad_norm": 1.1704418659210205,
      "learning_rate": 5.4935800971988986e-05,
      "loss": 0.9589,
      "step": 4230
    },
    {
      "epoch": 22.67,
      "grad_norm": 0.868606686592102,
      "learning_rate": 5.490152096214221e-05,
      "loss": 0.8832,
      "step": 4240
    },
    {
      "epoch": 22.73,
      "grad_norm": 1.3931360244750977,
      "learning_rate": 5.4867174198570575e-05,
      "loss": 0.9722,
      "step": 4250
    },
    {
      "epoch": 22.78,
      "grad_norm": 0.9417791366577148,
      "learning_rate": 5.4832760778213904e-05,
      "loss": 1.0468,
      "step": 4260
    },
    {
      "epoch": 22.83,
      "grad_norm": 1.258893609046936,
      "learning_rate": 5.479828079820015e-05,
      "loss": 1.0702,
      "step": 4270
    },
    {
      "epoch": 22.89,
      "grad_norm": 1.205407738685608,
      "learning_rate": 5.476373435584515e-05,
      "loss": 0.9014,
      "step": 4280
    },
    {
      "epoch": 22.94,
      "grad_norm": 0.7801938652992249,
      "learning_rate": 5.47291215486523e-05,
      "loss": 1.009,
      "step": 4290
    },
    {
      "epoch": 22.99,
      "grad_norm": 1.032673954963684,
      "learning_rate": 5.469444247431228e-05,
      "loss": 0.9098,
      "step": 4300
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4990290403366089,
      "eval_runtime": 1.1854,
      "eval_samples_per_second": 27.838,
      "eval_steps_per_second": 2.531,
      "step": 4301
    },
    {
      "epoch": 23.05,
      "grad_norm": 1.1930736303329468,
      "learning_rate": 5.465969723070287e-05,
      "loss": 0.9512,
      "step": 4310
    },
    {
      "epoch": 23.1,
      "grad_norm": 0.8117798566818237,
      "learning_rate": 5.4624885915888525e-05,
      "loss": 0.9594,
      "step": 4320
    },
    {
      "epoch": 23.16,
      "grad_norm": 0.8948596715927124,
      "learning_rate": 5.459000862812024e-05,
      "loss": 0.9624,
      "step": 4330
    },
    {
      "epoch": 23.21,
      "grad_norm": 0.7938948273658752,
      "learning_rate": 5.455506546583519e-05,
      "loss": 0.8883,
      "step": 4340
    },
    {
      "epoch": 23.26,
      "grad_norm": 1.0063211917877197,
      "learning_rate": 5.452005652765646e-05,
      "loss": 1.0209,
      "step": 4350
    },
    {
      "epoch": 23.32,
      "grad_norm": 0.755949079990387,
      "learning_rate": 5.4484981912392793e-05,
      "loss": 0.9598,
      "step": 4360
    },
    {
      "epoch": 23.37,
      "grad_norm": 1.2406325340270996,
      "learning_rate": 5.4449841719038314e-05,
      "loss": 1.0572,
      "step": 4370
    },
    {
      "epoch": 23.42,
      "grad_norm": 1.5346919298171997,
      "learning_rate": 5.4414636046772195e-05,
      "loss": 0.9659,
      "step": 4380
    },
    {
      "epoch": 23.48,
      "grad_norm": 0.9892810583114624,
      "learning_rate": 5.437936499495845e-05,
      "loss": 0.9802,
      "step": 4390
    },
    {
      "epoch": 23.53,
      "grad_norm": 1.1828047037124634,
      "learning_rate": 5.4344028663145594e-05,
      "loss": 0.9864,
      "step": 4400
    },
    {
      "epoch": 23.58,
      "grad_norm": 1.7457659244537354,
      "learning_rate": 5.430862715106642e-05,
      "loss": 0.9855,
      "step": 4410
    },
    {
      "epoch": 23.64,
      "grad_norm": 0.9262098073959351,
      "learning_rate": 5.4273160558637654e-05,
      "loss": 1.0146,
      "step": 4420
    },
    {
      "epoch": 23.69,
      "grad_norm": 0.874821662902832,
      "learning_rate": 5.4237628985959714e-05,
      "loss": 0.9108,
      "step": 4430
    },
    {
      "epoch": 23.74,
      "grad_norm": 0.8979295492172241,
      "learning_rate": 5.4202032533316414e-05,
      "loss": 0.9846,
      "step": 4440
    },
    {
      "epoch": 23.8,
      "grad_norm": 1.1829088926315308,
      "learning_rate": 5.4166371301174705e-05,
      "loss": 0.9741,
      "step": 4450
    },
    {
      "epoch": 23.85,
      "grad_norm": 0.8184618949890137,
      "learning_rate": 5.4130645390184334e-05,
      "loss": 0.9207,
      "step": 4460
    },
    {
      "epoch": 23.9,
      "grad_norm": 1.0501779317855835,
      "learning_rate": 5.4094854901177635e-05,
      "loss": 0.8996,
      "step": 4470
    },
    {
      "epoch": 23.96,
      "grad_norm": 0.8721911907196045,
      "learning_rate": 5.405899993516917e-05,
      "loss": 0.9313,
      "step": 4480
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.530210256576538,
      "eval_runtime": 1.2389,
      "eval_samples_per_second": 26.637,
      "eval_steps_per_second": 2.422,
      "step": 4488
    },
    {
      "epoch": 24.01,
      "grad_norm": 0.9845569729804993,
      "learning_rate": 5.4023080593355504e-05,
      "loss": 0.9955,
      "step": 4490
    },
    {
      "epoch": 24.06,
      "grad_norm": 0.6715483069419861,
      "learning_rate": 5.39870969771149e-05,
      "loss": 0.9071,
      "step": 4500
    },
    {
      "epoch": 24.12,
      "grad_norm": 0.9450945258140564,
      "learning_rate": 5.3951049188007006e-05,
      "loss": 1.0548,
      "step": 4510
    },
    {
      "epoch": 24.17,
      "grad_norm": 1.0552167892456055,
      "learning_rate": 5.391493732777261e-05,
      "loss": 0.9429,
      "step": 4520
    },
    {
      "epoch": 24.22,
      "grad_norm": 0.9204505681991577,
      "learning_rate": 5.387876149833332e-05,
      "loss": 1.0284,
      "step": 4530
    },
    {
      "epoch": 24.28,
      "grad_norm": 0.8346615433692932,
      "learning_rate": 5.3842521801791294e-05,
      "loss": 0.9097,
      "step": 4540
    },
    {
      "epoch": 24.33,
      "grad_norm": 0.9642741084098816,
      "learning_rate": 5.3806218340428954e-05,
      "loss": 0.9843,
      "step": 4550
    },
    {
      "epoch": 24.39,
      "grad_norm": 0.9277641177177429,
      "learning_rate": 5.3769851216708685e-05,
      "loss": 0.9776,
      "step": 4560
    },
    {
      "epoch": 24.44,
      "grad_norm": 0.7527029514312744,
      "learning_rate": 5.373342053327254e-05,
      "loss": 0.9651,
      "step": 4570
    },
    {
      "epoch": 24.49,
      "grad_norm": 0.9680630564689636,
      "learning_rate": 5.369692639294201e-05,
      "loss": 0.9845,
      "step": 4580
    },
    {
      "epoch": 24.55,
      "grad_norm": 0.9474259614944458,
      "learning_rate": 5.366036889871761e-05,
      "loss": 0.8923,
      "step": 4590
    },
    {
      "epoch": 24.6,
      "grad_norm": 1.037184238433838,
      "learning_rate": 5.362374815377873e-05,
      "loss": 0.8429,
      "step": 4600
    },
    {
      "epoch": 24.65,
      "grad_norm": 0.9255258440971375,
      "learning_rate": 5.358706426148324e-05,
      "loss": 0.8469,
      "step": 4610
    },
    {
      "epoch": 24.71,
      "grad_norm": 1.1595712900161743,
      "learning_rate": 5.3550317325367264e-05,
      "loss": 0.9127,
      "step": 4620
    },
    {
      "epoch": 24.76,
      "grad_norm": 0.7569807767868042,
      "learning_rate": 5.3513507449144825e-05,
      "loss": 0.9711,
      "step": 4630
    },
    {
      "epoch": 24.81,
      "grad_norm": 0.8688168525695801,
      "learning_rate": 5.347663473670762e-05,
      "loss": 1.0971,
      "step": 4640
    },
    {
      "epoch": 24.87,
      "grad_norm": 0.9474663138389587,
      "learning_rate": 5.343969929212468e-05,
      "loss": 1.046,
      "step": 4650
    },
    {
      "epoch": 24.92,
      "grad_norm": 0.8082059025764465,
      "learning_rate": 5.340270121964209e-05,
      "loss": 0.9464,
      "step": 4660
    },
    {
      "epoch": 24.97,
      "grad_norm": 1.1937922239303589,
      "learning_rate": 5.336564062368271e-05,
      "loss": 0.9614,
      "step": 4670
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.495309829711914,
      "eval_runtime": 1.1553,
      "eval_samples_per_second": 28.565,
      "eval_steps_per_second": 2.597,
      "step": 4675
    },
    {
      "epoch": 25.03,
      "grad_norm": 1.969961166381836,
      "learning_rate": 5.332851760884583e-05,
      "loss": 0.9592,
      "step": 4680
    },
    {
      "epoch": 25.08,
      "grad_norm": 1.2878953218460083,
      "learning_rate": 5.329133227990694e-05,
      "loss": 0.9275,
      "step": 4690
    },
    {
      "epoch": 25.13,
      "grad_norm": 1.1832237243652344,
      "learning_rate": 5.32540847418174e-05,
      "loss": 0.8806,
      "step": 4700
    },
    {
      "epoch": 25.19,
      "grad_norm": 0.7445362210273743,
      "learning_rate": 5.321677509970414e-05,
      "loss": 0.9607,
      "step": 4710
    },
    {
      "epoch": 25.24,
      "grad_norm": 1.1990312337875366,
      "learning_rate": 5.3179403458869395e-05,
      "loss": 1.0377,
      "step": 4720
    },
    {
      "epoch": 25.29,
      "grad_norm": 0.9747974276542664,
      "learning_rate": 5.314196992479034e-05,
      "loss": 0.9865,
      "step": 4730
    },
    {
      "epoch": 25.35,
      "grad_norm": 1.3285667896270752,
      "learning_rate": 5.310447460311888e-05,
      "loss": 0.9264,
      "step": 4740
    },
    {
      "epoch": 25.4,
      "grad_norm": 1.0680345296859741,
      "learning_rate": 5.306691759968128e-05,
      "loss": 1.0171,
      "step": 4750
    },
    {
      "epoch": 25.45,
      "grad_norm": 0.8972817659378052,
      "learning_rate": 5.3029299020477924e-05,
      "loss": 0.9065,
      "step": 4760
    },
    {
      "epoch": 25.51,
      "grad_norm": 0.9487742185592651,
      "learning_rate": 5.2991618971682944e-05,
      "loss": 1.0539,
      "step": 4770
    },
    {
      "epoch": 25.56,
      "grad_norm": 1.5384390354156494,
      "learning_rate": 5.2953877559644004e-05,
      "loss": 0.9658,
      "step": 4780
    },
    {
      "epoch": 25.61,
      "grad_norm": 1.0739552974700928,
      "learning_rate": 5.2916074890881934e-05,
      "loss": 0.9758,
      "step": 4790
    },
    {
      "epoch": 25.67,
      "grad_norm": 1.2690320014953613,
      "learning_rate": 5.287821107209047e-05,
      "loss": 0.9034,
      "step": 4800
    },
    {
      "epoch": 25.72,
      "grad_norm": 1.6859447956085205,
      "learning_rate": 5.284028621013592e-05,
      "loss": 0.9418,
      "step": 4810
    },
    {
      "epoch": 25.78,
      "grad_norm": 1.009531855583191,
      "learning_rate": 5.28023004120569e-05,
      "loss": 1.0633,
      "step": 4820
    },
    {
      "epoch": 25.83,
      "grad_norm": 1.448235273361206,
      "learning_rate": 5.276425378506399e-05,
      "loss": 1.0026,
      "step": 4830
    },
    {
      "epoch": 25.88,
      "grad_norm": 1.8704853057861328,
      "learning_rate": 5.272614643653946e-05,
      "loss": 0.9498,
      "step": 4840
    },
    {
      "epoch": 25.94,
      "grad_norm": 1.2013835906982422,
      "learning_rate": 5.2687978474036975e-05,
      "loss": 0.9094,
      "step": 4850
    },
    {
      "epoch": 25.99,
      "grad_norm": 1.3716132640838623,
      "learning_rate": 5.264975000528126e-05,
      "loss": 0.9348,
      "step": 4860
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.48484848484848486,
      "eval_loss": 1.4727891683578491,
      "eval_runtime": 1.1733,
      "eval_samples_per_second": 28.126,
      "eval_steps_per_second": 2.557,
      "step": 4862
    },
    {
      "epoch": 26.04,
      "grad_norm": 0.8439679145812988,
      "learning_rate": 5.2611461138167793e-05,
      "loss": 0.9995,
      "step": 4870
    },
    {
      "epoch": 26.1,
      "grad_norm": 0.8760703802108765,
      "learning_rate": 5.257311198076257e-05,
      "loss": 0.9311,
      "step": 4880
    },
    {
      "epoch": 26.15,
      "grad_norm": 1.5557494163513184,
      "learning_rate": 5.2534702641301725e-05,
      "loss": 1.0441,
      "step": 4890
    },
    {
      "epoch": 26.2,
      "grad_norm": 1.1858553886413574,
      "learning_rate": 5.249623322819122e-05,
      "loss": 0.9966,
      "step": 4900
    },
    {
      "epoch": 26.26,
      "grad_norm": 1.6278823614120483,
      "learning_rate": 5.24577038500066e-05,
      "loss": 0.9839,
      "step": 4910
    },
    {
      "epoch": 26.31,
      "grad_norm": 1.2186787128448486,
      "learning_rate": 5.241911461549266e-05,
      "loss": 0.9549,
      "step": 4920
    },
    {
      "epoch": 26.36,
      "grad_norm": 1.8455984592437744,
      "learning_rate": 5.238046563356311e-05,
      "loss": 0.967,
      "step": 4930
    },
    {
      "epoch": 26.42,
      "grad_norm": 0.9899476170539856,
      "learning_rate": 5.234175701330031e-05,
      "loss": 0.9517,
      "step": 4940
    },
    {
      "epoch": 26.47,
      "grad_norm": 1.4553513526916504,
      "learning_rate": 5.2302988863954915e-05,
      "loss": 1.0906,
      "step": 4950
    },
    {
      "epoch": 26.52,
      "grad_norm": 0.8011419773101807,
      "learning_rate": 5.226416129494563e-05,
      "loss": 0.9208,
      "step": 4960
    },
    {
      "epoch": 26.58,
      "grad_norm": 1.5305829048156738,
      "learning_rate": 5.222527441585885e-05,
      "loss": 0.9317,
      "step": 4970
    },
    {
      "epoch": 26.63,
      "grad_norm": 1.3296079635620117,
      "learning_rate": 5.218632833644834e-05,
      "loss": 0.9422,
      "step": 4980
    },
    {
      "epoch": 26.68,
      "grad_norm": 0.960790753364563,
      "learning_rate": 5.2147323166634993e-05,
      "loss": 0.9601,
      "step": 4990
    },
    {
      "epoch": 26.74,
      "grad_norm": 1.7140566110610962,
      "learning_rate": 5.210825901650647e-05,
      "loss": 0.8716,
      "step": 5000
    },
    {
      "epoch": 26.79,
      "grad_norm": 0.7763456106185913,
      "learning_rate": 5.2069135996316854e-05,
      "loss": 1.0239,
      "step": 5010
    },
    {
      "epoch": 26.84,
      "grad_norm": 1.1152408123016357,
      "learning_rate": 5.2029954216486445e-05,
      "loss": 0.9618,
      "step": 5020
    },
    {
      "epoch": 26.9,
      "grad_norm": 1.528591513633728,
      "learning_rate": 5.199071378760134e-05,
      "loss": 0.9358,
      "step": 5030
    },
    {
      "epoch": 26.95,
      "grad_norm": 1.025210976600647,
      "learning_rate": 5.195141482041319e-05,
      "loss": 0.8967,
      "step": 5040
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.495255708694458,
      "eval_runtime": 1.165,
      "eval_samples_per_second": 28.326,
      "eval_steps_per_second": 2.575,
      "step": 5049
    },
    {
      "epoch": 27.01,
      "grad_norm": 0.8730195760726929,
      "learning_rate": 5.191205742583885e-05,
      "loss": 0.8691,
      "step": 5050
    },
    {
      "epoch": 27.06,
      "grad_norm": 0.7496643662452698,
      "learning_rate": 5.187264171496009e-05,
      "loss": 0.9132,
      "step": 5060
    },
    {
      "epoch": 27.11,
      "grad_norm": 0.8879263401031494,
      "learning_rate": 5.183316779902325e-05,
      "loss": 0.9219,
      "step": 5070
    },
    {
      "epoch": 27.17,
      "grad_norm": 0.7056505084037781,
      "learning_rate": 5.1793635789438977e-05,
      "loss": 0.9617,
      "step": 5080
    },
    {
      "epoch": 27.22,
      "grad_norm": 0.7381085157394409,
      "learning_rate": 5.175404579778187e-05,
      "loss": 0.9472,
      "step": 5090
    },
    {
      "epoch": 27.27,
      "grad_norm": 1.2686277627944946,
      "learning_rate": 5.171439793579016e-05,
      "loss": 1.0024,
      "step": 5100
    },
    {
      "epoch": 27.33,
      "grad_norm": 0.9334902167320251,
      "learning_rate": 5.1674692315365437e-05,
      "loss": 0.9003,
      "step": 5110
    },
    {
      "epoch": 27.38,
      "grad_norm": 1.2248564958572388,
      "learning_rate": 5.163492904857228e-05,
      "loss": 0.9305,
      "step": 5120
    },
    {
      "epoch": 27.43,
      "grad_norm": 1.0347541570663452,
      "learning_rate": 5.159510824763799e-05,
      "loss": 0.9124,
      "step": 5130
    },
    {
      "epoch": 27.49,
      "grad_norm": 1.7893683910369873,
      "learning_rate": 5.155523002495224e-05,
      "loss": 0.9607,
      "step": 5140
    },
    {
      "epoch": 27.54,
      "grad_norm": 1.0460880994796753,
      "learning_rate": 5.1515294493066784e-05,
      "loss": 0.941,
      "step": 5150
    },
    {
      "epoch": 27.59,
      "grad_norm": 1.7800109386444092,
      "learning_rate": 5.1475301764695085e-05,
      "loss": 0.8767,
      "step": 5160
    },
    {
      "epoch": 27.65,
      "grad_norm": 1.048602819442749,
      "learning_rate": 5.14352519527121e-05,
      "loss": 0.9642,
      "step": 5170
    },
    {
      "epoch": 27.7,
      "grad_norm": 0.9048726558685303,
      "learning_rate": 5.139514517015385e-05,
      "loss": 1.0246,
      "step": 5180
    },
    {
      "epoch": 27.75,
      "grad_norm": 1.3732631206512451,
      "learning_rate": 5.135498153021716e-05,
      "loss": 0.8881,
      "step": 5190
    },
    {
      "epoch": 27.81,
      "grad_norm": 1.4169846773147583,
      "learning_rate": 5.131476114625932e-05,
      "loss": 0.9773,
      "step": 5200
    },
    {
      "epoch": 27.86,
      "grad_norm": 0.7613846063613892,
      "learning_rate": 5.127448413179779e-05,
      "loss": 0.9536,
      "step": 5210
    },
    {
      "epoch": 27.91,
      "grad_norm": 1.0233242511749268,
      "learning_rate": 5.123415060050987e-05,
      "loss": 0.9415,
      "step": 5220
    },
    {
      "epoch": 27.97,
      "grad_norm": 1.4863839149475098,
      "learning_rate": 5.119376066623235e-05,
      "loss": 0.9687,
      "step": 5230
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.4474337100982666,
      "eval_runtime": 1.1749,
      "eval_samples_per_second": 28.088,
      "eval_steps_per_second": 2.553,
      "step": 5236
    },
    {
      "epoch": 28.02,
      "grad_norm": 0.9542576670646667,
      "learning_rate": 5.115331444296123e-05,
      "loss": 0.8991,
      "step": 5240
    },
    {
      "epoch": 28.07,
      "grad_norm": 0.8041437864303589,
      "learning_rate": 5.111281204485135e-05,
      "loss": 0.9627,
      "step": 5250
    },
    {
      "epoch": 28.13,
      "grad_norm": 1.1848939657211304,
      "learning_rate": 5.107225358621613e-05,
      "loss": 0.8974,
      "step": 5260
    },
    {
      "epoch": 28.18,
      "grad_norm": 1.3347585201263428,
      "learning_rate": 5.10316391815272e-05,
      "loss": 0.9897,
      "step": 5270
    },
    {
      "epoch": 28.24,
      "grad_norm": 0.7059517502784729,
      "learning_rate": 5.0990968945414095e-05,
      "loss": 1.016,
      "step": 5280
    },
    {
      "epoch": 28.29,
      "grad_norm": 0.8960441946983337,
      "learning_rate": 5.095024299266392e-05,
      "loss": 1.0358,
      "step": 5290
    },
    {
      "epoch": 28.34,
      "grad_norm": 1.062646746635437,
      "learning_rate": 5.090946143822104e-05,
      "loss": 1.0012,
      "step": 5300
    },
    {
      "epoch": 28.4,
      "grad_norm": 0.7095854878425598,
      "learning_rate": 5.086862439718676e-05,
      "loss": 0.9314,
      "step": 5310
    },
    {
      "epoch": 28.45,
      "grad_norm": 1.0420596599578857,
      "learning_rate": 5.082773198481896e-05,
      "loss": 1.0871,
      "step": 5320
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.7807521224021912,
      "learning_rate": 5.078678431653183e-05,
      "loss": 0.9582,
      "step": 5330
    },
    {
      "epoch": 28.56,
      "grad_norm": 0.9578022956848145,
      "learning_rate": 5.0745781507895496e-05,
      "loss": 0.9396,
      "step": 5340
    },
    {
      "epoch": 28.61,
      "grad_norm": 0.8520365953445435,
      "learning_rate": 5.070472367463573e-05,
      "loss": 0.8759,
      "step": 5350
    },
    {
      "epoch": 28.66,
      "grad_norm": 1.3964519500732422,
      "learning_rate": 5.066361093263357e-05,
      "loss": 0.8424,
      "step": 5360
    },
    {
      "epoch": 28.72,
      "grad_norm": 1.233174443244934,
      "learning_rate": 5.0622443397925056e-05,
      "loss": 0.9207,
      "step": 5370
    },
    {
      "epoch": 28.77,
      "grad_norm": 1.2860121726989746,
      "learning_rate": 5.058122118670088e-05,
      "loss": 0.8757,
      "step": 5380
    },
    {
      "epoch": 28.82,
      "grad_norm": 0.8320493102073669,
      "learning_rate": 5.053994441530603e-05,
      "loss": 1.0077,
      "step": 5390
    },
    {
      "epoch": 28.88,
      "grad_norm": 1.5883046388626099,
      "learning_rate": 5.04986132002395e-05,
      "loss": 0.9676,
      "step": 5400
    },
    {
      "epoch": 28.93,
      "grad_norm": 1.8833045959472656,
      "learning_rate": 5.045722765815391e-05,
      "loss": 0.9073,
      "step": 5410
    },
    {
      "epoch": 28.98,
      "grad_norm": 0.7572395205497742,
      "learning_rate": 5.041578790585528e-05,
      "loss": 0.9127,
      "step": 5420
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4762601852416992,
      "eval_runtime": 1.1881,
      "eval_samples_per_second": 27.776,
      "eval_steps_per_second": 2.525,
      "step": 5423
    },
    {
      "epoch": 29.04,
      "grad_norm": 0.8867781162261963,
      "learning_rate": 5.037429406030258e-05,
      "loss": 0.9323,
      "step": 5430
    },
    {
      "epoch": 29.09,
      "grad_norm": 1.1127147674560547,
      "learning_rate": 5.0332746238607446e-05,
      "loss": 0.9036,
      "step": 5440
    },
    {
      "epoch": 29.14,
      "grad_norm": 0.914371132850647,
      "learning_rate": 5.029114455803389e-05,
      "loss": 0.9332,
      "step": 5450
    },
    {
      "epoch": 29.2,
      "grad_norm": 1.1112148761749268,
      "learning_rate": 5.024948913599792e-05,
      "loss": 0.9464,
      "step": 5460
    },
    {
      "epoch": 29.25,
      "grad_norm": 0.6966487169265747,
      "learning_rate": 5.0207780090067205e-05,
      "loss": 0.9808,
      "step": 5470
    },
    {
      "epoch": 29.3,
      "grad_norm": 0.8523676991462708,
      "learning_rate": 5.01660175379608e-05,
      "loss": 0.9513,
      "step": 5480
    },
    {
      "epoch": 29.36,
      "grad_norm": 0.8558575510978699,
      "learning_rate": 5.0124201597548744e-05,
      "loss": 0.9895,
      "step": 5490
    },
    {
      "epoch": 29.41,
      "grad_norm": 0.9109141826629639,
      "learning_rate": 5.0082332386851766e-05,
      "loss": 0.9085,
      "step": 5500
    },
    {
      "epoch": 29.47,
      "grad_norm": 1.2758440971374512,
      "learning_rate": 5.004041002404095e-05,
      "loss": 0.9409,
      "step": 5510
    },
    {
      "epoch": 29.52,
      "grad_norm": 1.0274646282196045,
      "learning_rate": 4.999843462743738e-05,
      "loss": 1.0586,
      "step": 5520
    },
    {
      "epoch": 29.57,
      "grad_norm": 1.1660484075546265,
      "learning_rate": 4.995640631551184e-05,
      "loss": 0.9122,
      "step": 5530
    },
    {
      "epoch": 29.63,
      "grad_norm": 0.984433650970459,
      "learning_rate": 4.991432520688446e-05,
      "loss": 0.9849,
      "step": 5540
    },
    {
      "epoch": 29.68,
      "grad_norm": 0.9977545142173767,
      "learning_rate": 4.9872191420324374e-05,
      "loss": 0.9483,
      "step": 5550
    },
    {
      "epoch": 29.73,
      "grad_norm": 1.1839724779129028,
      "learning_rate": 4.983000507474941e-05,
      "loss": 0.8462,
      "step": 5560
    },
    {
      "epoch": 29.79,
      "grad_norm": 1.3780421018600464,
      "learning_rate": 4.97877662892257e-05,
      "loss": 0.93,
      "step": 5570
    },
    {
      "epoch": 29.84,
      "grad_norm": 1.1936417818069458,
      "learning_rate": 4.9745475182967416e-05,
      "loss": 0.9733,
      "step": 5580
    },
    {
      "epoch": 29.89,
      "grad_norm": 1.1919975280761719,
      "learning_rate": 4.970313187533639e-05,
      "loss": 0.9697,
      "step": 5590
    },
    {
      "epoch": 29.95,
      "grad_norm": 1.1275157928466797,
      "learning_rate": 4.96607364858418e-05,
      "loss": 1.0023,
      "step": 5600
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.5739076137542725,
      "learning_rate": 4.9618289134139785e-05,
      "loss": 0.9929,
      "step": 5610
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4833252429962158,
      "eval_runtime": 1.1842,
      "eval_samples_per_second": 27.866,
      "eval_steps_per_second": 2.533,
      "step": 5610
    },
    {
      "epoch": 30.05,
      "grad_norm": 1.0791559219360352,
      "learning_rate": 4.957578994003318e-05,
      "loss": 0.9171,
      "step": 5620
    },
    {
      "epoch": 30.11,
      "grad_norm": 0.6928078532218933,
      "learning_rate": 4.953323902347111e-05,
      "loss": 0.9834,
      "step": 5630
    },
    {
      "epoch": 30.16,
      "grad_norm": 1.290741205215454,
      "learning_rate": 4.9490636504548696e-05,
      "loss": 0.9952,
      "step": 5640
    },
    {
      "epoch": 30.21,
      "grad_norm": 0.8814122080802917,
      "learning_rate": 4.944798250350669e-05,
      "loss": 0.8914,
      "step": 5650
    },
    {
      "epoch": 30.27,
      "grad_norm": 0.9534458518028259,
      "learning_rate": 4.940527714073116e-05,
      "loss": 0.9046,
      "step": 5660
    },
    {
      "epoch": 30.32,
      "grad_norm": 1.0885412693023682,
      "learning_rate": 4.936252053675314e-05,
      "loss": 0.9133,
      "step": 5670
    },
    {
      "epoch": 30.37,
      "grad_norm": 1.8421920537948608,
      "learning_rate": 4.9319712812248246e-05,
      "loss": 1.0428,
      "step": 5680
    },
    {
      "epoch": 30.43,
      "grad_norm": 0.7650648355484009,
      "learning_rate": 4.9276854088036434e-05,
      "loss": 0.9965,
      "step": 5690
    },
    {
      "epoch": 30.48,
      "grad_norm": 0.9493058919906616,
      "learning_rate": 4.923394448508157e-05,
      "loss": 1.015,
      "step": 5700
    },
    {
      "epoch": 30.53,
      "grad_norm": 0.8532283902168274,
      "learning_rate": 4.919098412449111e-05,
      "loss": 0.9512,
      "step": 5710
    },
    {
      "epoch": 30.59,
      "grad_norm": 0.8465755581855774,
      "learning_rate": 4.9147973127515786e-05,
      "loss": 0.9508,
      "step": 5720
    },
    {
      "epoch": 30.64,
      "grad_norm": 0.9102141857147217,
      "learning_rate": 4.9104911615549246e-05,
      "loss": 0.9234,
      "step": 5730
    },
    {
      "epoch": 30.7,
      "grad_norm": 1.490475058555603,
      "learning_rate": 4.90617997101277e-05,
      "loss": 0.9505,
      "step": 5740
    },
    {
      "epoch": 30.75,
      "grad_norm": 0.9259419441223145,
      "learning_rate": 4.901863753292958e-05,
      "loss": 0.9137,
      "step": 5750
    },
    {
      "epoch": 30.8,
      "grad_norm": 1.0851256847381592,
      "learning_rate": 4.897542520577524e-05,
      "loss": 0.9673,
      "step": 5760
    },
    {
      "epoch": 30.86,
      "grad_norm": 0.846038281917572,
      "learning_rate": 4.893216285062653e-05,
      "loss": 0.9094,
      "step": 5770
    },
    {
      "epoch": 30.91,
      "grad_norm": 1.424959659576416,
      "learning_rate": 4.888885058958655e-05,
      "loss": 0.88,
      "step": 5780
    },
    {
      "epoch": 30.96,
      "grad_norm": 0.8572200536727905,
      "learning_rate": 4.884548854489918e-05,
      "loss": 0.944,
      "step": 5790
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4501479864120483,
      "eval_runtime": 1.2634,
      "eval_samples_per_second": 26.121,
      "eval_steps_per_second": 2.375,
      "step": 5797
    },
    {
      "epoch": 31.02,
      "grad_norm": 0.9762566685676575,
      "learning_rate": 4.88020768389489e-05,
      "loss": 0.9891,
      "step": 5800
    },
    {
      "epoch": 31.07,
      "grad_norm": 0.7341299653053284,
      "learning_rate": 4.8758615594260276e-05,
      "loss": 0.8048,
      "step": 5810
    },
    {
      "epoch": 31.12,
      "grad_norm": 1.2444641590118408,
      "learning_rate": 4.871510493349775e-05,
      "loss": 0.9403,
      "step": 5820
    },
    {
      "epoch": 31.18,
      "grad_norm": 0.9630955457687378,
      "learning_rate": 4.8671544979465177e-05,
      "loss": 0.9261,
      "step": 5830
    },
    {
      "epoch": 31.23,
      "grad_norm": 0.9910022020339966,
      "learning_rate": 4.862793585510558e-05,
      "loss": 0.991,
      "step": 5840
    },
    {
      "epoch": 31.28,
      "grad_norm": 1.1917784214019775,
      "learning_rate": 4.858427768350077e-05,
      "loss": 0.943,
      "step": 5850
    },
    {
      "epoch": 31.34,
      "grad_norm": 1.4496876001358032,
      "learning_rate": 4.8540570587870924e-05,
      "loss": 0.9371,
      "step": 5860
    },
    {
      "epoch": 31.39,
      "grad_norm": 0.8826786279678345,
      "learning_rate": 4.8496814691574366e-05,
      "loss": 0.9627,
      "step": 5870
    },
    {
      "epoch": 31.44,
      "grad_norm": 1.6054571866989136,
      "learning_rate": 4.845301011810714e-05,
      "loss": 0.9919,
      "step": 5880
    },
    {
      "epoch": 31.5,
      "grad_norm": 1.0297023057937622,
      "learning_rate": 4.8409156991102644e-05,
      "loss": 0.9128,
      "step": 5890
    },
    {
      "epoch": 31.55,
      "grad_norm": 1.1970869302749634,
      "learning_rate": 4.836525543433136e-05,
      "loss": 0.8686,
      "step": 5900
    },
    {
      "epoch": 31.6,
      "grad_norm": 1.0020906925201416,
      "learning_rate": 4.83213055717004e-05,
      "loss": 0.9018,
      "step": 5910
    },
    {
      "epoch": 31.66,
      "grad_norm": 1.4928293228149414,
      "learning_rate": 4.827730752725329e-05,
      "loss": 0.9556,
      "step": 5920
    },
    {
      "epoch": 31.71,
      "grad_norm": 1.190658688545227,
      "learning_rate": 4.823326142516946e-05,
      "loss": 1.0369,
      "step": 5930
    },
    {
      "epoch": 31.76,
      "grad_norm": 0.9625412821769714,
      "learning_rate": 4.8189167389764046e-05,
      "loss": 0.9283,
      "step": 5940
    },
    {
      "epoch": 31.82,
      "grad_norm": 1.1846542358398438,
      "learning_rate": 4.8145025545487425e-05,
      "loss": 0.9633,
      "step": 5950
    },
    {
      "epoch": 31.87,
      "grad_norm": 1.0562114715576172,
      "learning_rate": 4.8100836016924935e-05,
      "loss": 0.9194,
      "step": 5960
    },
    {
      "epoch": 31.93,
      "grad_norm": 1.3903098106384277,
      "learning_rate": 4.805659892879649e-05,
      "loss": 0.9614,
      "step": 5970
    },
    {
      "epoch": 31.98,
      "grad_norm": 1.196431279182434,
      "learning_rate": 4.8012314405956226e-05,
      "loss": 0.9676,
      "step": 5980
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4867955446243286,
      "eval_runtime": 1.2324,
      "eval_samples_per_second": 26.777,
      "eval_steps_per_second": 2.434,
      "step": 5984
    },
    {
      "epoch": 32.03,
      "grad_norm": 1.1160391569137573,
      "learning_rate": 4.796798257339218e-05,
      "loss": 0.9229,
      "step": 5990
    },
    {
      "epoch": 32.09,
      "grad_norm": 1.4959717988967896,
      "learning_rate": 4.792360355622589e-05,
      "loss": 0.8771,
      "step": 6000
    },
    {
      "epoch": 32.14,
      "grad_norm": 0.7581830024719238,
      "learning_rate": 4.787917747971208e-05,
      "loss": 0.9946,
      "step": 6010
    },
    {
      "epoch": 32.19,
      "grad_norm": 0.8485940098762512,
      "learning_rate": 4.783470446923829e-05,
      "loss": 0.8926,
      "step": 6020
    },
    {
      "epoch": 32.25,
      "grad_norm": 1.6228126287460327,
      "learning_rate": 4.7790184650324546e-05,
      "loss": 1.0278,
      "step": 6030
    },
    {
      "epoch": 32.3,
      "grad_norm": 1.2764908075332642,
      "learning_rate": 4.774561814862294e-05,
      "loss": 0.9541,
      "step": 6040
    },
    {
      "epoch": 32.35,
      "grad_norm": 0.952763020992279,
      "learning_rate": 4.770100508991737e-05,
      "loss": 0.875,
      "step": 6050
    },
    {
      "epoch": 32.41,
      "grad_norm": 0.8756734132766724,
      "learning_rate": 4.765634560012311e-05,
      "loss": 0.9622,
      "step": 6060
    },
    {
      "epoch": 32.46,
      "grad_norm": 1.310794472694397,
      "learning_rate": 4.761163980528648e-05,
      "loss": 0.8872,
      "step": 6070
    },
    {
      "epoch": 32.51,
      "grad_norm": 1.1421843767166138,
      "learning_rate": 4.7566887831584494e-05,
      "loss": 0.993,
      "step": 6080
    },
    {
      "epoch": 32.57,
      "grad_norm": 1.2686657905578613,
      "learning_rate": 4.75220898053245e-05,
      "loss": 0.9684,
      "step": 6090
    },
    {
      "epoch": 32.62,
      "grad_norm": 1.6587839126586914,
      "learning_rate": 4.7477245852943845e-05,
      "loss": 0.9645,
      "step": 6100
    },
    {
      "epoch": 32.67,
      "grad_norm": 1.1936157941818237,
      "learning_rate": 4.743235610100946e-05,
      "loss": 1.0035,
      "step": 6110
    },
    {
      "epoch": 32.73,
      "grad_norm": 1.0137683153152466,
      "learning_rate": 4.738742067621756e-05,
      "loss": 0.9635,
      "step": 6120
    },
    {
      "epoch": 32.78,
      "grad_norm": 1.2331112623214722,
      "learning_rate": 4.734243970539327e-05,
      "loss": 0.925,
      "step": 6130
    },
    {
      "epoch": 32.83,
      "grad_norm": 0.9539144039154053,
      "learning_rate": 4.729741331549026e-05,
      "loss": 0.8543,
      "step": 6140
    },
    {
      "epoch": 32.89,
      "grad_norm": 1.5057241916656494,
      "learning_rate": 4.7252341633590396e-05,
      "loss": 0.9787,
      "step": 6150
    },
    {
      "epoch": 32.94,
      "grad_norm": 1.338826060295105,
      "learning_rate": 4.720722478690334e-05,
      "loss": 0.9279,
      "step": 6160
    },
    {
      "epoch": 32.99,
      "grad_norm": 1.0213851928710938,
      "learning_rate": 4.716206290276628e-05,
      "loss": 0.9427,
      "step": 6170
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.450272560119629,
      "eval_runtime": 1.1651,
      "eval_samples_per_second": 28.324,
      "eval_steps_per_second": 2.575,
      "step": 6171
    },
    {
      "epoch": 33.05,
      "grad_norm": 1.7384344339370728,
      "learning_rate": 4.711685610864349e-05,
      "loss": 0.9204,
      "step": 6180
    },
    {
      "epoch": 33.1,
      "grad_norm": 1.3804434537887573,
      "learning_rate": 4.7071604532126e-05,
      "loss": 1.0221,
      "step": 6190
    },
    {
      "epoch": 33.16,
      "grad_norm": 1.0088157653808594,
      "learning_rate": 4.702630830093121e-05,
      "loss": 0.9845,
      "step": 6200
    },
    {
      "epoch": 33.21,
      "grad_norm": 1.0602604150772095,
      "learning_rate": 4.6980967542902596e-05,
      "loss": 0.931,
      "step": 6210
    },
    {
      "epoch": 33.26,
      "grad_norm": 1.1788711547851562,
      "learning_rate": 4.6935582386009274e-05,
      "loss": 0.8662,
      "step": 6220
    },
    {
      "epoch": 33.32,
      "grad_norm": 0.99528968334198,
      "learning_rate": 4.689015295834569e-05,
      "loss": 0.9421,
      "step": 6230
    },
    {
      "epoch": 33.37,
      "grad_norm": 0.9057333469390869,
      "learning_rate": 4.684467938813124e-05,
      "loss": 0.9101,
      "step": 6240
    },
    {
      "epoch": 33.42,
      "grad_norm": 1.2287044525146484,
      "learning_rate": 4.679916180370987e-05,
      "loss": 0.9009,
      "step": 6250
    },
    {
      "epoch": 33.48,
      "grad_norm": 1.3927686214447021,
      "learning_rate": 4.6753600333549797e-05,
      "loss": 0.9621,
      "step": 6260
    },
    {
      "epoch": 33.53,
      "grad_norm": 1.268701195716858,
      "learning_rate": 4.670799510624309e-05,
      "loss": 0.8941,
      "step": 6270
    },
    {
      "epoch": 33.58,
      "grad_norm": 1.8533176183700562,
      "learning_rate": 4.66623462505053e-05,
      "loss": 1.0104,
      "step": 6280
    },
    {
      "epoch": 33.64,
      "grad_norm": 0.8880080580711365,
      "learning_rate": 4.6616653895175124e-05,
      "loss": 1.0477,
      "step": 6290
    },
    {
      "epoch": 33.69,
      "grad_norm": 1.806931495666504,
      "learning_rate": 4.657091816921403e-05,
      "loss": 0.9656,
      "step": 6300
    },
    {
      "epoch": 33.74,
      "grad_norm": 1.007074236869812,
      "learning_rate": 4.65251392017059e-05,
      "loss": 0.9808,
      "step": 6310
    },
    {
      "epoch": 33.8,
      "grad_norm": 1.1178901195526123,
      "learning_rate": 4.647931712185667e-05,
      "loss": 0.9234,
      "step": 6320
    },
    {
      "epoch": 33.85,
      "grad_norm": 1.1100738048553467,
      "learning_rate": 4.6433452058993924e-05,
      "loss": 0.8863,
      "step": 6330
    },
    {
      "epoch": 33.9,
      "grad_norm": 0.9109746217727661,
      "learning_rate": 4.638754414256658e-05,
      "loss": 0.9262,
      "step": 6340
    },
    {
      "epoch": 33.96,
      "grad_norm": 0.9277697801589966,
      "learning_rate": 4.6341593502144514e-05,
      "loss": 0.8383,
      "step": 6350
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4281352758407593,
      "eval_runtime": 1.1583,
      "eval_samples_per_second": 28.49,
      "eval_steps_per_second": 2.59,
      "step": 6358
    },
    {
      "epoch": 34.01,
      "grad_norm": 1.4459885358810425,
      "learning_rate": 4.629560026741818e-05,
      "loss": 0.9191,
      "step": 6360
    },
    {
      "epoch": 34.06,
      "grad_norm": 1.309554934501648,
      "learning_rate": 4.624956456819823e-05,
      "loss": 0.956,
      "step": 6370
    },
    {
      "epoch": 34.12,
      "grad_norm": 1.3340739011764526,
      "learning_rate": 4.6203486534415205e-05,
      "loss": 0.9863,
      "step": 6380
    },
    {
      "epoch": 34.17,
      "grad_norm": 0.8217849731445312,
      "learning_rate": 4.615736629611909e-05,
      "loss": 0.9718,
      "step": 6390
    },
    {
      "epoch": 34.22,
      "grad_norm": 0.9026288390159607,
      "learning_rate": 4.6111203983479026e-05,
      "loss": 0.9102,
      "step": 6400
    },
    {
      "epoch": 34.28,
      "grad_norm": 0.9299717545509338,
      "learning_rate": 4.6064999726782855e-05,
      "loss": 1.0073,
      "step": 6410
    },
    {
      "epoch": 34.33,
      "grad_norm": 1.0460219383239746,
      "learning_rate": 4.601875365643685e-05,
      "loss": 0.9073,
      "step": 6420
    },
    {
      "epoch": 34.39,
      "grad_norm": 1.1615846157073975,
      "learning_rate": 4.5972465902965275e-05,
      "loss": 1.0653,
      "step": 6430
    },
    {
      "epoch": 34.44,
      "grad_norm": 1.203359603881836,
      "learning_rate": 4.592613659701006e-05,
      "loss": 0.922,
      "step": 6440
    },
    {
      "epoch": 34.49,
      "grad_norm": 1.80341374874115,
      "learning_rate": 4.587976586933036e-05,
      "loss": 1.0169,
      "step": 6450
    },
    {
      "epoch": 34.55,
      "grad_norm": 0.8357510566711426,
      "learning_rate": 4.5833353850802304e-05,
      "loss": 0.9479,
      "step": 6460
    },
    {
      "epoch": 34.6,
      "grad_norm": 1.1596795320510864,
      "learning_rate": 4.578690067241852e-05,
      "loss": 0.8774,
      "step": 6470
    },
    {
      "epoch": 34.65,
      "grad_norm": 0.8425080180168152,
      "learning_rate": 4.574040646528781e-05,
      "loss": 0.9537,
      "step": 6480
    },
    {
      "epoch": 34.71,
      "grad_norm": 1.2915748357772827,
      "learning_rate": 4.569387136063479e-05,
      "loss": 0.9787,
      "step": 6490
    },
    {
      "epoch": 34.76,
      "grad_norm": 1.4061468839645386,
      "learning_rate": 4.5647295489799484e-05,
      "loss": 0.9213,
      "step": 6500
    },
    {
      "epoch": 34.81,
      "grad_norm": 0.7697538733482361,
      "learning_rate": 4.560067898423699e-05,
      "loss": 0.8865,
      "step": 6510
    },
    {
      "epoch": 34.87,
      "grad_norm": 1.3415076732635498,
      "learning_rate": 4.555402197551709e-05,
      "loss": 0.945,
      "step": 6520
    },
    {
      "epoch": 34.92,
      "grad_norm": 0.8922111392021179,
      "learning_rate": 4.550732459532386e-05,
      "loss": 0.8842,
      "step": 6530
    },
    {
      "epoch": 34.97,
      "grad_norm": 1.17383873462677,
      "learning_rate": 4.5460586975455365e-05,
      "loss": 1.051,
      "step": 6540
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4604430198669434,
      "eval_runtime": 1.1752,
      "eval_samples_per_second": 28.079,
      "eval_steps_per_second": 2.553,
      "step": 6545
    },
    {
      "epoch": 35.03,
      "grad_norm": 1.124092698097229,
      "learning_rate": 4.54138092478232e-05,
      "loss": 0.9897,
      "step": 6550
    },
    {
      "epoch": 35.08,
      "grad_norm": 0.9509946703910828,
      "learning_rate": 4.5366991544452175e-05,
      "loss": 0.8824,
      "step": 6560
    },
    {
      "epoch": 35.13,
      "grad_norm": 1.5034507513046265,
      "learning_rate": 4.532013399747994e-05,
      "loss": 0.9357,
      "step": 6570
    },
    {
      "epoch": 35.19,
      "grad_norm": 0.8536981344223022,
      "learning_rate": 4.527323673915656e-05,
      "loss": 0.8523,
      "step": 6580
    },
    {
      "epoch": 35.24,
      "grad_norm": 0.7765238881111145,
      "learning_rate": 4.5226299901844234e-05,
      "loss": 0.9132,
      "step": 6590
    },
    {
      "epoch": 35.29,
      "grad_norm": 0.7337812185287476,
      "learning_rate": 4.517932361801683e-05,
      "loss": 0.9126,
      "step": 6600
    },
    {
      "epoch": 35.35,
      "grad_norm": 0.8196563124656677,
      "learning_rate": 4.513230802025955e-05,
      "loss": 0.9961,
      "step": 6610
    },
    {
      "epoch": 35.4,
      "grad_norm": 0.8968552947044373,
      "learning_rate": 4.508525324126857e-05,
      "loss": 0.9318,
      "step": 6620
    },
    {
      "epoch": 35.45,
      "grad_norm": 1.3106324672698975,
      "learning_rate": 4.503815941385066e-05,
      "loss": 0.8772,
      "step": 6630
    },
    {
      "epoch": 35.51,
      "grad_norm": 1.094473958015442,
      "learning_rate": 4.499102667092278e-05,
      "loss": 0.9218,
      "step": 6640
    },
    {
      "epoch": 35.56,
      "grad_norm": 1.4284297227859497,
      "learning_rate": 4.4943855145511734e-05,
      "loss": 0.9579,
      "step": 6650
    },
    {
      "epoch": 35.61,
      "grad_norm": 1.2332403659820557,
      "learning_rate": 4.489664497075376e-05,
      "loss": 0.8743,
      "step": 6660
    },
    {
      "epoch": 35.67,
      "grad_norm": 1.1300748586654663,
      "learning_rate": 4.484939627989421e-05,
      "loss": 0.9131,
      "step": 6670
    },
    {
      "epoch": 35.72,
      "grad_norm": 1.0094852447509766,
      "learning_rate": 4.480210920628715e-05,
      "loss": 0.8221,
      "step": 6680
    },
    {
      "epoch": 35.78,
      "grad_norm": 1.2485437393188477,
      "learning_rate": 4.475478388339495e-05,
      "loss": 0.9616,
      "step": 6690
    },
    {
      "epoch": 35.83,
      "grad_norm": 1.055065393447876,
      "learning_rate": 4.4707420444787944e-05,
      "loss": 0.9036,
      "step": 6700
    },
    {
      "epoch": 35.88,
      "grad_norm": 0.939542829990387,
      "learning_rate": 4.466001902414404e-05,
      "loss": 0.9644,
      "step": 6710
    },
    {
      "epoch": 35.94,
      "grad_norm": 0.8844242691993713,
      "learning_rate": 4.461257975524835e-05,
      "loss": 1.0393,
      "step": 6720
    },
    {
      "epoch": 35.99,
      "grad_norm": 0.7100968360900879,
      "learning_rate": 4.456510277199282e-05,
      "loss": 0.8893,
      "step": 6730
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4203602075576782,
      "eval_runtime": 1.2372,
      "eval_samples_per_second": 26.672,
      "eval_steps_per_second": 2.425,
      "step": 6732
    },
    {
      "epoch": 36.04,
      "grad_norm": 1.322240948677063,
      "learning_rate": 4.451758820837583e-05,
      "loss": 0.7989,
      "step": 6740
    },
    {
      "epoch": 36.1,
      "grad_norm": 0.7436256408691406,
      "learning_rate": 4.447003619850181e-05,
      "loss": 0.9289,
      "step": 6750
    },
    {
      "epoch": 36.15,
      "grad_norm": 0.810080885887146,
      "learning_rate": 4.442244687658091e-05,
      "loss": 0.8808,
      "step": 6760
    },
    {
      "epoch": 36.2,
      "grad_norm": 1.5140410661697388,
      "learning_rate": 4.437482037692856e-05,
      "loss": 0.9056,
      "step": 6770
    },
    {
      "epoch": 36.26,
      "grad_norm": 0.7494302988052368,
      "learning_rate": 4.4327156833965144e-05,
      "loss": 0.93,
      "step": 6780
    },
    {
      "epoch": 36.31,
      "grad_norm": 1.2963460683822632,
      "learning_rate": 4.4279456382215576e-05,
      "loss": 0.9703,
      "step": 6790
    },
    {
      "epoch": 36.36,
      "grad_norm": 1.1907261610031128,
      "learning_rate": 4.423171915630896e-05,
      "loss": 0.9358,
      "step": 6800
    },
    {
      "epoch": 36.42,
      "grad_norm": 1.4857852458953857,
      "learning_rate": 4.418394529097816e-05,
      "loss": 0.9607,
      "step": 6810
    },
    {
      "epoch": 36.47,
      "grad_norm": 0.8952710032463074,
      "learning_rate": 4.4136134921059485e-05,
      "loss": 0.905,
      "step": 6820
    },
    {
      "epoch": 36.52,
      "grad_norm": 0.9918977618217468,
      "learning_rate": 4.408828818149227e-05,
      "loss": 0.9184,
      "step": 6830
    },
    {
      "epoch": 36.58,
      "grad_norm": 1.8249207735061646,
      "learning_rate": 4.404040520731847e-05,
      "loss": 0.9844,
      "step": 6840
    },
    {
      "epoch": 36.63,
      "grad_norm": 1.1289832592010498,
      "learning_rate": 4.3992486133682336e-05,
      "loss": 1.0019,
      "step": 6850
    },
    {
      "epoch": 36.68,
      "grad_norm": 0.9615403413772583,
      "learning_rate": 4.394453109583e-05,
      "loss": 0.8394,
      "step": 6860
    },
    {
      "epoch": 36.74,
      "grad_norm": 0.5731536149978638,
      "learning_rate": 4.389654022910909e-05,
      "loss": 0.9215,
      "step": 6870
    },
    {
      "epoch": 36.79,
      "grad_norm": 0.7853761911392212,
      "learning_rate": 4.384851366896837e-05,
      "loss": 0.9251,
      "step": 6880
    },
    {
      "epoch": 36.84,
      "grad_norm": 1.4708000421524048,
      "learning_rate": 4.3800451550957325e-05,
      "loss": 0.9801,
      "step": 6890
    },
    {
      "epoch": 36.9,
      "grad_norm": 1.7773960828781128,
      "learning_rate": 4.375235401072583e-05,
      "loss": 0.9028,
      "step": 6900
    },
    {
      "epoch": 36.95,
      "grad_norm": 0.9179329872131348,
      "learning_rate": 4.37042211840237e-05,
      "loss": 1.0019,
      "step": 6910
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.4672410488128662,
      "eval_runtime": 1.1525,
      "eval_samples_per_second": 28.633,
      "eval_steps_per_second": 2.603,
      "step": 6919
    },
    {
      "epoch": 37.01,
      "grad_norm": 0.7560046315193176,
      "learning_rate": 4.365605320670037e-05,
      "loss": 0.9236,
      "step": 6920
    },
    {
      "epoch": 37.06,
      "grad_norm": 0.9032727479934692,
      "learning_rate": 4.360785021470445e-05,
      "loss": 0.9026,
      "step": 6930
    },
    {
      "epoch": 37.11,
      "grad_norm": 1.11763596534729,
      "learning_rate": 4.3559612344083426e-05,
      "loss": 0.8642,
      "step": 6940
    },
    {
      "epoch": 37.17,
      "grad_norm": 0.9591771364212036,
      "learning_rate": 4.351133973098318e-05,
      "loss": 0.9544,
      "step": 6950
    },
    {
      "epoch": 37.22,
      "grad_norm": 1.034158706665039,
      "learning_rate": 4.346303251164765e-05,
      "loss": 0.9295,
      "step": 6960
    },
    {
      "epoch": 37.27,
      "grad_norm": 1.0224156379699707,
      "learning_rate": 4.341469082241849e-05,
      "loss": 0.9295,
      "step": 6970
    },
    {
      "epoch": 37.33,
      "grad_norm": 1.256533145904541,
      "learning_rate": 4.33663147997346e-05,
      "loss": 1.0803,
      "step": 6980
    },
    {
      "epoch": 37.38,
      "grad_norm": 1.5866117477416992,
      "learning_rate": 4.3317904580131786e-05,
      "loss": 0.8936,
      "step": 6990
    },
    {
      "epoch": 37.43,
      "grad_norm": 1.2743606567382812,
      "learning_rate": 4.3269460300242395e-05,
      "loss": 0.9615,
      "step": 7000
    },
    {
      "epoch": 37.49,
      "grad_norm": 1.3625104427337646,
      "learning_rate": 4.3220982096794896e-05,
      "loss": 0.9221,
      "step": 7010
    },
    {
      "epoch": 37.54,
      "grad_norm": 1.1530202627182007,
      "learning_rate": 4.317247010661349e-05,
      "loss": 0.9745,
      "step": 7020
    },
    {
      "epoch": 37.59,
      "grad_norm": 0.8132659792900085,
      "learning_rate": 4.3123924466617746e-05,
      "loss": 0.8664,
      "step": 7030
    },
    {
      "epoch": 37.65,
      "grad_norm": 1.3186194896697998,
      "learning_rate": 4.30753453138222e-05,
      "loss": 0.8512,
      "step": 7040
    },
    {
      "epoch": 37.7,
      "grad_norm": 0.8042386770248413,
      "learning_rate": 4.302673278533598e-05,
      "loss": 0.9365,
      "step": 7050
    },
    {
      "epoch": 37.75,
      "grad_norm": 1.1567225456237793,
      "learning_rate": 4.297808701836242e-05,
      "loss": 0.9537,
      "step": 7060
    },
    {
      "epoch": 37.81,
      "grad_norm": 0.8311055302619934,
      "learning_rate": 4.2929408150198665e-05,
      "loss": 0.9226,
      "step": 7070
    },
    {
      "epoch": 37.86,
      "grad_norm": 0.8232475519180298,
      "learning_rate": 4.288069631823526e-05,
      "loss": 0.965,
      "step": 7080
    },
    {
      "epoch": 37.91,
      "grad_norm": 1.2399332523345947,
      "learning_rate": 4.2831951659955806e-05,
      "loss": 0.9614,
      "step": 7090
    },
    {
      "epoch": 37.97,
      "grad_norm": 0.8902685046195984,
      "learning_rate": 4.278317431293657e-05,
      "loss": 0.9271,
      "step": 7100
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.467477560043335,
      "eval_runtime": 1.1444,
      "eval_samples_per_second": 28.836,
      "eval_steps_per_second": 2.621,
      "step": 7106
    },
    {
      "epoch": 38.02,
      "grad_norm": 0.8167108297348022,
      "learning_rate": 4.273436441484603e-05,
      "loss": 0.8951,
      "step": 7110
    },
    {
      "epoch": 38.07,
      "grad_norm": 0.9405921697616577,
      "learning_rate": 4.268552210344459e-05,
      "loss": 0.9354,
      "step": 7120
    },
    {
      "epoch": 38.13,
      "grad_norm": 0.7870425581932068,
      "learning_rate": 4.263664751658411e-05,
      "loss": 0.983,
      "step": 7130
    },
    {
      "epoch": 38.18,
      "grad_norm": 1.3015779256820679,
      "learning_rate": 4.258774079220753e-05,
      "loss": 0.9697,
      "step": 7140
    },
    {
      "epoch": 38.24,
      "grad_norm": 1.0313888788223267,
      "learning_rate": 4.253880206834854e-05,
      "loss": 0.8443,
      "step": 7150
    },
    {
      "epoch": 38.29,
      "grad_norm": 0.9618089199066162,
      "learning_rate": 4.248983148313108e-05,
      "loss": 0.9301,
      "step": 7160
    },
    {
      "epoch": 38.34,
      "grad_norm": 1.2008819580078125,
      "learning_rate": 4.2440829174769075e-05,
      "loss": 1.0147,
      "step": 7170
    },
    {
      "epoch": 38.4,
      "grad_norm": 1.1835304498672485,
      "learning_rate": 4.2391795281565945e-05,
      "loss": 0.8809,
      "step": 7180
    },
    {
      "epoch": 38.45,
      "grad_norm": 0.8944228291511536,
      "learning_rate": 4.2342729941914295e-05,
      "loss": 0.9189,
      "step": 7190
    },
    {
      "epoch": 38.5,
      "grad_norm": 1.0218974351882935,
      "learning_rate": 4.229363329429544e-05,
      "loss": 0.8559,
      "step": 7200
    },
    {
      "epoch": 38.56,
      "grad_norm": 1.1303447484970093,
      "learning_rate": 4.224450547727908e-05,
      "loss": 0.8925,
      "step": 7210
    },
    {
      "epoch": 38.61,
      "grad_norm": 0.9582884907722473,
      "learning_rate": 4.219534662952288e-05,
      "loss": 0.9275,
      "step": 7220
    },
    {
      "epoch": 38.66,
      "grad_norm": 0.9950461387634277,
      "learning_rate": 4.21461568897721e-05,
      "loss": 0.9859,
      "step": 7230
    },
    {
      "epoch": 38.72,
      "grad_norm": 1.0269533395767212,
      "learning_rate": 4.209693639685918e-05,
      "loss": 1.026,
      "step": 7240
    },
    {
      "epoch": 38.77,
      "grad_norm": 1.2560924291610718,
      "learning_rate": 4.2047685289703347e-05,
      "loss": 0.9551,
      "step": 7250
    },
    {
      "epoch": 38.82,
      "grad_norm": 1.168607234954834,
      "learning_rate": 4.199840370731026e-05,
      "loss": 0.8444,
      "step": 7260
    },
    {
      "epoch": 38.88,
      "grad_norm": 0.8950477838516235,
      "learning_rate": 4.194909178877155e-05,
      "loss": 0.9456,
      "step": 7270
    },
    {
      "epoch": 38.93,
      "grad_norm": 0.8620461225509644,
      "learning_rate": 4.189974967326451e-05,
      "loss": 0.9549,
      "step": 7280
    },
    {
      "epoch": 38.98,
      "grad_norm": 1.3448514938354492,
      "learning_rate": 4.185037750005164e-05,
      "loss": 0.9668,
      "step": 7290
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4364060163497925,
      "eval_runtime": 2.6131,
      "eval_samples_per_second": 12.629,
      "eval_steps_per_second": 1.148,
      "step": 7293
    },
    {
      "epoch": 39.04,
      "grad_norm": 0.8579457402229309,
      "learning_rate": 4.180097540848028e-05,
      "loss": 0.9246,
      "step": 7300
    },
    {
      "epoch": 39.09,
      "grad_norm": 1.2595115900039673,
      "learning_rate": 4.175154353798219e-05,
      "loss": 0.9779,
      "step": 7310
    },
    {
      "epoch": 39.14,
      "grad_norm": 0.8404684066772461,
      "learning_rate": 4.1702082028073226e-05,
      "loss": 0.8977,
      "step": 7320
    },
    {
      "epoch": 39.2,
      "grad_norm": 0.7714629769325256,
      "learning_rate": 4.1652591018352836e-05,
      "loss": 0.9588,
      "step": 7330
    },
    {
      "epoch": 39.25,
      "grad_norm": 1.4690933227539062,
      "learning_rate": 4.1603070648503786e-05,
      "loss": 0.7911,
      "step": 7340
    },
    {
      "epoch": 39.3,
      "grad_norm": 1.2718762159347534,
      "learning_rate": 4.155352105829166e-05,
      "loss": 0.9278,
      "step": 7350
    },
    {
      "epoch": 39.36,
      "grad_norm": 0.8921736478805542,
      "learning_rate": 4.1503942387564556e-05,
      "loss": 1.073,
      "step": 7360
    },
    {
      "epoch": 39.41,
      "grad_norm": 1.4466313123703003,
      "learning_rate": 4.14543347762526e-05,
      "loss": 0.9689,
      "step": 7370
    },
    {
      "epoch": 39.47,
      "grad_norm": 1.0749155282974243,
      "learning_rate": 4.140469836436765e-05,
      "loss": 0.9686,
      "step": 7380
    },
    {
      "epoch": 39.52,
      "grad_norm": 1.0122419595718384,
      "learning_rate": 4.135503329200283e-05,
      "loss": 0.9707,
      "step": 7390
    },
    {
      "epoch": 39.57,
      "grad_norm": 1.0133459568023682,
      "learning_rate": 4.1305339699332125e-05,
      "loss": 0.891,
      "step": 7400
    },
    {
      "epoch": 39.63,
      "grad_norm": 0.9346213936805725,
      "learning_rate": 4.1255617726610075e-05,
      "loss": 0.9393,
      "step": 7410
    },
    {
      "epoch": 39.68,
      "grad_norm": 0.8965733051300049,
      "learning_rate": 4.1205867514171247e-05,
      "loss": 0.9398,
      "step": 7420
    },
    {
      "epoch": 39.73,
      "grad_norm": 1.8717275857925415,
      "learning_rate": 4.1156089202429985e-05,
      "loss": 0.8679,
      "step": 7430
    },
    {
      "epoch": 39.79,
      "grad_norm": 1.1846429109573364,
      "learning_rate": 4.110628293187989e-05,
      "loss": 0.8643,
      "step": 7440
    },
    {
      "epoch": 39.84,
      "grad_norm": 1.166983962059021,
      "learning_rate": 4.1056448843093506e-05,
      "loss": 0.9367,
      "step": 7450
    },
    {
      "epoch": 39.89,
      "grad_norm": 1.0624735355377197,
      "learning_rate": 4.100658707672185e-05,
      "loss": 1.0887,
      "step": 7460
    },
    {
      "epoch": 39.95,
      "grad_norm": 1.5566792488098145,
      "learning_rate": 4.095669777349409e-05,
      "loss": 0.9762,
      "step": 7470
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.738002300262451,
      "learning_rate": 4.090678107421711e-05,
      "loss": 0.902,
      "step": 7480
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4213443994522095,
      "eval_runtime": 1.408,
      "eval_samples_per_second": 23.437,
      "eval_steps_per_second": 2.131,
      "step": 7480
    },
    {
      "epoch": 40.05,
      "grad_norm": 1.1186888217926025,
      "learning_rate": 4.08568371197751e-05,
      "loss": 0.8906,
      "step": 7490
    },
    {
      "epoch": 40.11,
      "grad_norm": 1.208969235420227,
      "learning_rate": 4.0806866051129197e-05,
      "loss": 0.9111,
      "step": 7500
    },
    {
      "epoch": 40.16,
      "grad_norm": 1.0661808252334595,
      "learning_rate": 4.0756868009317046e-05,
      "loss": 0.9277,
      "step": 7510
    },
    {
      "epoch": 40.21,
      "grad_norm": 0.8310621380805969,
      "learning_rate": 4.070684313545242e-05,
      "loss": 0.9378,
      "step": 7520
    },
    {
      "epoch": 40.27,
      "grad_norm": 1.5173169374465942,
      "learning_rate": 4.065679157072484e-05,
      "loss": 0.9905,
      "step": 7530
    },
    {
      "epoch": 40.32,
      "grad_norm": 0.8375676274299622,
      "learning_rate": 4.060671345639915e-05,
      "loss": 0.9296,
      "step": 7540
    },
    {
      "epoch": 40.37,
      "grad_norm": 1.1841962337493896,
      "learning_rate": 4.055660893381511e-05,
      "loss": 0.8766,
      "step": 7550
    },
    {
      "epoch": 40.43,
      "grad_norm": 0.9782437086105347,
      "learning_rate": 4.050647814438704e-05,
      "loss": 1.0392,
      "step": 7560
    },
    {
      "epoch": 40.48,
      "grad_norm": 1.0697059631347656,
      "learning_rate": 4.0456321229603397e-05,
      "loss": 1.0764,
      "step": 7570
    },
    {
      "epoch": 40.53,
      "grad_norm": 0.8175973296165466,
      "learning_rate": 4.040613833102634e-05,
      "loss": 0.9227,
      "step": 7580
    },
    {
      "epoch": 40.59,
      "grad_norm": 0.995000958442688,
      "learning_rate": 4.0355929590291396e-05,
      "loss": 0.9905,
      "step": 7590
    },
    {
      "epoch": 40.64,
      "grad_norm": 1.6505059003829956,
      "learning_rate": 4.030569514910702e-05,
      "loss": 0.954,
      "step": 7600
    },
    {
      "epoch": 40.7,
      "grad_norm": 1.182518720626831,
      "learning_rate": 4.025543514925421e-05,
      "loss": 0.8591,
      "step": 7610
    },
    {
      "epoch": 40.75,
      "grad_norm": 1.8284214735031128,
      "learning_rate": 4.020514973258607e-05,
      "loss": 0.924,
      "step": 7620
    },
    {
      "epoch": 40.8,
      "grad_norm": 0.8065454363822937,
      "learning_rate": 4.015483904102749e-05,
      "loss": 0.9076,
      "step": 7630
    },
    {
      "epoch": 40.86,
      "grad_norm": 0.7880685925483704,
      "learning_rate": 4.010450321657464e-05,
      "loss": 0.9885,
      "step": 7640
    },
    {
      "epoch": 40.91,
      "grad_norm": 2.116898536682129,
      "learning_rate": 4.005414240129468e-05,
      "loss": 0.8939,
      "step": 7650
    },
    {
      "epoch": 40.96,
      "grad_norm": 0.8423213362693787,
      "learning_rate": 4.0003756737325265e-05,
      "loss": 0.9056,
      "step": 7660
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.46146559715271,
      "eval_runtime": 1.4669,
      "eval_samples_per_second": 22.496,
      "eval_steps_per_second": 2.045,
      "step": 7667
    },
    {
      "epoch": 41.02,
      "grad_norm": 0.8321268558502197,
      "learning_rate": 3.995334636687418e-05,
      "loss": 0.889,
      "step": 7670
    },
    {
      "epoch": 41.07,
      "grad_norm": 1.0777631998062134,
      "learning_rate": 3.990291143221899e-05,
      "loss": 0.8342,
      "step": 7680
    },
    {
      "epoch": 41.12,
      "grad_norm": 0.7171064615249634,
      "learning_rate": 3.985245207570653e-05,
      "loss": 1.0052,
      "step": 7690
    },
    {
      "epoch": 41.18,
      "grad_norm": 1.103753924369812,
      "learning_rate": 3.98019684397526e-05,
      "loss": 1.0103,
      "step": 7700
    },
    {
      "epoch": 41.23,
      "grad_norm": 1.0437124967575073,
      "learning_rate": 3.975146066684149e-05,
      "loss": 0.9321,
      "step": 7710
    },
    {
      "epoch": 41.28,
      "grad_norm": 1.0694353580474854,
      "learning_rate": 3.9700928899525674e-05,
      "loss": 0.9903,
      "step": 7720
    },
    {
      "epoch": 41.34,
      "grad_norm": 0.946567952632904,
      "learning_rate": 3.965037328042528e-05,
      "loss": 0.958,
      "step": 7730
    },
    {
      "epoch": 41.39,
      "grad_norm": 0.8662450909614563,
      "learning_rate": 3.9599793952227806e-05,
      "loss": 0.898,
      "step": 7740
    },
    {
      "epoch": 41.44,
      "grad_norm": 1.0905569791793823,
      "learning_rate": 3.954919105768764e-05,
      "loss": 0.9236,
      "step": 7750
    },
    {
      "epoch": 41.5,
      "grad_norm": 0.8522189855575562,
      "learning_rate": 3.9498564739625696e-05,
      "loss": 0.9804,
      "step": 7760
    },
    {
      "epoch": 41.55,
      "grad_norm": 0.8782164454460144,
      "learning_rate": 3.9447915140928976e-05,
      "loss": 0.8328,
      "step": 7770
    },
    {
      "epoch": 41.6,
      "grad_norm": 0.7541294097900391,
      "learning_rate": 3.9397242404550225e-05,
      "loss": 0.9417,
      "step": 7780
    },
    {
      "epoch": 41.66,
      "grad_norm": 1.69646155834198,
      "learning_rate": 3.9346546673507466e-05,
      "loss": 0.9295,
      "step": 7790
    },
    {
      "epoch": 41.71,
      "grad_norm": 1.1449627876281738,
      "learning_rate": 3.929582809088362e-05,
      "loss": 0.8672,
      "step": 7800
    },
    {
      "epoch": 41.76,
      "grad_norm": 1.1521729230880737,
      "learning_rate": 3.924508679982612e-05,
      "loss": 0.9302,
      "step": 7810
    },
    {
      "epoch": 41.82,
      "grad_norm": 0.9107154011726379,
      "learning_rate": 3.9194322943546475e-05,
      "loss": 0.9047,
      "step": 7820
    },
    {
      "epoch": 41.87,
      "grad_norm": 1.386824607849121,
      "learning_rate": 3.914353666531989e-05,
      "loss": 0.8301,
      "step": 7830
    },
    {
      "epoch": 41.93,
      "grad_norm": 1.341248631477356,
      "learning_rate": 3.909272810848485e-05,
      "loss": 1.0114,
      "step": 7840
    },
    {
      "epoch": 41.98,
      "grad_norm": 1.009785771369934,
      "learning_rate": 3.9041897416442734e-05,
      "loss": 0.9078,
      "step": 7850
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.436354398727417,
      "eval_runtime": 1.3431,
      "eval_samples_per_second": 24.57,
      "eval_steps_per_second": 2.234,
      "step": 7854
    },
    {
      "epoch": 42.03,
      "grad_norm": 0.8711077570915222,
      "learning_rate": 3.899104473265738e-05,
      "loss": 0.8912,
      "step": 7860
    },
    {
      "epoch": 42.09,
      "grad_norm": 1.120666742324829,
      "learning_rate": 3.894017020065468e-05,
      "loss": 0.9199,
      "step": 7870
    },
    {
      "epoch": 42.14,
      "grad_norm": 0.9791567921638489,
      "learning_rate": 3.8889273964022224e-05,
      "loss": 0.8905,
      "step": 7880
    },
    {
      "epoch": 42.19,
      "grad_norm": 1.0919153690338135,
      "learning_rate": 3.883835616640884e-05,
      "loss": 0.9912,
      "step": 7890
    },
    {
      "epoch": 42.25,
      "grad_norm": 0.7074032425880432,
      "learning_rate": 3.878741695152422e-05,
      "loss": 0.8185,
      "step": 7900
    },
    {
      "epoch": 42.3,
      "grad_norm": 1.011152982711792,
      "learning_rate": 3.87364564631385e-05,
      "loss": 0.8248,
      "step": 7910
    },
    {
      "epoch": 42.35,
      "grad_norm": 0.9964146018028259,
      "learning_rate": 3.8685474845081834e-05,
      "loss": 1.0106,
      "step": 7920
    },
    {
      "epoch": 42.41,
      "grad_norm": 0.8249213695526123,
      "learning_rate": 3.863447224124406e-05,
      "loss": 0.9495,
      "step": 7930
    },
    {
      "epoch": 42.46,
      "grad_norm": 0.9472766518592834,
      "learning_rate": 3.8583448795574203e-05,
      "loss": 0.9251,
      "step": 7940
    },
    {
      "epoch": 42.51,
      "grad_norm": 1.1087802648544312,
      "learning_rate": 3.8532404652080144e-05,
      "loss": 0.8563,
      "step": 7950
    },
    {
      "epoch": 42.57,
      "grad_norm": 0.9094424247741699,
      "learning_rate": 3.848133995482815e-05,
      "loss": 0.9156,
      "step": 7960
    },
    {
      "epoch": 42.62,
      "grad_norm": 1.146041989326477,
      "learning_rate": 3.843025484794252e-05,
      "loss": 0.9906,
      "step": 7970
    },
    {
      "epoch": 42.67,
      "grad_norm": 0.7619853615760803,
      "learning_rate": 3.8379149475605145e-05,
      "loss": 0.9047,
      "step": 7980
    },
    {
      "epoch": 42.73,
      "grad_norm": 0.9343012571334839,
      "learning_rate": 3.832802398205514e-05,
      "loss": 0.8809,
      "step": 7990
    },
    {
      "epoch": 42.78,
      "grad_norm": 0.6515477299690247,
      "learning_rate": 3.827687851158837e-05,
      "loss": 0.8572,
      "step": 8000
    },
    {
      "epoch": 42.83,
      "grad_norm": 0.8693698644638062,
      "learning_rate": 3.822571320855711e-05,
      "loss": 1.0437,
      "step": 8010
    },
    {
      "epoch": 42.89,
      "grad_norm": 0.9688628911972046,
      "learning_rate": 3.8174528217369595e-05,
      "loss": 0.9395,
      "step": 8020
    },
    {
      "epoch": 42.94,
      "grad_norm": 1.5036299228668213,
      "learning_rate": 3.812332368248965e-05,
      "loss": 0.8901,
      "step": 8030
    },
    {
      "epoch": 42.99,
      "grad_norm": 1.4594969749450684,
      "learning_rate": 3.807209974843622e-05,
      "loss": 0.9908,
      "step": 8040
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4557889699935913,
      "eval_runtime": 1.1763,
      "eval_samples_per_second": 28.055,
      "eval_steps_per_second": 2.55,
      "step": 8041
    },
    {
      "epoch": 43.05,
      "grad_norm": 1.0012415647506714,
      "learning_rate": 3.8020856559783055e-05,
      "loss": 1.0922,
      "step": 8050
    },
    {
      "epoch": 43.1,
      "grad_norm": 1.2418323755264282,
      "learning_rate": 3.796959426115819e-05,
      "loss": 0.921,
      "step": 8060
    },
    {
      "epoch": 43.16,
      "grad_norm": 0.9240189790725708,
      "learning_rate": 3.7918312997243655e-05,
      "loss": 0.9035,
      "step": 8070
    },
    {
      "epoch": 43.21,
      "grad_norm": 1.1771827936172485,
      "learning_rate": 3.786701291277496e-05,
      "loss": 0.9241,
      "step": 8080
    },
    {
      "epoch": 43.26,
      "grad_norm": 1.4129704236984253,
      "learning_rate": 3.7815694152540755e-05,
      "loss": 0.9217,
      "step": 8090
    },
    {
      "epoch": 43.32,
      "grad_norm": 0.9978371858596802,
      "learning_rate": 3.77643568613824e-05,
      "loss": 1.0255,
      "step": 8100
    },
    {
      "epoch": 43.37,
      "grad_norm": 0.8626393675804138,
      "learning_rate": 3.771300118419355e-05,
      "loss": 0.9418,
      "step": 8110
    },
    {
      "epoch": 43.42,
      "grad_norm": 1.0021581649780273,
      "learning_rate": 3.7661627265919766e-05,
      "loss": 0.8884,
      "step": 8120
    },
    {
      "epoch": 43.48,
      "grad_norm": 1.2056913375854492,
      "learning_rate": 3.761023525155807e-05,
      "loss": 0.9832,
      "step": 8130
    },
    {
      "epoch": 43.53,
      "grad_norm": 1.338240623474121,
      "learning_rate": 3.755882528615657e-05,
      "loss": 0.904,
      "step": 8140
    },
    {
      "epoch": 43.58,
      "grad_norm": 0.6762505769729614,
      "learning_rate": 3.750739751481405e-05,
      "loss": 0.9639,
      "step": 8150
    },
    {
      "epoch": 43.64,
      "grad_norm": 1.389841079711914,
      "learning_rate": 3.745595208267955e-05,
      "loss": 0.8734,
      "step": 8160
    },
    {
      "epoch": 43.69,
      "grad_norm": 1.1945713758468628,
      "learning_rate": 3.740448913495192e-05,
      "loss": 0.8961,
      "step": 8170
    },
    {
      "epoch": 43.74,
      "grad_norm": 1.1864643096923828,
      "learning_rate": 3.735300881687948e-05,
      "loss": 0.9472,
      "step": 8180
    },
    {
      "epoch": 43.8,
      "grad_norm": 1.6455178260803223,
      "learning_rate": 3.730151127375956e-05,
      "loss": 0.9843,
      "step": 8190
    },
    {
      "epoch": 43.85,
      "grad_norm": 1.1036031246185303,
      "learning_rate": 3.724999665093813e-05,
      "loss": 0.9422,
      "step": 8200
    },
    {
      "epoch": 43.9,
      "grad_norm": 1.0557705163955688,
      "learning_rate": 3.719846509380933e-05,
      "loss": 0.9399,
      "step": 8210
    },
    {
      "epoch": 43.96,
      "grad_norm": 1.211921215057373,
      "learning_rate": 3.714691674781511e-05,
      "loss": 0.8961,
      "step": 8220
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.36363636363636365,
      "eval_loss": 1.4362515211105347,
      "eval_runtime": 1.1854,
      "eval_samples_per_second": 27.839,
      "eval_steps_per_second": 2.531,
      "step": 8228
    },
    {
      "epoch": 44.01,
      "grad_norm": 0.8038492202758789,
      "learning_rate": 3.709535175844482e-05,
      "loss": 0.8536,
      "step": 8230
    },
    {
      "epoch": 44.06,
      "grad_norm": 0.7614076137542725,
      "learning_rate": 3.704377027123477e-05,
      "loss": 0.8804,
      "step": 8240
    },
    {
      "epoch": 44.12,
      "grad_norm": 1.0634069442749023,
      "learning_rate": 3.6992172431767826e-05,
      "loss": 0.8389,
      "step": 8250
    },
    {
      "epoch": 44.17,
      "grad_norm": 0.917574942111969,
      "learning_rate": 3.694055838567302e-05,
      "loss": 0.8966,
      "step": 8260
    },
    {
      "epoch": 44.22,
      "grad_norm": 0.8914284110069275,
      "learning_rate": 3.688892827862511e-05,
      "loss": 0.9263,
      "step": 8270
    },
    {
      "epoch": 44.28,
      "grad_norm": 1.0905712842941284,
      "learning_rate": 3.683728225634421e-05,
      "loss": 0.8757,
      "step": 8280
    },
    {
      "epoch": 44.33,
      "grad_norm": 1.149033784866333,
      "learning_rate": 3.678562046459534e-05,
      "loss": 1.0713,
      "step": 8290
    },
    {
      "epoch": 44.39,
      "grad_norm": 1.62887442111969,
      "learning_rate": 3.6733943049188005e-05,
      "loss": 0.9348,
      "step": 8300
    },
    {
      "epoch": 44.44,
      "grad_norm": 0.9522219300270081,
      "learning_rate": 3.6682250155975834e-05,
      "loss": 0.9327,
      "step": 8310
    },
    {
      "epoch": 44.49,
      "grad_norm": 0.7872262001037598,
      "learning_rate": 3.663054193085614e-05,
      "loss": 0.8605,
      "step": 8320
    },
    {
      "epoch": 44.55,
      "grad_norm": 0.9040985107421875,
      "learning_rate": 3.6578818519769495e-05,
      "loss": 0.936,
      "step": 8330
    },
    {
      "epoch": 44.6,
      "grad_norm": 0.8254292607307434,
      "learning_rate": 3.6527080068699336e-05,
      "loss": 0.9066,
      "step": 8340
    },
    {
      "epoch": 44.65,
      "grad_norm": 0.7347627878189087,
      "learning_rate": 3.647532672367155e-05,
      "loss": 0.8644,
      "step": 8350
    },
    {
      "epoch": 44.71,
      "grad_norm": 1.473123550415039,
      "learning_rate": 3.642355863075406e-05,
      "loss": 0.9557,
      "step": 8360
    },
    {
      "epoch": 44.76,
      "grad_norm": 1.0563318729400635,
      "learning_rate": 3.637177593605643e-05,
      "loss": 0.9373,
      "step": 8370
    },
    {
      "epoch": 44.81,
      "grad_norm": 0.9448814392089844,
      "learning_rate": 3.631997878572939e-05,
      "loss": 0.947,
      "step": 8380
    },
    {
      "epoch": 44.87,
      "grad_norm": 1.712670922279358,
      "learning_rate": 3.626816732596452e-05,
      "loss": 1.0488,
      "step": 8390
    },
    {
      "epoch": 44.92,
      "grad_norm": 1.0158028602600098,
      "learning_rate": 3.621634170299375e-05,
      "loss": 0.9606,
      "step": 8400
    },
    {
      "epoch": 44.97,
      "grad_norm": 0.7918938398361206,
      "learning_rate": 3.616450206308902e-05,
      "loss": 0.8811,
      "step": 8410
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.413500189781189,
      "eval_runtime": 1.1737,
      "eval_samples_per_second": 28.117,
      "eval_steps_per_second": 2.556,
      "step": 8415
    },
    {
      "epoch": 45.03,
      "grad_norm": 0.8792471885681152,
      "learning_rate": 3.61126485525618e-05,
      "loss": 0.9415,
      "step": 8420
    },
    {
      "epoch": 45.08,
      "grad_norm": 1.1659479141235352,
      "learning_rate": 3.6060781317762716e-05,
      "loss": 0.9039,
      "step": 8430
    },
    {
      "epoch": 45.13,
      "grad_norm": 1.5890952348709106,
      "learning_rate": 3.600890050508113e-05,
      "loss": 0.9333,
      "step": 8440
    },
    {
      "epoch": 45.19,
      "grad_norm": 0.8710546493530273,
      "learning_rate": 3.5957006260944754e-05,
      "loss": 0.9089,
      "step": 8450
    },
    {
      "epoch": 45.24,
      "grad_norm": 1.6147397756576538,
      "learning_rate": 3.590509873181915e-05,
      "loss": 0.8372,
      "step": 8460
    },
    {
      "epoch": 45.29,
      "grad_norm": 0.9571077227592468,
      "learning_rate": 3.5853178064207426e-05,
      "loss": 0.9011,
      "step": 8470
    },
    {
      "epoch": 45.35,
      "grad_norm": 0.9925188422203064,
      "learning_rate": 3.580124440464975e-05,
      "loss": 0.9835,
      "step": 8480
    },
    {
      "epoch": 45.4,
      "grad_norm": 0.6650118231773376,
      "learning_rate": 3.574929789972296e-05,
      "loss": 0.9982,
      "step": 8490
    },
    {
      "epoch": 45.45,
      "grad_norm": 0.92352694272995,
      "learning_rate": 3.569733869604017e-05,
      "loss": 0.9731,
      "step": 8500
    },
    {
      "epoch": 45.51,
      "grad_norm": 0.9015805125236511,
      "learning_rate": 3.564536694025029e-05,
      "loss": 0.8193,
      "step": 8510
    },
    {
      "epoch": 45.56,
      "grad_norm": 1.2173861265182495,
      "learning_rate": 3.559338277903769e-05,
      "loss": 1.0309,
      "step": 8520
    },
    {
      "epoch": 45.61,
      "grad_norm": 1.2300890684127808,
      "learning_rate": 3.554138635912175e-05,
      "loss": 0.9014,
      "step": 8530
    },
    {
      "epoch": 45.67,
      "grad_norm": 1.5042455196380615,
      "learning_rate": 3.548937782725645e-05,
      "loss": 0.9512,
      "step": 8540
    },
    {
      "epoch": 45.72,
      "grad_norm": 0.7157743573188782,
      "learning_rate": 3.5437357330229946e-05,
      "loss": 1.0323,
      "step": 8550
    },
    {
      "epoch": 45.78,
      "grad_norm": 1.1638127565383911,
      "learning_rate": 3.5385325014864164e-05,
      "loss": 0.8763,
      "step": 8560
    },
    {
      "epoch": 45.83,
      "grad_norm": 1.1477335691452026,
      "learning_rate": 3.533328102801439e-05,
      "loss": 0.8703,
      "step": 8570
    },
    {
      "epoch": 45.88,
      "grad_norm": 1.3646525144577026,
      "learning_rate": 3.5281225516568856e-05,
      "loss": 0.968,
      "step": 8580
    },
    {
      "epoch": 45.94,
      "grad_norm": 1.5215425491333008,
      "learning_rate": 3.522915862744831e-05,
      "loss": 0.8864,
      "step": 8590
    },
    {
      "epoch": 45.99,
      "grad_norm": 0.9964292049407959,
      "learning_rate": 3.517708050760562e-05,
      "loss": 0.9152,
      "step": 8600
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4550294876098633,
      "eval_runtime": 1.1812,
      "eval_samples_per_second": 27.937,
      "eval_steps_per_second": 2.54,
      "step": 8602
    },
    {
      "epoch": 46.04,
      "grad_norm": 1.2689003944396973,
      "learning_rate": 3.512499130402534e-05,
      "loss": 0.9312,
      "step": 8610
    },
    {
      "epoch": 46.1,
      "grad_norm": 0.7834722399711609,
      "learning_rate": 3.507289116372334e-05,
      "loss": 0.8976,
      "step": 8620
    },
    {
      "epoch": 46.15,
      "grad_norm": 0.9697892665863037,
      "learning_rate": 3.502078023374632e-05,
      "loss": 0.9836,
      "step": 8630
    },
    {
      "epoch": 46.2,
      "grad_norm": 1.5300451517105103,
      "learning_rate": 3.4968658661171436e-05,
      "loss": 0.9494,
      "step": 8640
    },
    {
      "epoch": 46.26,
      "grad_norm": 1.20348060131073,
      "learning_rate": 3.49165265931059e-05,
      "loss": 0.9148,
      "step": 8650
    },
    {
      "epoch": 46.31,
      "grad_norm": 0.7531508207321167,
      "learning_rate": 3.486438417668655e-05,
      "loss": 0.896,
      "step": 8660
    },
    {
      "epoch": 46.36,
      "grad_norm": 0.9305780529975891,
      "learning_rate": 3.481223155907939e-05,
      "loss": 0.8549,
      "step": 8670
    },
    {
      "epoch": 46.42,
      "grad_norm": 0.9013834595680237,
      "learning_rate": 3.4760068887479284e-05,
      "loss": 0.8863,
      "step": 8680
    },
    {
      "epoch": 46.47,
      "grad_norm": 1.0133806467056274,
      "learning_rate": 3.47078963091094e-05,
      "loss": 1.0869,
      "step": 8690
    },
    {
      "epoch": 46.52,
      "grad_norm": 1.127368688583374,
      "learning_rate": 3.4655713971220916e-05,
      "loss": 0.9134,
      "step": 8700
    },
    {
      "epoch": 46.58,
      "grad_norm": 1.6530499458312988,
      "learning_rate": 3.4603522021092545e-05,
      "loss": 0.8618,
      "step": 8710
    },
    {
      "epoch": 46.63,
      "grad_norm": 0.9021478891372681,
      "learning_rate": 3.45513206060301e-05,
      "loss": 0.8626,
      "step": 8720
    },
    {
      "epoch": 46.68,
      "grad_norm": 0.8667493462562561,
      "learning_rate": 3.449910987336616e-05,
      "loss": 0.8665,
      "step": 8730
    },
    {
      "epoch": 46.74,
      "grad_norm": 0.7902733683586121,
      "learning_rate": 3.444688997045954e-05,
      "loss": 0.926,
      "step": 8740
    },
    {
      "epoch": 46.79,
      "grad_norm": 0.8101222515106201,
      "learning_rate": 3.4394661044695006e-05,
      "loss": 0.9793,
      "step": 8750
    },
    {
      "epoch": 46.84,
      "grad_norm": 0.9661953449249268,
      "learning_rate": 3.434242324348273e-05,
      "loss": 0.9157,
      "step": 8760
    },
    {
      "epoch": 46.9,
      "grad_norm": 1.200891137123108,
      "learning_rate": 3.4290176714257965e-05,
      "loss": 0.9868,
      "step": 8770
    },
    {
      "epoch": 46.95,
      "grad_norm": 1.2784241437911987,
      "learning_rate": 3.423792160448058e-05,
      "loss": 0.9714,
      "step": 8780
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4410457611083984,
      "eval_runtime": 1.2543,
      "eval_samples_per_second": 26.31,
      "eval_steps_per_second": 2.392,
      "step": 8789
    },
    {
      "epoch": 47.01,
      "grad_norm": 2.016975164413452,
      "learning_rate": 3.418565806163469e-05,
      "loss": 1.0567,
      "step": 8790
    },
    {
      "epoch": 47.06,
      "grad_norm": 1.064967155456543,
      "learning_rate": 3.413338623322819e-05,
      "loss": 0.9727,
      "step": 8800
    },
    {
      "epoch": 47.11,
      "grad_norm": 1.4118436574935913,
      "learning_rate": 3.408110626679235e-05,
      "loss": 0.8307,
      "step": 8810
    },
    {
      "epoch": 47.17,
      "grad_norm": 1.6225277185440063,
      "learning_rate": 3.4028818309881445e-05,
      "loss": 1.0363,
      "step": 8820
    },
    {
      "epoch": 47.22,
      "grad_norm": 0.8701858520507812,
      "learning_rate": 3.3976522510072266e-05,
      "loss": 0.902,
      "step": 8830
    },
    {
      "epoch": 47.27,
      "grad_norm": 1.1879833936691284,
      "learning_rate": 3.3924219014963747e-05,
      "loss": 1.0051,
      "step": 8840
    },
    {
      "epoch": 47.33,
      "grad_norm": 0.9718979597091675,
      "learning_rate": 3.387190797217655e-05,
      "loss": 0.9643,
      "step": 8850
    },
    {
      "epoch": 47.38,
      "grad_norm": 1.0134292840957642,
      "learning_rate": 3.381958952935265e-05,
      "loss": 0.9902,
      "step": 8860
    },
    {
      "epoch": 47.43,
      "grad_norm": 0.6267253756523132,
      "learning_rate": 3.37672638341549e-05,
      "loss": 0.815,
      "step": 8870
    },
    {
      "epoch": 47.49,
      "grad_norm": 0.9459753632545471,
      "learning_rate": 3.371493103426658e-05,
      "loss": 0.8715,
      "step": 8880
    },
    {
      "epoch": 47.54,
      "grad_norm": 0.8511176109313965,
      "learning_rate": 3.3662591277391094e-05,
      "loss": 0.8958,
      "step": 8890
    },
    {
      "epoch": 47.59,
      "grad_norm": 0.8143740296363831,
      "learning_rate": 3.361024471125143e-05,
      "loss": 0.8797,
      "step": 8900
    },
    {
      "epoch": 47.65,
      "grad_norm": 1.0040310621261597,
      "learning_rate": 3.3557891483589813e-05,
      "loss": 0.9486,
      "step": 8910
    },
    {
      "epoch": 47.7,
      "grad_norm": 1.1920567750930786,
      "learning_rate": 3.350553174216727e-05,
      "loss": 0.8866,
      "step": 8920
    },
    {
      "epoch": 47.75,
      "grad_norm": 1.0615262985229492,
      "learning_rate": 3.345316563476321e-05,
      "loss": 1.0119,
      "step": 8930
    },
    {
      "epoch": 47.81,
      "grad_norm": 1.2535501718521118,
      "learning_rate": 3.3400793309175e-05,
      "loss": 1.0215,
      "step": 8940
    },
    {
      "epoch": 47.86,
      "grad_norm": 0.8123649954795837,
      "learning_rate": 3.334841491321759e-05,
      "loss": 0.8649,
      "step": 8950
    },
    {
      "epoch": 47.91,
      "grad_norm": 1.0685875415802002,
      "learning_rate": 3.329603059472301e-05,
      "loss": 0.9849,
      "step": 8960
    },
    {
      "epoch": 47.97,
      "grad_norm": 0.6928761005401611,
      "learning_rate": 3.3243640501540044e-05,
      "loss": 0.8005,
      "step": 8970
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4038070440292358,
      "eval_runtime": 1.4345,
      "eval_samples_per_second": 23.004,
      "eval_steps_per_second": 2.091,
      "step": 8976
    },
    {
      "epoch": 48.02,
      "grad_norm": 1.3671928644180298,
      "learning_rate": 3.319124478153376e-05,
      "loss": 1.013,
      "step": 8980
    },
    {
      "epoch": 48.07,
      "grad_norm": 0.9048854112625122,
      "learning_rate": 3.313884358258513e-05,
      "loss": 0.8972,
      "step": 8990
    },
    {
      "epoch": 48.13,
      "grad_norm": 1.109576940536499,
      "learning_rate": 3.308643705259056e-05,
      "loss": 0.8975,
      "step": 9000
    },
    {
      "epoch": 48.18,
      "grad_norm": 0.775132417678833,
      "learning_rate": 3.30340253394615e-05,
      "loss": 0.8684,
      "step": 9010
    },
    {
      "epoch": 48.24,
      "grad_norm": 0.9228231906890869,
      "learning_rate": 3.2981608591124065e-05,
      "loss": 0.9273,
      "step": 9020
    },
    {
      "epoch": 48.29,
      "grad_norm": 1.4473373889923096,
      "learning_rate": 3.292918695551855e-05,
      "loss": 0.9153,
      "step": 9030
    },
    {
      "epoch": 48.34,
      "grad_norm": 1.5248624086380005,
      "learning_rate": 3.287676058059904e-05,
      "loss": 0.9074,
      "step": 9040
    },
    {
      "epoch": 48.4,
      "grad_norm": 0.9674004316329956,
      "learning_rate": 3.282432961433303e-05,
      "loss": 0.838,
      "step": 9050
    },
    {
      "epoch": 48.45,
      "grad_norm": 1.8402504920959473,
      "learning_rate": 3.2771894204700935e-05,
      "loss": 1.0467,
      "step": 9060
    },
    {
      "epoch": 48.5,
      "grad_norm": 1.4364013671875,
      "learning_rate": 3.271945449969574e-05,
      "loss": 0.8552,
      "step": 9070
    },
    {
      "epoch": 48.56,
      "grad_norm": 1.3472355604171753,
      "learning_rate": 3.2667010647322546e-05,
      "loss": 0.9845,
      "step": 9080
    },
    {
      "epoch": 48.61,
      "grad_norm": 1.0808632373809814,
      "learning_rate": 3.261456279559814e-05,
      "loss": 0.9151,
      "step": 9090
    },
    {
      "epoch": 48.66,
      "grad_norm": 1.5729466676712036,
      "learning_rate": 3.256211109255061e-05,
      "loss": 1.0399,
      "step": 9100
    },
    {
      "epoch": 48.72,
      "grad_norm": 0.7727620601654053,
      "learning_rate": 3.2509655686218926e-05,
      "loss": 0.9279,
      "step": 9110
    },
    {
      "epoch": 48.77,
      "grad_norm": 0.9585298895835876,
      "learning_rate": 3.245719672465251e-05,
      "loss": 1.0139,
      "step": 9120
    },
    {
      "epoch": 48.82,
      "grad_norm": 1.1158727407455444,
      "learning_rate": 3.240473435591079e-05,
      "loss": 0.8999,
      "step": 9130
    },
    {
      "epoch": 48.88,
      "grad_norm": 1.405397653579712,
      "learning_rate": 3.2352268728062824e-05,
      "loss": 0.9704,
      "step": 9140
    },
    {
      "epoch": 48.93,
      "grad_norm": 1.470584511756897,
      "learning_rate": 3.2299799989186884e-05,
      "loss": 0.9433,
      "step": 9150
    },
    {
      "epoch": 48.98,
      "grad_norm": 0.8972126841545105,
      "learning_rate": 3.2247328287370004e-05,
      "loss": 0.9102,
      "step": 9160
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4433683156967163,
      "eval_runtime": 1.1753,
      "eval_samples_per_second": 28.077,
      "eval_steps_per_second": 2.552,
      "step": 9163
    },
    {
      "epoch": 49.04,
      "grad_norm": 0.9405807256698608,
      "learning_rate": 3.21948537707076e-05,
      "loss": 0.9039,
      "step": 9170
    },
    {
      "epoch": 49.09,
      "grad_norm": 1.1254386901855469,
      "learning_rate": 3.2142376587303006e-05,
      "loss": 0.9745,
      "step": 9180
    },
    {
      "epoch": 49.14,
      "grad_norm": 0.9307206869125366,
      "learning_rate": 3.208989688526711e-05,
      "loss": 0.7652,
      "step": 9190
    },
    {
      "epoch": 49.2,
      "grad_norm": 1.4388128519058228,
      "learning_rate": 3.2037414812717885e-05,
      "loss": 0.882,
      "step": 9200
    },
    {
      "epoch": 49.25,
      "grad_norm": 0.7373242378234863,
      "learning_rate": 3.198493051778002e-05,
      "loss": 0.9624,
      "step": 9210
    },
    {
      "epoch": 49.3,
      "grad_norm": 1.278616189956665,
      "learning_rate": 3.193244414858444e-05,
      "loss": 0.935,
      "step": 9220
    },
    {
      "epoch": 49.36,
      "grad_norm": 0.9173226952552795,
      "learning_rate": 3.187995585326796e-05,
      "loss": 0.8561,
      "step": 9230
    },
    {
      "epoch": 49.41,
      "grad_norm": 0.8311341404914856,
      "learning_rate": 3.182746577997281e-05,
      "loss": 0.9035,
      "step": 9240
    },
    {
      "epoch": 49.47,
      "grad_norm": 0.8495292067527771,
      "learning_rate": 3.177497407684626e-05,
      "loss": 0.9606,
      "step": 9250
    },
    {
      "epoch": 49.52,
      "grad_norm": 1.1954030990600586,
      "learning_rate": 3.172248089204014e-05,
      "loss": 0.9235,
      "step": 9260
    },
    {
      "epoch": 49.57,
      "grad_norm": 1.3802469968795776,
      "learning_rate": 3.1669986373710504e-05,
      "loss": 0.9281,
      "step": 9270
    },
    {
      "epoch": 49.63,
      "grad_norm": 0.8216301798820496,
      "learning_rate": 3.161749067001715e-05,
      "loss": 0.8967,
      "step": 9280
    },
    {
      "epoch": 49.68,
      "grad_norm": 1.2516354322433472,
      "learning_rate": 3.156499392912322e-05,
      "loss": 1.0394,
      "step": 9290
    },
    {
      "epoch": 49.73,
      "grad_norm": 0.9488077163696289,
      "learning_rate": 3.1512496299194794e-05,
      "loss": 1.0009,
      "step": 9300
    },
    {
      "epoch": 49.79,
      "grad_norm": 0.7647080421447754,
      "learning_rate": 3.1459997928400456e-05,
      "loss": 0.8963,
      "step": 9310
    },
    {
      "epoch": 49.84,
      "grad_norm": 1.944195032119751,
      "learning_rate": 3.140749896491087e-05,
      "loss": 0.9707,
      "step": 9320
    },
    {
      "epoch": 49.89,
      "grad_norm": 0.875088632106781,
      "learning_rate": 3.1354999556898404e-05,
      "loss": 0.9238,
      "step": 9330
    },
    {
      "epoch": 49.95,
      "grad_norm": 1.4712566137313843,
      "learning_rate": 3.130249985253663e-05,
      "loss": 0.9673,
      "step": 9340
    },
    {
      "epoch": 50.0,
      "grad_norm": 1.3456772565841675,
      "learning_rate": 3.125e-05,
      "loss": 0.9557,
      "step": 9350
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4539185762405396,
      "eval_runtime": 1.2033,
      "eval_samples_per_second": 27.425,
      "eval_steps_per_second": 2.493,
      "step": 9350
    },
    {
      "epoch": 50.05,
      "grad_norm": 1.2794517278671265,
      "learning_rate": 3.119750014746338e-05,
      "loss": 0.8982,
      "step": 9360
    },
    {
      "epoch": 50.11,
      "grad_norm": 0.8262075185775757,
      "learning_rate": 3.1145000443101604e-05,
      "loss": 0.8894,
      "step": 9370
    },
    {
      "epoch": 50.16,
      "grad_norm": 1.2069964408874512,
      "learning_rate": 3.109250103508913e-05,
      "loss": 0.8993,
      "step": 9380
    },
    {
      "epoch": 50.21,
      "grad_norm": 0.9468837380409241,
      "learning_rate": 3.1040002071599546e-05,
      "loss": 0.9143,
      "step": 9390
    },
    {
      "epoch": 50.27,
      "grad_norm": 0.8864517211914062,
      "learning_rate": 3.098750370080521e-05,
      "loss": 0.8517,
      "step": 9400
    },
    {
      "epoch": 50.32,
      "grad_norm": 0.9673523306846619,
      "learning_rate": 3.093500607087678e-05,
      "loss": 0.8945,
      "step": 9410
    },
    {
      "epoch": 50.37,
      "grad_norm": 1.3467695713043213,
      "learning_rate": 3.088250932998286e-05,
      "loss": 0.9313,
      "step": 9420
    },
    {
      "epoch": 50.43,
      "grad_norm": 1.0678671598434448,
      "learning_rate": 3.08300136262895e-05,
      "loss": 1.0372,
      "step": 9430
    },
    {
      "epoch": 50.48,
      "grad_norm": 1.273620367050171,
      "learning_rate": 3.077751910795987e-05,
      "loss": 0.9815,
      "step": 9440
    },
    {
      "epoch": 50.53,
      "grad_norm": 1.5141019821166992,
      "learning_rate": 3.072502592315375e-05,
      "loss": 1.0182,
      "step": 9450
    },
    {
      "epoch": 50.59,
      "grad_norm": 1.2332265377044678,
      "learning_rate": 3.06725342200272e-05,
      "loss": 0.8876,
      "step": 9460
    },
    {
      "epoch": 50.64,
      "grad_norm": 0.6972481608390808,
      "learning_rate": 3.062004414673204e-05,
      "loss": 0.8582,
      "step": 9470
    },
    {
      "epoch": 50.7,
      "grad_norm": 1.495200753211975,
      "learning_rate": 3.056755585141556e-05,
      "loss": 0.9037,
      "step": 9480
    },
    {
      "epoch": 50.75,
      "grad_norm": 1.0559470653533936,
      "learning_rate": 3.051506948221999e-05,
      "loss": 0.8999,
      "step": 9490
    },
    {
      "epoch": 50.8,
      "grad_norm": 1.1064362525939941,
      "learning_rate": 3.046258518728211e-05,
      "loss": 0.9328,
      "step": 9500
    },
    {
      "epoch": 50.86,
      "grad_norm": 0.9300763607025146,
      "learning_rate": 3.0410103114732893e-05,
      "loss": 0.9143,
      "step": 9510
    },
    {
      "epoch": 50.91,
      "grad_norm": 1.9341436624526978,
      "learning_rate": 3.0357623412696995e-05,
      "loss": 0.9488,
      "step": 9520
    },
    {
      "epoch": 50.96,
      "grad_norm": 1.185135841369629,
      "learning_rate": 3.0305146229292406e-05,
      "loss": 1.0028,
      "step": 9530
    },
    {
      "epoch": 51.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4186530113220215,
      "eval_runtime": 1.2073,
      "eval_samples_per_second": 27.334,
      "eval_steps_per_second": 2.485,
      "step": 9537
    },
    {
      "epoch": 51.02,
      "grad_norm": 1.0573315620422363,
      "learning_rate": 3.0252671712629998e-05,
      "loss": 0.9252,
      "step": 9540
    },
    {
      "epoch": 51.07,
      "grad_norm": 0.6501807570457458,
      "learning_rate": 3.0200200010813124e-05,
      "loss": 0.9646,
      "step": 9550
    },
    {
      "epoch": 51.12,
      "grad_norm": 0.9109105467796326,
      "learning_rate": 3.0147731271937184e-05,
      "loss": 0.8544,
      "step": 9560
    },
    {
      "epoch": 51.18,
      "grad_norm": 1.1800211668014526,
      "learning_rate": 3.0095265644089227e-05,
      "loss": 0.835,
      "step": 9570
    },
    {
      "epoch": 51.23,
      "grad_norm": 1.0370063781738281,
      "learning_rate": 3.0042803275347495e-05,
      "loss": 0.9083,
      "step": 9580
    },
    {
      "epoch": 51.28,
      "grad_norm": 1.4554014205932617,
      "learning_rate": 2.9990344313781072e-05,
      "loss": 0.9782,
      "step": 9590
    },
    {
      "epoch": 51.34,
      "grad_norm": 1.0287392139434814,
      "learning_rate": 2.9937888907449386e-05,
      "loss": 1.044,
      "step": 9600
    },
    {
      "epoch": 51.39,
      "grad_norm": 1.0377025604248047,
      "learning_rate": 2.988543720440187e-05,
      "loss": 0.9909,
      "step": 9610
    },
    {
      "epoch": 51.44,
      "grad_norm": 0.9847885370254517,
      "learning_rate": 2.9832989352677465e-05,
      "loss": 0.8354,
      "step": 9620
    },
    {
      "epoch": 51.5,
      "grad_norm": 1.0038191080093384,
      "learning_rate": 2.9780545500304256e-05,
      "loss": 1.0169,
      "step": 9630
    },
    {
      "epoch": 51.55,
      "grad_norm": 0.967784583568573,
      "learning_rate": 2.972810579529907e-05,
      "loss": 0.9926,
      "step": 9640
    },
    {
      "epoch": 51.6,
      "grad_norm": 1.2228093147277832,
      "learning_rate": 2.9675670385666975e-05,
      "loss": 0.8802,
      "step": 9650
    },
    {
      "epoch": 51.66,
      "grad_norm": 0.7908043265342712,
      "learning_rate": 2.9623239419400965e-05,
      "loss": 0.9045,
      "step": 9660
    },
    {
      "epoch": 51.71,
      "grad_norm": 0.9324193596839905,
      "learning_rate": 2.9570813044481458e-05,
      "loss": 0.8392,
      "step": 9670
    },
    {
      "epoch": 51.76,
      "grad_norm": 0.8973305225372314,
      "learning_rate": 2.951839140887594e-05,
      "loss": 0.9446,
      "step": 9680
    },
    {
      "epoch": 51.82,
      "grad_norm": 1.0168229341506958,
      "learning_rate": 2.94659746605385e-05,
      "loss": 0.8712,
      "step": 9690
    },
    {
      "epoch": 51.87,
      "grad_norm": 1.0595967769622803,
      "learning_rate": 2.941356294740945e-05,
      "loss": 0.8764,
      "step": 9700
    },
    {
      "epoch": 51.93,
      "grad_norm": 1.3723410367965698,
      "learning_rate": 2.9361156417414867e-05,
      "loss": 0.9686,
      "step": 9710
    },
    {
      "epoch": 51.98,
      "grad_norm": 0.9641308188438416,
      "learning_rate": 2.9308755218466236e-05,
      "loss": 0.9203,
      "step": 9720
    },
    {
      "epoch": 52.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.413938045501709,
      "eval_runtime": 1.2423,
      "eval_samples_per_second": 26.564,
      "eval_steps_per_second": 2.415,
      "step": 9724
    },
    {
      "epoch": 52.03,
      "grad_norm": 1.1888346672058105,
      "learning_rate": 2.9256359498459968e-05,
      "loss": 0.9825,
      "step": 9730
    },
    {
      "epoch": 52.09,
      "grad_norm": 1.1322476863861084,
      "learning_rate": 2.9203969405276993e-05,
      "loss": 0.8751,
      "step": 9740
    },
    {
      "epoch": 52.14,
      "grad_norm": 0.6537492275238037,
      "learning_rate": 2.9151585086782418e-05,
      "loss": 0.8875,
      "step": 9750
    },
    {
      "epoch": 52.19,
      "grad_norm": 1.2768248319625854,
      "learning_rate": 2.9099206690824992e-05,
      "loss": 0.8932,
      "step": 9760
    },
    {
      "epoch": 52.25,
      "grad_norm": 0.946796178817749,
      "learning_rate": 2.9046834365236793e-05,
      "loss": 0.9628,
      "step": 9770
    },
    {
      "epoch": 52.3,
      "grad_norm": 0.8784024119377136,
      "learning_rate": 2.8994468257832734e-05,
      "loss": 0.8738,
      "step": 9780
    },
    {
      "epoch": 52.35,
      "grad_norm": 1.2248725891113281,
      "learning_rate": 2.894210851641019e-05,
      "loss": 0.8792,
      "step": 9790
    },
    {
      "epoch": 52.41,
      "grad_norm": 1.109663724899292,
      "learning_rate": 2.8889755288748578e-05,
      "loss": 0.9854,
      "step": 9800
    },
    {
      "epoch": 52.46,
      "grad_norm": 1.043076992034912,
      "learning_rate": 2.883740872260891e-05,
      "loss": 0.9174,
      "step": 9810
    },
    {
      "epoch": 52.51,
      "grad_norm": 0.7080162167549133,
      "learning_rate": 2.8785068965733423e-05,
      "loss": 0.9004,
      "step": 9820
    },
    {
      "epoch": 52.57,
      "grad_norm": 0.8276172280311584,
      "learning_rate": 2.8732736165845116e-05,
      "loss": 1.0581,
      "step": 9830
    },
    {
      "epoch": 52.62,
      "grad_norm": 1.8115063905715942,
      "learning_rate": 2.8680410470647343e-05,
      "loss": 1.0027,
      "step": 9840
    },
    {
      "epoch": 52.67,
      "grad_norm": 1.1494722366333008,
      "learning_rate": 2.862809202782345e-05,
      "loss": 0.889,
      "step": 9850
    },
    {
      "epoch": 52.73,
      "grad_norm": 0.8006481528282166,
      "learning_rate": 2.8575780985036268e-05,
      "loss": 0.8924,
      "step": 9860
    },
    {
      "epoch": 52.78,
      "grad_norm": 0.9930629134178162,
      "learning_rate": 2.8523477489927742e-05,
      "loss": 0.9926,
      "step": 9870
    },
    {
      "epoch": 52.83,
      "grad_norm": 1.0353994369506836,
      "learning_rate": 2.8471181690118567e-05,
      "loss": 0.9648,
      "step": 9880
    },
    {
      "epoch": 52.89,
      "grad_norm": 0.8435787558555603,
      "learning_rate": 2.8418893733207644e-05,
      "loss": 0.8661,
      "step": 9890
    },
    {
      "epoch": 52.94,
      "grad_norm": 1.047289490699768,
      "learning_rate": 2.8366613766771814e-05,
      "loss": 0.9589,
      "step": 9900
    },
    {
      "epoch": 52.99,
      "grad_norm": 1.3599268198013306,
      "learning_rate": 2.831434193836531e-05,
      "loss": 0.979,
      "step": 9910
    },
    {
      "epoch": 53.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4292590618133545,
      "eval_runtime": 1.1932,
      "eval_samples_per_second": 27.658,
      "eval_steps_per_second": 2.514,
      "step": 9911
    },
    {
      "epoch": 53.05,
      "grad_norm": 1.0608035326004028,
      "learning_rate": 2.826207839551942e-05,
      "loss": 0.9717,
      "step": 9920
    },
    {
      "epoch": 53.1,
      "grad_norm": 0.8239593505859375,
      "learning_rate": 2.8209823285742043e-05,
      "loss": 0.7617,
      "step": 9930
    },
    {
      "epoch": 53.16,
      "grad_norm": 1.0452251434326172,
      "learning_rate": 2.8157576756517283e-05,
      "loss": 1.0237,
      "step": 9940
    },
    {
      "epoch": 53.21,
      "grad_norm": 0.9039027094841003,
      "learning_rate": 2.8105338955304995e-05,
      "loss": 0.8814,
      "step": 9950
    },
    {
      "epoch": 53.26,
      "grad_norm": 1.0686198472976685,
      "learning_rate": 2.805311002954046e-05,
      "loss": 0.8434,
      "step": 9960
    },
    {
      "epoch": 53.32,
      "grad_norm": 1.0650489330291748,
      "learning_rate": 2.8000890126633842e-05,
      "loss": 0.921,
      "step": 9970
    },
    {
      "epoch": 53.37,
      "grad_norm": 0.6913754940032959,
      "learning_rate": 2.79486793939699e-05,
      "loss": 0.8859,
      "step": 9980
    },
    {
      "epoch": 53.42,
      "grad_norm": 1.1040830612182617,
      "learning_rate": 2.7896477978907466e-05,
      "loss": 0.9334,
      "step": 9990
    },
    {
      "epoch": 53.48,
      "grad_norm": 0.8748508095741272,
      "learning_rate": 2.7844286028779078e-05,
      "loss": 1.0138,
      "step": 10000
    },
    {
      "epoch": 53.53,
      "grad_norm": 0.8703868985176086,
      "learning_rate": 2.7792103690890605e-05,
      "loss": 0.9086,
      "step": 10010
    },
    {
      "epoch": 53.58,
      "grad_norm": 0.7073926329612732,
      "learning_rate": 2.7739931112520717e-05,
      "loss": 0.8608,
      "step": 10020
    },
    {
      "epoch": 53.64,
      "grad_norm": 1.1736018657684326,
      "learning_rate": 2.7687768440920607e-05,
      "loss": 0.9462,
      "step": 10030
    },
    {
      "epoch": 53.69,
      "grad_norm": 1.1226575374603271,
      "learning_rate": 2.763561582331346e-05,
      "loss": 0.9182,
      "step": 10040
    },
    {
      "epoch": 53.74,
      "grad_norm": 1.1884679794311523,
      "learning_rate": 2.7583473406894103e-05,
      "loss": 1.0379,
      "step": 10050
    },
    {
      "epoch": 53.8,
      "grad_norm": 1.0657721757888794,
      "learning_rate": 2.7531341338828572e-05,
      "loss": 0.9249,
      "step": 10060
    },
    {
      "epoch": 53.85,
      "grad_norm": 1.277276873588562,
      "learning_rate": 2.7479219766253697e-05,
      "loss": 0.8548,
      "step": 10070
    },
    {
      "epoch": 53.9,
      "grad_norm": 0.9168153405189514,
      "learning_rate": 2.7427108836276658e-05,
      "loss": 0.8826,
      "step": 10080
    },
    {
      "epoch": 53.96,
      "grad_norm": 1.6811116933822632,
      "learning_rate": 2.737500869597466e-05,
      "loss": 0.9131,
      "step": 10090
    },
    {
      "epoch": 54.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3989278078079224,
      "eval_runtime": 1.1848,
      "eval_samples_per_second": 27.854,
      "eval_steps_per_second": 2.532,
      "step": 10098
    },
    {
      "epoch": 54.01,
      "grad_norm": 1.2619644403457642,
      "learning_rate": 2.732291949239438e-05,
      "loss": 0.9366,
      "step": 10100
    },
    {
      "epoch": 54.06,
      "grad_norm": 0.8211237192153931,
      "learning_rate": 2.7270841372551696e-05,
      "loss": 0.8434,
      "step": 10110
    },
    {
      "epoch": 54.12,
      "grad_norm": 1.2314282655715942,
      "learning_rate": 2.7218774483431156e-05,
      "loss": 0.986,
      "step": 10120
    },
    {
      "epoch": 54.17,
      "grad_norm": 0.8263047337532043,
      "learning_rate": 2.716671897198561e-05,
      "loss": 0.8333,
      "step": 10130
    },
    {
      "epoch": 54.22,
      "grad_norm": 1.0569819211959839,
      "learning_rate": 2.7114674985135844e-05,
      "loss": 0.8744,
      "step": 10140
    },
    {
      "epoch": 54.28,
      "grad_norm": 1.0957766771316528,
      "learning_rate": 2.7062642669770065e-05,
      "loss": 0.9556,
      "step": 10150
    },
    {
      "epoch": 54.33,
      "grad_norm": 1.0118430852890015,
      "learning_rate": 2.7010622172743552e-05,
      "loss": 0.9947,
      "step": 10160
    },
    {
      "epoch": 54.39,
      "grad_norm": 1.0887306928634644,
      "learning_rate": 2.6958613640878255e-05,
      "loss": 0.8446,
      "step": 10170
    },
    {
      "epoch": 54.44,
      "grad_norm": 1.0532153844833374,
      "learning_rate": 2.690661722096231e-05,
      "loss": 0.9632,
      "step": 10180
    },
    {
      "epoch": 54.49,
      "grad_norm": 1.1793467998504639,
      "learning_rate": 2.685463305974972e-05,
      "loss": 0.8746,
      "step": 10190
    },
    {
      "epoch": 54.55,
      "grad_norm": 1.0967457294464111,
      "learning_rate": 2.6802661303959843e-05,
      "loss": 0.9105,
      "step": 10200
    },
    {
      "epoch": 54.6,
      "grad_norm": 0.8494356274604797,
      "learning_rate": 2.6750702100277036e-05,
      "loss": 0.9666,
      "step": 10210
    },
    {
      "epoch": 54.65,
      "grad_norm": 1.1298164129257202,
      "learning_rate": 2.6698755595350256e-05,
      "loss": 0.8913,
      "step": 10220
    },
    {
      "epoch": 54.71,
      "grad_norm": 0.8248699903488159,
      "learning_rate": 2.6646821935792572e-05,
      "loss": 0.8702,
      "step": 10230
    },
    {
      "epoch": 54.76,
      "grad_norm": 1.0639257431030273,
      "learning_rate": 2.6594901268180854e-05,
      "loss": 0.8917,
      "step": 10240
    },
    {
      "epoch": 54.81,
      "grad_norm": 1.556151032447815,
      "learning_rate": 2.6542993739055258e-05,
      "loss": 0.9146,
      "step": 10250
    },
    {
      "epoch": 54.87,
      "grad_norm": 1.4655675888061523,
      "learning_rate": 2.6491099494918863e-05,
      "loss": 0.9947,
      "step": 10260
    },
    {
      "epoch": 54.92,
      "grad_norm": 1.0254267454147339,
      "learning_rate": 2.6439218682237292e-05,
      "loss": 0.9586,
      "step": 10270
    },
    {
      "epoch": 54.97,
      "grad_norm": 1.1413649320602417,
      "learning_rate": 2.6387351447438216e-05,
      "loss": 0.9097,
      "step": 10280
    },
    {
      "epoch": 55.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.447568655014038,
      "eval_runtime": 1.2801,
      "eval_samples_per_second": 25.779,
      "eval_steps_per_second": 2.344,
      "step": 10285
    },
    {
      "epoch": 55.03,
      "grad_norm": 0.9374262690544128,
      "learning_rate": 2.6335497936910987e-05,
      "loss": 0.8718,
      "step": 10290
    },
    {
      "epoch": 55.08,
      "grad_norm": 1.2128894329071045,
      "learning_rate": 2.6283658297006257e-05,
      "loss": 0.9245,
      "step": 10300
    },
    {
      "epoch": 55.13,
      "grad_norm": 1.1026209592819214,
      "learning_rate": 2.6231832674035486e-05,
      "loss": 0.878,
      "step": 10310
    },
    {
      "epoch": 55.19,
      "grad_norm": 1.042966604232788,
      "learning_rate": 2.6180021214270612e-05,
      "loss": 0.9236,
      "step": 10320
    },
    {
      "epoch": 55.24,
      "grad_norm": 1.1202030181884766,
      "learning_rate": 2.6128224063943585e-05,
      "loss": 0.9897,
      "step": 10330
    },
    {
      "epoch": 55.29,
      "grad_norm": 1.076981544494629,
      "learning_rate": 2.6076441369245936e-05,
      "loss": 0.967,
      "step": 10340
    },
    {
      "epoch": 55.35,
      "grad_norm": 1.4766933917999268,
      "learning_rate": 2.602467327632845e-05,
      "loss": 0.9458,
      "step": 10350
    },
    {
      "epoch": 55.4,
      "grad_norm": 0.7219924926757812,
      "learning_rate": 2.5972919931300673e-05,
      "loss": 0.9614,
      "step": 10360
    },
    {
      "epoch": 55.45,
      "grad_norm": 0.9082040786743164,
      "learning_rate": 2.5921181480230506e-05,
      "loss": 0.8805,
      "step": 10370
    },
    {
      "epoch": 55.51,
      "grad_norm": 0.6418066024780273,
      "learning_rate": 2.5869458069143867e-05,
      "loss": 0.8835,
      "step": 10380
    },
    {
      "epoch": 55.56,
      "grad_norm": 1.2396143674850464,
      "learning_rate": 2.581774984402416e-05,
      "loss": 0.8738,
      "step": 10390
    },
    {
      "epoch": 55.61,
      "grad_norm": 0.8842318654060364,
      "learning_rate": 2.5766056950812e-05,
      "loss": 0.8708,
      "step": 10400
    },
    {
      "epoch": 55.67,
      "grad_norm": 1.2240759134292603,
      "learning_rate": 2.5714379535404676e-05,
      "loss": 0.966,
      "step": 10410
    },
    {
      "epoch": 55.72,
      "grad_norm": 0.8228174448013306,
      "learning_rate": 2.5662717743655785e-05,
      "loss": 0.9029,
      "step": 10420
    },
    {
      "epoch": 55.78,
      "grad_norm": 1.1454133987426758,
      "learning_rate": 2.5611071721374895e-05,
      "loss": 1.0025,
      "step": 10430
    },
    {
      "epoch": 55.83,
      "grad_norm": 0.9142608642578125,
      "learning_rate": 2.5559441614326986e-05,
      "loss": 0.9974,
      "step": 10440
    },
    {
      "epoch": 55.88,
      "grad_norm": 0.8135955929756165,
      "learning_rate": 2.5507827568232175e-05,
      "loss": 0.8445,
      "step": 10450
    },
    {
      "epoch": 55.94,
      "grad_norm": 0.7500903010368347,
      "learning_rate": 2.5456229728765238e-05,
      "loss": 0.9051,
      "step": 10460
    },
    {
      "epoch": 55.99,
      "grad_norm": 0.8887930512428284,
      "learning_rate": 2.5404648241555174e-05,
      "loss": 0.9941,
      "step": 10470
    },
    {
      "epoch": 56.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4338014125823975,
      "eval_runtime": 1.2159,
      "eval_samples_per_second": 27.14,
      "eval_steps_per_second": 2.467,
      "step": 10472
    },
    {
      "epoch": 56.04,
      "grad_norm": 1.0271538496017456,
      "learning_rate": 2.535308325218489e-05,
      "loss": 0.9603,
      "step": 10480
    },
    {
      "epoch": 56.1,
      "grad_norm": 0.7807486057281494,
      "learning_rate": 2.530153490619068e-05,
      "loss": 0.8769,
      "step": 10490
    },
    {
      "epoch": 56.15,
      "grad_norm": 0.863640308380127,
      "learning_rate": 2.5250003349061873e-05,
      "loss": 0.9377,
      "step": 10500
    },
    {
      "epoch": 56.2,
      "grad_norm": 0.8613763451576233,
      "learning_rate": 2.5198488726240445e-05,
      "loss": 0.8518,
      "step": 10510
    },
    {
      "epoch": 56.26,
      "grad_norm": 0.9733428359031677,
      "learning_rate": 2.514699118312052e-05,
      "loss": 1.0247,
      "step": 10520
    },
    {
      "epoch": 56.31,
      "grad_norm": 1.4310214519500732,
      "learning_rate": 2.5095510865048086e-05,
      "loss": 0.9415,
      "step": 10530
    },
    {
      "epoch": 56.36,
      "grad_norm": 0.7505768537521362,
      "learning_rate": 2.5044047917320464e-05,
      "loss": 0.9187,
      "step": 10540
    },
    {
      "epoch": 56.42,
      "grad_norm": 1.0690604448318481,
      "learning_rate": 2.4992602485185948e-05,
      "loss": 1.0296,
      "step": 10550
    },
    {
      "epoch": 56.47,
      "grad_norm": 1.1882398128509521,
      "learning_rate": 2.4941174713843437e-05,
      "loss": 0.9886,
      "step": 10560
    },
    {
      "epoch": 56.52,
      "grad_norm": 0.9717845916748047,
      "learning_rate": 2.4889764748441943e-05,
      "loss": 0.8044,
      "step": 10570
    },
    {
      "epoch": 56.58,
      "grad_norm": 1.731797456741333,
      "learning_rate": 2.483837273408024e-05,
      "loss": 0.8702,
      "step": 10580
    },
    {
      "epoch": 56.63,
      "grad_norm": 0.9406822919845581,
      "learning_rate": 2.4786998815806457e-05,
      "loss": 0.9165,
      "step": 10590
    },
    {
      "epoch": 56.68,
      "grad_norm": 0.7827734351158142,
      "learning_rate": 2.47356431386176e-05,
      "loss": 0.8982,
      "step": 10600
    },
    {
      "epoch": 56.74,
      "grad_norm": 1.3357658386230469,
      "learning_rate": 2.4684305847459253e-05,
      "loss": 0.9707,
      "step": 10610
    },
    {
      "epoch": 56.79,
      "grad_norm": 0.7938603758811951,
      "learning_rate": 2.463298708722505e-05,
      "loss": 0.8946,
      "step": 10620
    },
    {
      "epoch": 56.84,
      "grad_norm": 0.9165518879890442,
      "learning_rate": 2.458168700275635e-05,
      "loss": 0.9177,
      "step": 10630
    },
    {
      "epoch": 56.9,
      "grad_norm": 1.0145149230957031,
      "learning_rate": 2.4530405738841814e-05,
      "loss": 0.8721,
      "step": 10640
    },
    {
      "epoch": 56.95,
      "grad_norm": 1.3125078678131104,
      "learning_rate": 2.4479143440216963e-05,
      "loss": 0.9348,
      "step": 10650
    },
    {
      "epoch": 57.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4159188270568848,
      "eval_runtime": 1.1648,
      "eval_samples_per_second": 28.331,
      "eval_steps_per_second": 2.576,
      "step": 10659
    },
    {
      "epoch": 57.01,
      "grad_norm": 1.1212928295135498,
      "learning_rate": 2.4427900251563778e-05,
      "loss": 0.9946,
      "step": 10660
    },
    {
      "epoch": 57.06,
      "grad_norm": 1.2427866458892822,
      "learning_rate": 2.4376676317510366e-05,
      "loss": 0.9382,
      "step": 10670
    },
    {
      "epoch": 57.11,
      "grad_norm": 1.1996498107910156,
      "learning_rate": 2.4325471782630403e-05,
      "loss": 1.025,
      "step": 10680
    },
    {
      "epoch": 57.17,
      "grad_norm": 1.7366507053375244,
      "learning_rate": 2.4274286791442897e-05,
      "loss": 1.0506,
      "step": 10690
    },
    {
      "epoch": 57.22,
      "grad_norm": 0.8661109805107117,
      "learning_rate": 2.4223121488411638e-05,
      "loss": 0.8844,
      "step": 10700
    },
    {
      "epoch": 57.27,
      "grad_norm": 1.2240296602249146,
      "learning_rate": 2.417197601794486e-05,
      "loss": 0.8433,
      "step": 10710
    },
    {
      "epoch": 57.33,
      "grad_norm": 1.3302663564682007,
      "learning_rate": 2.4120850524394857e-05,
      "loss": 0.9601,
      "step": 10720
    },
    {
      "epoch": 57.38,
      "grad_norm": 1.318114995956421,
      "learning_rate": 2.4069745152057482e-05,
      "loss": 0.8784,
      "step": 10730
    },
    {
      "epoch": 57.43,
      "grad_norm": 0.7654082179069519,
      "learning_rate": 2.401866004517186e-05,
      "loss": 0.7895,
      "step": 10740
    },
    {
      "epoch": 57.49,
      "grad_norm": 0.9089853763580322,
      "learning_rate": 2.3967595347919868e-05,
      "loss": 0.8966,
      "step": 10750
    },
    {
      "epoch": 57.54,
      "grad_norm": 0.7879502773284912,
      "learning_rate": 2.3916551204425794e-05,
      "loss": 0.9941,
      "step": 10760
    },
    {
      "epoch": 57.59,
      "grad_norm": 1.2131545543670654,
      "learning_rate": 2.3865527758755944e-05,
      "loss": 0.8321,
      "step": 10770
    },
    {
      "epoch": 57.65,
      "grad_norm": 1.2967497110366821,
      "learning_rate": 2.381452515491817e-05,
      "loss": 0.8962,
      "step": 10780
    },
    {
      "epoch": 57.7,
      "grad_norm": 0.9541223049163818,
      "learning_rate": 2.3763543536861504e-05,
      "loss": 0.95,
      "step": 10790
    },
    {
      "epoch": 57.75,
      "grad_norm": 1.0169754028320312,
      "learning_rate": 2.371258304847578e-05,
      "loss": 0.8989,
      "step": 10800
    },
    {
      "epoch": 57.81,
      "grad_norm": 0.9937558770179749,
      "learning_rate": 2.3661643833591156e-05,
      "loss": 0.9509,
      "step": 10810
    },
    {
      "epoch": 57.86,
      "grad_norm": 0.8808465600013733,
      "learning_rate": 2.3610726035977784e-05,
      "loss": 0.9151,
      "step": 10820
    },
    {
      "epoch": 57.91,
      "grad_norm": 1.0829784870147705,
      "learning_rate": 2.3559829799345328e-05,
      "loss": 0.9032,
      "step": 10830
    },
    {
      "epoch": 57.97,
      "grad_norm": 1.5607699155807495,
      "learning_rate": 2.3508955267342624e-05,
      "loss": 0.9219,
      "step": 10840
    },
    {
      "epoch": 58.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3955261707305908,
      "eval_runtime": 1.1795,
      "eval_samples_per_second": 27.978,
      "eval_steps_per_second": 2.543,
      "step": 10846
    },
    {
      "epoch": 58.02,
      "grad_norm": 0.9987891316413879,
      "learning_rate": 2.345810258355727e-05,
      "loss": 0.9031,
      "step": 10850
    },
    {
      "epoch": 58.07,
      "grad_norm": 0.9068872332572937,
      "learning_rate": 2.340727189151516e-05,
      "loss": 0.872,
      "step": 10860
    },
    {
      "epoch": 58.13,
      "grad_norm": 1.1424099206924438,
      "learning_rate": 2.3356463334680117e-05,
      "loss": 0.8889,
      "step": 10870
    },
    {
      "epoch": 58.18,
      "grad_norm": 1.6244146823883057,
      "learning_rate": 2.330567705645354e-05,
      "loss": 0.9288,
      "step": 10880
    },
    {
      "epoch": 58.24,
      "grad_norm": 1.1853903532028198,
      "learning_rate": 2.3254913200173888e-05,
      "loss": 0.8999,
      "step": 10890
    },
    {
      "epoch": 58.29,
      "grad_norm": 1.3820741176605225,
      "learning_rate": 2.3204171909116388e-05,
      "loss": 0.8608,
      "step": 10900
    },
    {
      "epoch": 58.34,
      "grad_norm": 1.1171221733093262,
      "learning_rate": 2.3153453326492545e-05,
      "loss": 0.8506,
      "step": 10910
    },
    {
      "epoch": 58.4,
      "grad_norm": 0.9442391991615295,
      "learning_rate": 2.3102757595449773e-05,
      "loss": 0.838,
      "step": 10920
    },
    {
      "epoch": 58.45,
      "grad_norm": 0.9604455232620239,
      "learning_rate": 2.3052084859071026e-05,
      "loss": 0.8862,
      "step": 10930
    },
    {
      "epoch": 58.5,
      "grad_norm": 1.362241506576538,
      "learning_rate": 2.3001435260374308e-05,
      "loss": 1.0039,
      "step": 10940
    },
    {
      "epoch": 58.56,
      "grad_norm": 0.9377654790878296,
      "learning_rate": 2.2950808942312362e-05,
      "loss": 0.9006,
      "step": 10950
    },
    {
      "epoch": 58.61,
      "grad_norm": 0.9912973046302795,
      "learning_rate": 2.29002060477722e-05,
      "loss": 0.8797,
      "step": 10960
    },
    {
      "epoch": 58.66,
      "grad_norm": 1.1772481203079224,
      "learning_rate": 2.284962671957472e-05,
      "loss": 0.9699,
      "step": 10970
    },
    {
      "epoch": 58.72,
      "grad_norm": 0.9118795394897461,
      "learning_rate": 2.2799071100474334e-05,
      "loss": 0.8856,
      "step": 10980
    },
    {
      "epoch": 58.77,
      "grad_norm": 0.9523695111274719,
      "learning_rate": 2.2748539333158517e-05,
      "loss": 0.9037,
      "step": 10990
    },
    {
      "epoch": 58.82,
      "grad_norm": 0.9276469945907593,
      "learning_rate": 2.2698031560247412e-05,
      "loss": 0.9647,
      "step": 11000
    },
    {
      "epoch": 58.88,
      "grad_norm": 0.9411396980285645,
      "learning_rate": 2.264754792429348e-05,
      "loss": 0.9365,
      "step": 11010
    },
    {
      "epoch": 58.93,
      "grad_norm": 0.7949631810188293,
      "learning_rate": 2.259708856778101e-05,
      "loss": 1.0001,
      "step": 11020
    },
    {
      "epoch": 58.98,
      "grad_norm": 1.4583706855773926,
      "learning_rate": 2.2546653633125815e-05,
      "loss": 1.027,
      "step": 11030
    },
    {
      "epoch": 59.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3984225988388062,
      "eval_runtime": 1.2975,
      "eval_samples_per_second": 25.433,
      "eval_steps_per_second": 2.312,
      "step": 11033
    },
    {
      "epoch": 59.04,
      "grad_norm": 0.841856837272644,
      "learning_rate": 2.249624326267475e-05,
      "loss": 1.0065,
      "step": 11040
    },
    {
      "epoch": 59.09,
      "grad_norm": 0.9039390683174133,
      "learning_rate": 2.244585759870532e-05,
      "loss": 0.8286,
      "step": 11050
    },
    {
      "epoch": 59.14,
      "grad_norm": 1.6462428569793701,
      "learning_rate": 2.239549678342537e-05,
      "loss": 0.9886,
      "step": 11060
    },
    {
      "epoch": 59.2,
      "grad_norm": 1.4698323011398315,
      "learning_rate": 2.2345160958972523e-05,
      "loss": 0.9369,
      "step": 11070
    },
    {
      "epoch": 59.25,
      "grad_norm": 0.8010483980178833,
      "learning_rate": 2.2294850267413938e-05,
      "loss": 0.8763,
      "step": 11080
    },
    {
      "epoch": 59.3,
      "grad_norm": 0.8989266157150269,
      "learning_rate": 2.2244564850745803e-05,
      "loss": 0.8986,
      "step": 11090
    },
    {
      "epoch": 59.36,
      "grad_norm": 0.8275405764579773,
      "learning_rate": 2.2194304850892978e-05,
      "loss": 0.9363,
      "step": 11100
    },
    {
      "epoch": 59.41,
      "grad_norm": 0.8136007189750671,
      "learning_rate": 2.2144070409708605e-05,
      "loss": 0.8532,
      "step": 11110
    },
    {
      "epoch": 59.47,
      "grad_norm": 1.2493339776992798,
      "learning_rate": 2.2093861668973668e-05,
      "loss": 0.9516,
      "step": 11120
    },
    {
      "epoch": 59.52,
      "grad_norm": 1.0065932273864746,
      "learning_rate": 2.2043678770396605e-05,
      "loss": 0.9079,
      "step": 11130
    },
    {
      "epoch": 59.57,
      "grad_norm": 1.0253770351409912,
      "learning_rate": 2.199352185561296e-05,
      "loss": 0.9169,
      "step": 11140
    },
    {
      "epoch": 59.63,
      "grad_norm": 0.9451619386672974,
      "learning_rate": 2.194339106618489e-05,
      "loss": 0.9427,
      "step": 11150
    },
    {
      "epoch": 59.68,
      "grad_norm": 0.7433124780654907,
      "learning_rate": 2.1893286543600857e-05,
      "loss": 1.0179,
      "step": 11160
    },
    {
      "epoch": 59.73,
      "grad_norm": 1.2416449785232544,
      "learning_rate": 2.1843208429275166e-05,
      "loss": 0.8966,
      "step": 11170
    },
    {
      "epoch": 59.79,
      "grad_norm": 1.2973358631134033,
      "learning_rate": 2.1793156864547582e-05,
      "loss": 0.7974,
      "step": 11180
    },
    {
      "epoch": 59.84,
      "grad_norm": 0.7873454689979553,
      "learning_rate": 2.1743131990682966e-05,
      "loss": 0.7832,
      "step": 11190
    },
    {
      "epoch": 59.89,
      "grad_norm": 1.3848210573196411,
      "learning_rate": 2.1693133948870808e-05,
      "loss": 0.9374,
      "step": 11200
    },
    {
      "epoch": 59.95,
      "grad_norm": 0.6738908290863037,
      "learning_rate": 2.16431628802249e-05,
      "loss": 0.9854,
      "step": 11210
    },
    {
      "epoch": 60.0,
      "grad_norm": 2.0256621837615967,
      "learning_rate": 2.1593218925782896e-05,
      "loss": 1.0058,
      "step": 11220
    },
    {
      "epoch": 60.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4267218112945557,
      "eval_runtime": 1.17,
      "eval_samples_per_second": 28.204,
      "eval_steps_per_second": 2.564,
      "step": 11220
    },
    {
      "epoch": 60.05,
      "grad_norm": 1.156429648399353,
      "learning_rate": 2.1543302226505914e-05,
      "loss": 0.8344,
      "step": 11230
    },
    {
      "epoch": 60.11,
      "grad_norm": 1.7087385654449463,
      "learning_rate": 2.1493412923278157e-05,
      "loss": 0.9648,
      "step": 11240
    },
    {
      "epoch": 60.16,
      "grad_norm": 0.8852593302726746,
      "learning_rate": 2.1443551156906506e-05,
      "loss": 0.9097,
      "step": 11250
    },
    {
      "epoch": 60.21,
      "grad_norm": 0.7634126543998718,
      "learning_rate": 2.1393717068120105e-05,
      "loss": 1.0328,
      "step": 11260
    },
    {
      "epoch": 60.27,
      "grad_norm": 0.8966854214668274,
      "learning_rate": 2.134391079757002e-05,
      "loss": 0.9372,
      "step": 11270
    },
    {
      "epoch": 60.32,
      "grad_norm": 1.3291133642196655,
      "learning_rate": 2.129413248582876e-05,
      "loss": 0.9833,
      "step": 11280
    },
    {
      "epoch": 60.37,
      "grad_norm": 0.9861819744110107,
      "learning_rate": 2.1244382273389936e-05,
      "loss": 0.8899,
      "step": 11290
    },
    {
      "epoch": 60.43,
      "grad_norm": 0.9502735733985901,
      "learning_rate": 2.119466030066788e-05,
      "loss": 0.9387,
      "step": 11300
    },
    {
      "epoch": 60.48,
      "grad_norm": 0.9497700333595276,
      "learning_rate": 2.1144966707997177e-05,
      "loss": 0.8971,
      "step": 11310
    },
    {
      "epoch": 60.53,
      "grad_norm": 1.240536093711853,
      "learning_rate": 2.109530163563235e-05,
      "loss": 0.9482,
      "step": 11320
    },
    {
      "epoch": 60.59,
      "grad_norm": 0.8552908301353455,
      "learning_rate": 2.10456652237474e-05,
      "loss": 0.8915,
      "step": 11330
    },
    {
      "epoch": 60.64,
      "grad_norm": 0.8336474299430847,
      "learning_rate": 2.0996057612435456e-05,
      "loss": 0.9883,
      "step": 11340
    },
    {
      "epoch": 60.7,
      "grad_norm": 1.514252781867981,
      "learning_rate": 2.094647894170834e-05,
      "loss": 0.8426,
      "step": 11350
    },
    {
      "epoch": 60.75,
      "grad_norm": 0.9124246835708618,
      "learning_rate": 2.0896929351496222e-05,
      "loss": 0.864,
      "step": 11360
    },
    {
      "epoch": 60.8,
      "grad_norm": 1.0555354356765747,
      "learning_rate": 2.0847408981647165e-05,
      "loss": 0.9716,
      "step": 11370
    },
    {
      "epoch": 60.86,
      "grad_norm": 0.9217607378959656,
      "learning_rate": 2.079791797192679e-05,
      "loss": 0.7861,
      "step": 11380
    },
    {
      "epoch": 60.91,
      "grad_norm": 1.9103809595108032,
      "learning_rate": 2.0748456462017803e-05,
      "loss": 1.0186,
      "step": 11390
    },
    {
      "epoch": 60.96,
      "grad_norm": 0.8906013369560242,
      "learning_rate": 2.0699024591519728e-05,
      "loss": 0.9575,
      "step": 11400
    },
    {
      "epoch": 61.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4103039503097534,
      "eval_runtime": 1.1712,
      "eval_samples_per_second": 28.176,
      "eval_steps_per_second": 2.561,
      "step": 11407
    },
    {
      "epoch": 61.02,
      "grad_norm": 0.7193538546562195,
      "learning_rate": 2.0649622499948366e-05,
      "loss": 0.8646,
      "step": 11410
    },
    {
      "epoch": 61.07,
      "grad_norm": 0.7608150243759155,
      "learning_rate": 2.0600250326735492e-05,
      "loss": 0.9617,
      "step": 11420
    },
    {
      "epoch": 61.12,
      "grad_norm": 1.0216293334960938,
      "learning_rate": 2.0550908211228457e-05,
      "loss": 0.917,
      "step": 11430
    },
    {
      "epoch": 61.18,
      "grad_norm": 1.2167960405349731,
      "learning_rate": 2.0501596292689744e-05,
      "loss": 0.9456,
      "step": 11440
    },
    {
      "epoch": 61.23,
      "grad_norm": 1.0726020336151123,
      "learning_rate": 2.0452314710296655e-05,
      "loss": 0.8807,
      "step": 11450
    },
    {
      "epoch": 61.28,
      "grad_norm": 1.3753149509429932,
      "learning_rate": 2.0403063603140828e-05,
      "loss": 0.9426,
      "step": 11460
    },
    {
      "epoch": 61.34,
      "grad_norm": 1.4018076658248901,
      "learning_rate": 2.0353843110227903e-05,
      "loss": 0.8418,
      "step": 11470
    },
    {
      "epoch": 61.39,
      "grad_norm": 1.1938762664794922,
      "learning_rate": 2.0304653370477124e-05,
      "loss": 0.9306,
      "step": 11480
    },
    {
      "epoch": 61.44,
      "grad_norm": 1.233049750328064,
      "learning_rate": 2.0255494522720935e-05,
      "loss": 0.9063,
      "step": 11490
    },
    {
      "epoch": 61.5,
      "grad_norm": 0.7592093348503113,
      "learning_rate": 2.020636670570457e-05,
      "loss": 0.8593,
      "step": 11500
    },
    {
      "epoch": 61.55,
      "grad_norm": 1.2468891143798828,
      "learning_rate": 2.0157270058085714e-05,
      "loss": 1.0582,
      "step": 11510
    },
    {
      "epoch": 61.6,
      "grad_norm": 0.9520576596260071,
      "learning_rate": 2.010820471843405e-05,
      "loss": 0.9638,
      "step": 11520
    },
    {
      "epoch": 61.66,
      "grad_norm": 0.7668365240097046,
      "learning_rate": 2.0059170825230933e-05,
      "loss": 0.9717,
      "step": 11530
    },
    {
      "epoch": 61.71,
      "grad_norm": 0.951012909412384,
      "learning_rate": 2.0010168516868933e-05,
      "loss": 0.8994,
      "step": 11540
    },
    {
      "epoch": 61.76,
      "grad_norm": 1.3461889028549194,
      "learning_rate": 1.996119793165147e-05,
      "loss": 0.9767,
      "step": 11550
    },
    {
      "epoch": 61.82,
      "grad_norm": 1.264477252960205,
      "learning_rate": 1.9912259207792473e-05,
      "loss": 0.9577,
      "step": 11560
    },
    {
      "epoch": 61.87,
      "grad_norm": 0.8061457872390747,
      "learning_rate": 1.986335248341589e-05,
      "loss": 0.8328,
      "step": 11570
    },
    {
      "epoch": 61.93,
      "grad_norm": 0.9447234869003296,
      "learning_rate": 1.9814477896555415e-05,
      "loss": 0.8511,
      "step": 11580
    },
    {
      "epoch": 61.98,
      "grad_norm": 0.7975690960884094,
      "learning_rate": 1.976563558515397e-05,
      "loss": 0.8204,
      "step": 11590
    },
    {
      "epoch": 62.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4207839965820312,
      "eval_runtime": 1.1762,
      "eval_samples_per_second": 28.055,
      "eval_steps_per_second": 2.55,
      "step": 11594
    },
    {
      "epoch": 62.03,
      "grad_norm": 0.9666793942451477,
      "learning_rate": 1.9716825687063442e-05,
      "loss": 0.8108,
      "step": 11600
    },
    {
      "epoch": 62.09,
      "grad_norm": 0.8119445443153381,
      "learning_rate": 1.9668048340044196e-05,
      "loss": 0.8055,
      "step": 11610
    },
    {
      "epoch": 62.14,
      "grad_norm": 0.9799383282661438,
      "learning_rate": 1.9619303681764753e-05,
      "loss": 0.991,
      "step": 11620
    },
    {
      "epoch": 62.19,
      "grad_norm": 1.3436973094940186,
      "learning_rate": 1.957059184980134e-05,
      "loss": 0.9511,
      "step": 11630
    },
    {
      "epoch": 62.25,
      "grad_norm": 0.7754029035568237,
      "learning_rate": 1.952191298163758e-05,
      "loss": 0.8947,
      "step": 11640
    },
    {
      "epoch": 62.3,
      "grad_norm": 1.137277364730835,
      "learning_rate": 1.9473267214664016e-05,
      "loss": 0.8014,
      "step": 11650
    },
    {
      "epoch": 62.35,
      "grad_norm": 0.7731767296791077,
      "learning_rate": 1.9424654686177804e-05,
      "loss": 0.852,
      "step": 11660
    },
    {
      "epoch": 62.41,
      "grad_norm": 1.831691861152649,
      "learning_rate": 1.937607553338227e-05,
      "loss": 0.8885,
      "step": 11670
    },
    {
      "epoch": 62.46,
      "grad_norm": 1.5985127687454224,
      "learning_rate": 1.9327529893386514e-05,
      "loss": 1.0517,
      "step": 11680
    },
    {
      "epoch": 62.51,
      "grad_norm": 0.8853057026863098,
      "learning_rate": 1.927901790320511e-05,
      "loss": 0.9177,
      "step": 11690
    },
    {
      "epoch": 62.57,
      "grad_norm": 1.3086879253387451,
      "learning_rate": 1.9230539699757606e-05,
      "loss": 0.8414,
      "step": 11700
    },
    {
      "epoch": 62.62,
      "grad_norm": 0.7836544513702393,
      "learning_rate": 1.918209541986822e-05,
      "loss": 0.9947,
      "step": 11710
    },
    {
      "epoch": 62.67,
      "grad_norm": 1.2888654470443726,
      "learning_rate": 1.9133685200265414e-05,
      "loss": 1.0035,
      "step": 11720
    },
    {
      "epoch": 62.73,
      "grad_norm": 0.8267551064491272,
      "learning_rate": 1.9085309177581518e-05,
      "loss": 0.8928,
      "step": 11730
    },
    {
      "epoch": 62.78,
      "grad_norm": 0.9251289367675781,
      "learning_rate": 1.9036967488352354e-05,
      "loss": 0.9559,
      "step": 11740
    },
    {
      "epoch": 62.83,
      "grad_norm": 1.12714421749115,
      "learning_rate": 1.8988660269016835e-05,
      "loss": 0.9153,
      "step": 11750
    },
    {
      "epoch": 62.89,
      "grad_norm": 1.1607118844985962,
      "learning_rate": 1.8940387655916575e-05,
      "loss": 0.8969,
      "step": 11760
    },
    {
      "epoch": 62.94,
      "grad_norm": 1.1624763011932373,
      "learning_rate": 1.8892149785295547e-05,
      "loss": 0.9499,
      "step": 11770
    },
    {
      "epoch": 62.99,
      "grad_norm": 1.2491892576217651,
      "learning_rate": 1.8843946793299627e-05,
      "loss": 0.8744,
      "step": 11780
    },
    {
      "epoch": 63.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3932487964630127,
      "eval_runtime": 1.1841,
      "eval_samples_per_second": 27.868,
      "eval_steps_per_second": 2.533,
      "step": 11781
    },
    {
      "epoch": 63.05,
      "grad_norm": 0.8368093967437744,
      "learning_rate": 1.8795778815976298e-05,
      "loss": 0.8472,
      "step": 11790
    },
    {
      "epoch": 63.1,
      "grad_norm": 0.9939966201782227,
      "learning_rate": 1.8747645989274177e-05,
      "loss": 0.9243,
      "step": 11800
    },
    {
      "epoch": 63.16,
      "grad_norm": 1.005910038948059,
      "learning_rate": 1.869954844904267e-05,
      "loss": 1.0184,
      "step": 11810
    },
    {
      "epoch": 63.21,
      "grad_norm": 0.9660114645957947,
      "learning_rate": 1.8651486331031637e-05,
      "loss": 0.9026,
      "step": 11820
    },
    {
      "epoch": 63.26,
      "grad_norm": 0.6904241442680359,
      "learning_rate": 1.8603459770890916e-05,
      "loss": 0.9572,
      "step": 11830
    },
    {
      "epoch": 63.32,
      "grad_norm": 0.8725392818450928,
      "learning_rate": 1.855546890417001e-05,
      "loss": 0.9176,
      "step": 11840
    },
    {
      "epoch": 63.37,
      "grad_norm": 1.1377992630004883,
      "learning_rate": 1.8507513866317666e-05,
      "loss": 0.9898,
      "step": 11850
    },
    {
      "epoch": 63.42,
      "grad_norm": 1.0628156661987305,
      "learning_rate": 1.8459594792681535e-05,
      "loss": 0.8679,
      "step": 11860
    },
    {
      "epoch": 63.48,
      "grad_norm": 1.125436782836914,
      "learning_rate": 1.841171181850774e-05,
      "loss": 0.8871,
      "step": 11870
    },
    {
      "epoch": 63.53,
      "grad_norm": 1.9445058107376099,
      "learning_rate": 1.8363865078940523e-05,
      "loss": 0.8895,
      "step": 11880
    },
    {
      "epoch": 63.58,
      "grad_norm": 0.679707944393158,
      "learning_rate": 1.831605470902184e-05,
      "loss": 0.8935,
      "step": 11890
    },
    {
      "epoch": 63.64,
      "grad_norm": 0.8572478294372559,
      "learning_rate": 1.826828084369105e-05,
      "loss": 0.8942,
      "step": 11900
    },
    {
      "epoch": 63.69,
      "grad_norm": 0.8747974634170532,
      "learning_rate": 1.8220543617784433e-05,
      "loss": 0.9367,
      "step": 11910
    },
    {
      "epoch": 63.74,
      "grad_norm": 0.833897054195404,
      "learning_rate": 1.8172843166034854e-05,
      "loss": 0.948,
      "step": 11920
    },
    {
      "epoch": 63.8,
      "grad_norm": 0.8836754560470581,
      "learning_rate": 1.8125179623071446e-05,
      "loss": 0.9693,
      "step": 11930
    },
    {
      "epoch": 63.85,
      "grad_norm": 1.0256787538528442,
      "learning_rate": 1.8077553123419083e-05,
      "loss": 0.8257,
      "step": 11940
    },
    {
      "epoch": 63.9,
      "grad_norm": 0.8218495845794678,
      "learning_rate": 1.8029963801498195e-05,
      "loss": 1.0042,
      "step": 11950
    },
    {
      "epoch": 63.96,
      "grad_norm": 1.2197197675704956,
      "learning_rate": 1.798241179162418e-05,
      "loss": 0.9246,
      "step": 11960
    },
    {
      "epoch": 64.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3931015729904175,
      "eval_runtime": 1.2423,
      "eval_samples_per_second": 26.564,
      "eval_steps_per_second": 2.415,
      "step": 11968
    },
    {
      "epoch": 64.01,
      "grad_norm": 1.1236730813980103,
      "learning_rate": 1.793489722800718e-05,
      "loss": 0.935,
      "step": 11970
    },
    {
      "epoch": 64.06,
      "grad_norm": 1.1363234519958496,
      "learning_rate": 1.7887420244751653e-05,
      "loss": 0.7995,
      "step": 11980
    },
    {
      "epoch": 64.12,
      "grad_norm": 1.3238182067871094,
      "learning_rate": 1.783998097585597e-05,
      "loss": 0.8825,
      "step": 11990
    },
    {
      "epoch": 64.17,
      "grad_norm": 1.1215975284576416,
      "learning_rate": 1.7792579555212068e-05,
      "loss": 0.9171,
      "step": 12000
    },
    {
      "epoch": 64.22,
      "grad_norm": 1.243213176727295,
      "learning_rate": 1.7745216116605067e-05,
      "loss": 0.855,
      "step": 12010
    },
    {
      "epoch": 64.28,
      "grad_norm": 1.3860853910446167,
      "learning_rate": 1.769789079371285e-05,
      "loss": 0.921,
      "step": 12020
    },
    {
      "epoch": 64.33,
      "grad_norm": 0.7438651323318481,
      "learning_rate": 1.7650603720105797e-05,
      "loss": 0.9765,
      "step": 12030
    },
    {
      "epoch": 64.39,
      "grad_norm": 1.2120038270950317,
      "learning_rate": 1.7603355029246254e-05,
      "loss": 0.9991,
      "step": 12040
    },
    {
      "epoch": 64.44,
      "grad_norm": 1.1542956829071045,
      "learning_rate": 1.755614485448828e-05,
      "loss": 0.9254,
      "step": 12050
    },
    {
      "epoch": 64.49,
      "grad_norm": 0.8982494473457336,
      "learning_rate": 1.7508973329077224e-05,
      "loss": 0.9255,
      "step": 12060
    },
    {
      "epoch": 64.55,
      "grad_norm": 1.123309850692749,
      "learning_rate": 1.7461840586149326e-05,
      "loss": 0.9481,
      "step": 12070
    },
    {
      "epoch": 64.6,
      "grad_norm": 0.8900277614593506,
      "learning_rate": 1.7414746758731426e-05,
      "loss": 0.8456,
      "step": 12080
    },
    {
      "epoch": 64.65,
      "grad_norm": 1.5687685012817383,
      "learning_rate": 1.7367691979740457e-05,
      "loss": 1.01,
      "step": 12090
    },
    {
      "epoch": 64.71,
      "grad_norm": 0.6292960047721863,
      "learning_rate": 1.732067638198318e-05,
      "loss": 0.8707,
      "step": 12100
    },
    {
      "epoch": 64.76,
      "grad_norm": 0.967667818069458,
      "learning_rate": 1.727370009815577e-05,
      "loss": 0.9114,
      "step": 12110
    },
    {
      "epoch": 64.81,
      "grad_norm": 0.9129038453102112,
      "learning_rate": 1.7226763260843452e-05,
      "loss": 0.8468,
      "step": 12120
    },
    {
      "epoch": 64.87,
      "grad_norm": 0.8097567558288574,
      "learning_rate": 1.7179866002520067e-05,
      "loss": 0.8773,
      "step": 12130
    },
    {
      "epoch": 64.92,
      "grad_norm": 1.4803621768951416,
      "learning_rate": 1.7133008455547833e-05,
      "loss": 0.8976,
      "step": 12140
    },
    {
      "epoch": 64.97,
      "grad_norm": 1.1085731983184814,
      "learning_rate": 1.7086190752176802e-05,
      "loss": 0.825,
      "step": 12150
    },
    {
      "epoch": 65.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4227583408355713,
      "eval_runtime": 1.1721,
      "eval_samples_per_second": 28.154,
      "eval_steps_per_second": 2.559,
      "step": 12155
    },
    {
      "epoch": 65.03,
      "grad_norm": 1.5647070407867432,
      "learning_rate": 1.7039413024544644e-05,
      "loss": 0.9173,
      "step": 12160
    },
    {
      "epoch": 65.08,
      "grad_norm": 0.8185170888900757,
      "learning_rate": 1.6992675404676146e-05,
      "loss": 0.9088,
      "step": 12170
    },
    {
      "epoch": 65.13,
      "grad_norm": 1.378826379776001,
      "learning_rate": 1.6945978024482925e-05,
      "loss": 0.9621,
      "step": 12180
    },
    {
      "epoch": 65.19,
      "grad_norm": 1.0799037218093872,
      "learning_rate": 1.689932101576302e-05,
      "loss": 0.8843,
      "step": 12190
    },
    {
      "epoch": 65.24,
      "grad_norm": 1.9360648393630981,
      "learning_rate": 1.685270451020051e-05,
      "loss": 0.9468,
      "step": 12200
    },
    {
      "epoch": 65.29,
      "grad_norm": 1.4899877309799194,
      "learning_rate": 1.6806128639365217e-05,
      "loss": 0.9779,
      "step": 12210
    },
    {
      "epoch": 65.35,
      "grad_norm": 1.1498929262161255,
      "learning_rate": 1.6759593534712196e-05,
      "loss": 0.9071,
      "step": 12220
    },
    {
      "epoch": 65.4,
      "grad_norm": 1.019869327545166,
      "learning_rate": 1.6713099327581486e-05,
      "loss": 0.9163,
      "step": 12230
    },
    {
      "epoch": 65.45,
      "grad_norm": 0.9732009172439575,
      "learning_rate": 1.6666646149197698e-05,
      "loss": 0.8678,
      "step": 12240
    },
    {
      "epoch": 65.51,
      "grad_norm": 0.6503914594650269,
      "learning_rate": 1.6620234130669652e-05,
      "loss": 0.8742,
      "step": 12250
    },
    {
      "epoch": 65.56,
      "grad_norm": 1.137718915939331,
      "learning_rate": 1.6573863402989948e-05,
      "loss": 0.9716,
      "step": 12260
    },
    {
      "epoch": 65.61,
      "grad_norm": 0.9449122548103333,
      "learning_rate": 1.6527534097034733e-05,
      "loss": 0.9134,
      "step": 12270
    },
    {
      "epoch": 65.67,
      "grad_norm": 0.9094316959381104,
      "learning_rate": 1.648124634356315e-05,
      "loss": 0.7937,
      "step": 12280
    },
    {
      "epoch": 65.72,
      "grad_norm": 1.4614181518554688,
      "learning_rate": 1.6435000273217156e-05,
      "loss": 0.8392,
      "step": 12290
    },
    {
      "epoch": 65.78,
      "grad_norm": 0.9200847744941711,
      "learning_rate": 1.6388796016520992e-05,
      "loss": 0.8866,
      "step": 12300
    },
    {
      "epoch": 65.83,
      "grad_norm": 0.8201621770858765,
      "learning_rate": 1.6342633703880915e-05,
      "loss": 0.9411,
      "step": 12310
    },
    {
      "epoch": 65.88,
      "grad_norm": 0.9387288093566895,
      "learning_rate": 1.62965134655848e-05,
      "loss": 0.8294,
      "step": 12320
    },
    {
      "epoch": 65.94,
      "grad_norm": 1.3577419519424438,
      "learning_rate": 1.625043543180177e-05,
      "loss": 0.9102,
      "step": 12330
    },
    {
      "epoch": 65.99,
      "grad_norm": 0.8688320517539978,
      "learning_rate": 1.6204399732581826e-05,
      "loss": 0.9661,
      "step": 12340
    },
    {
      "epoch": 66.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.424248456954956,
      "eval_runtime": 1.2187,
      "eval_samples_per_second": 27.079,
      "eval_steps_per_second": 2.462,
      "step": 12342
    },
    {
      "epoch": 66.04,
      "grad_norm": 1.397864818572998,
      "learning_rate": 1.6158406497855488e-05,
      "loss": 1.0024,
      "step": 12350
    },
    {
      "epoch": 66.1,
      "grad_norm": 1.0501148700714111,
      "learning_rate": 1.6112455857433423e-05,
      "loss": 0.9266,
      "step": 12360
    },
    {
      "epoch": 66.15,
      "grad_norm": 1.084926724433899,
      "learning_rate": 1.6066547941006087e-05,
      "loss": 0.9126,
      "step": 12370
    },
    {
      "epoch": 66.2,
      "grad_norm": 0.9864715933799744,
      "learning_rate": 1.602068287814335e-05,
      "loss": 0.835,
      "step": 12380
    },
    {
      "epoch": 66.26,
      "grad_norm": 1.0493266582489014,
      "learning_rate": 1.5974860798294098e-05,
      "loss": 0.9183,
      "step": 12390
    },
    {
      "epoch": 66.31,
      "grad_norm": 0.9478960037231445,
      "learning_rate": 1.5929081830785982e-05,
      "loss": 0.8744,
      "step": 12400
    },
    {
      "epoch": 66.36,
      "grad_norm": 0.8884198665618896,
      "learning_rate": 1.5883346104824878e-05,
      "loss": 0.8781,
      "step": 12410
    },
    {
      "epoch": 66.42,
      "grad_norm": 1.318751573562622,
      "learning_rate": 1.583765374949471e-05,
      "loss": 0.9486,
      "step": 12420
    },
    {
      "epoch": 66.47,
      "grad_norm": 0.9562662243843079,
      "learning_rate": 1.579200489375692e-05,
      "loss": 0.9701,
      "step": 12430
    },
    {
      "epoch": 66.52,
      "grad_norm": 0.8585475087165833,
      "learning_rate": 1.5746399666450205e-05,
      "loss": 0.8114,
      "step": 12440
    },
    {
      "epoch": 66.58,
      "grad_norm": 1.0404226779937744,
      "learning_rate": 1.5700838196290136e-05,
      "loss": 0.8404,
      "step": 12450
    },
    {
      "epoch": 66.63,
      "grad_norm": 0.9881935119628906,
      "learning_rate": 1.565532061186877e-05,
      "loss": 0.9184,
      "step": 12460
    },
    {
      "epoch": 66.68,
      "grad_norm": 0.8658044338226318,
      "learning_rate": 1.560984704165431e-05,
      "loss": 0.9913,
      "step": 12470
    },
    {
      "epoch": 66.74,
      "grad_norm": 1.616931676864624,
      "learning_rate": 1.5564417613990727e-05,
      "loss": 0.9477,
      "step": 12480
    },
    {
      "epoch": 66.79,
      "grad_norm": 0.7626843452453613,
      "learning_rate": 1.5519032457097412e-05,
      "loss": 0.8358,
      "step": 12490
    },
    {
      "epoch": 66.84,
      "grad_norm": 1.0992587804794312,
      "learning_rate": 1.5473691699068793e-05,
      "loss": 0.9066,
      "step": 12500
    },
    {
      "epoch": 66.9,
      "grad_norm": 1.47162926197052,
      "learning_rate": 1.5428395467874023e-05,
      "loss": 0.9639,
      "step": 12510
    },
    {
      "epoch": 66.95,
      "grad_norm": 1.0600528717041016,
      "learning_rate": 1.5383143891356507e-05,
      "loss": 0.8938,
      "step": 12520
    },
    {
      "epoch": 67.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.423856258392334,
      "eval_runtime": 1.2029,
      "eval_samples_per_second": 27.434,
      "eval_steps_per_second": 2.494,
      "step": 12529
    },
    {
      "epoch": 67.01,
      "grad_norm": 0.8219632506370544,
      "learning_rate": 1.5337937097233723e-05,
      "loss": 0.9017,
      "step": 12530
    },
    {
      "epoch": 67.06,
      "grad_norm": 1.0986952781677246,
      "learning_rate": 1.5292775213096663e-05,
      "loss": 0.7994,
      "step": 12540
    },
    {
      "epoch": 67.11,
      "grad_norm": 0.8098008632659912,
      "learning_rate": 1.5247658366409615e-05,
      "loss": 0.8483,
      "step": 12550
    },
    {
      "epoch": 67.17,
      "grad_norm": 1.369801640510559,
      "learning_rate": 1.5202586684509741e-05,
      "loss": 0.8734,
      "step": 12560
    },
    {
      "epoch": 67.22,
      "grad_norm": 1.194146990776062,
      "learning_rate": 1.5157560294606732e-05,
      "loss": 0.9324,
      "step": 12570
    },
    {
      "epoch": 67.27,
      "grad_norm": 1.4035106897354126,
      "learning_rate": 1.5112579323782443e-05,
      "loss": 1.0219,
      "step": 12580
    },
    {
      "epoch": 67.33,
      "grad_norm": 0.8472781181335449,
      "learning_rate": 1.5067643898990548e-05,
      "loss": 0.9322,
      "step": 12590
    },
    {
      "epoch": 67.38,
      "grad_norm": 0.7730200886726379,
      "learning_rate": 1.5022754147056162e-05,
      "loss": 0.8771,
      "step": 12600
    },
    {
      "epoch": 67.43,
      "grad_norm": 1.472679615020752,
      "learning_rate": 1.4977910194675498e-05,
      "loss": 0.8912,
      "step": 12610
    },
    {
      "epoch": 67.49,
      "grad_norm": 1.2273834943771362,
      "learning_rate": 1.4933112168415512e-05,
      "loss": 0.8633,
      "step": 12620
    },
    {
      "epoch": 67.54,
      "grad_norm": 1.2459429502487183,
      "learning_rate": 1.4888360194713527e-05,
      "loss": 0.9685,
      "step": 12630
    },
    {
      "epoch": 67.59,
      "grad_norm": 1.3381427526474,
      "learning_rate": 1.4843654399876905e-05,
      "loss": 0.9688,
      "step": 12640
    },
    {
      "epoch": 67.65,
      "grad_norm": 0.9554954767227173,
      "learning_rate": 1.4798994910082628e-05,
      "loss": 0.93,
      "step": 12650
    },
    {
      "epoch": 67.7,
      "grad_norm": 0.9608690142631531,
      "learning_rate": 1.4754381851377066e-05,
      "loss": 0.8609,
      "step": 12660
    },
    {
      "epoch": 67.75,
      "grad_norm": 1.4739201068878174,
      "learning_rate": 1.4709815349675467e-05,
      "loss": 0.9312,
      "step": 12670
    },
    {
      "epoch": 67.81,
      "grad_norm": 1.1045033931732178,
      "learning_rate": 1.4665295530761715e-05,
      "loss": 0.9428,
      "step": 12680
    },
    {
      "epoch": 67.86,
      "grad_norm": 0.8421691060066223,
      "learning_rate": 1.4620822520287927e-05,
      "loss": 0.8661,
      "step": 12690
    },
    {
      "epoch": 67.91,
      "grad_norm": 1.197754979133606,
      "learning_rate": 1.4576396443774118e-05,
      "loss": 0.9167,
      "step": 12700
    },
    {
      "epoch": 67.97,
      "grad_norm": 0.7271690368652344,
      "learning_rate": 1.4532017426607824e-05,
      "loss": 0.9198,
      "step": 12710
    },
    {
      "epoch": 68.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4126269817352295,
      "eval_runtime": 1.1633,
      "eval_samples_per_second": 28.368,
      "eval_steps_per_second": 2.579,
      "step": 12716
    },
    {
      "epoch": 68.02,
      "grad_norm": 1.0092469453811646,
      "learning_rate": 1.4487685594043773e-05,
      "loss": 0.8995,
      "step": 12720
    },
    {
      "epoch": 68.07,
      "grad_norm": 0.931343138217926,
      "learning_rate": 1.444340107120351e-05,
      "loss": 0.9109,
      "step": 12730
    },
    {
      "epoch": 68.13,
      "grad_norm": 0.9562121629714966,
      "learning_rate": 1.4399163983075066e-05,
      "loss": 0.9408,
      "step": 12740
    },
    {
      "epoch": 68.18,
      "grad_norm": 0.8560511469841003,
      "learning_rate": 1.4354974454512587e-05,
      "loss": 0.838,
      "step": 12750
    },
    {
      "epoch": 68.24,
      "grad_norm": 0.7724584341049194,
      "learning_rate": 1.4310832610235955e-05,
      "loss": 0.8923,
      "step": 12760
    },
    {
      "epoch": 68.29,
      "grad_norm": 1.111588478088379,
      "learning_rate": 1.4266738574830549e-05,
      "loss": 0.9575,
      "step": 12770
    },
    {
      "epoch": 68.34,
      "grad_norm": 1.0448232889175415,
      "learning_rate": 1.4222692472746713e-05,
      "loss": 0.9233,
      "step": 12780
    },
    {
      "epoch": 68.4,
      "grad_norm": 0.9569735527038574,
      "learning_rate": 1.4178694428299603e-05,
      "loss": 1.0489,
      "step": 12790
    },
    {
      "epoch": 68.45,
      "grad_norm": 1.3328654766082764,
      "learning_rate": 1.4134744565668652e-05,
      "loss": 0.8989,
      "step": 12800
    },
    {
      "epoch": 68.5,
      "grad_norm": 0.9694403409957886,
      "learning_rate": 1.4090843008897361e-05,
      "loss": 0.8731,
      "step": 12810
    },
    {
      "epoch": 68.56,
      "grad_norm": 0.9042069911956787,
      "learning_rate": 1.4046989881892867e-05,
      "loss": 0.8376,
      "step": 12820
    },
    {
      "epoch": 68.61,
      "grad_norm": 1.0524786710739136,
      "learning_rate": 1.4003185308425634e-05,
      "loss": 0.8836,
      "step": 12830
    },
    {
      "epoch": 68.66,
      "grad_norm": 1.021077275276184,
      "learning_rate": 1.395942941212908e-05,
      "loss": 0.85,
      "step": 12840
    },
    {
      "epoch": 68.72,
      "grad_norm": 1.132083535194397,
      "learning_rate": 1.3915722316499243e-05,
      "loss": 0.9521,
      "step": 12850
    },
    {
      "epoch": 68.77,
      "grad_norm": 0.6002641320228577,
      "learning_rate": 1.3872064144894417e-05,
      "loss": 0.8412,
      "step": 12860
    },
    {
      "epoch": 68.82,
      "grad_norm": 0.9043973684310913,
      "learning_rate": 1.3828455020534828e-05,
      "loss": 0.8175,
      "step": 12870
    },
    {
      "epoch": 68.88,
      "grad_norm": 1.1122270822525024,
      "learning_rate": 1.3784895066502268e-05,
      "loss": 0.9024,
      "step": 12880
    },
    {
      "epoch": 68.93,
      "grad_norm": 1.088701605796814,
      "learning_rate": 1.3741384405739722e-05,
      "loss": 0.8874,
      "step": 12890
    },
    {
      "epoch": 68.98,
      "grad_norm": 0.9629074335098267,
      "learning_rate": 1.3697923161051115e-05,
      "loss": 0.8754,
      "step": 12900
    },
    {
      "epoch": 69.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4100234508514404,
      "eval_runtime": 1.2253,
      "eval_samples_per_second": 26.933,
      "eval_steps_per_second": 2.448,
      "step": 12903
    },
    {
      "epoch": 69.04,
      "grad_norm": 1.6694459915161133,
      "learning_rate": 1.3654511455100816e-05,
      "loss": 0.8831,
      "step": 12910
    },
    {
      "epoch": 69.09,
      "grad_norm": 0.8977339863777161,
      "learning_rate": 1.361114941041347e-05,
      "loss": 0.9032,
      "step": 12920
    },
    {
      "epoch": 69.14,
      "grad_norm": 0.9101350903511047,
      "learning_rate": 1.3567837149373475e-05,
      "loss": 0.9502,
      "step": 12930
    },
    {
      "epoch": 69.2,
      "grad_norm": 1.6364047527313232,
      "learning_rate": 1.3524574794224771e-05,
      "loss": 0.8896,
      "step": 12940
    },
    {
      "epoch": 69.25,
      "grad_norm": 0.9879659414291382,
      "learning_rate": 1.348136246707042e-05,
      "loss": 0.8723,
      "step": 12950
    },
    {
      "epoch": 69.3,
      "grad_norm": 1.2077407836914062,
      "learning_rate": 1.3438200289872308e-05,
      "loss": 0.8851,
      "step": 12960
    },
    {
      "epoch": 69.36,
      "grad_norm": 1.6603111028671265,
      "learning_rate": 1.3395088384450755e-05,
      "loss": 0.9108,
      "step": 12970
    },
    {
      "epoch": 69.41,
      "grad_norm": 1.1007578372955322,
      "learning_rate": 1.3352026872484213e-05,
      "loss": 0.8471,
      "step": 12980
    },
    {
      "epoch": 69.47,
      "grad_norm": 1.213183879852295,
      "learning_rate": 1.3309015875508892e-05,
      "loss": 0.9445,
      "step": 12990
    },
    {
      "epoch": 69.52,
      "grad_norm": 1.1379072666168213,
      "learning_rate": 1.3266055514918434e-05,
      "loss": 0.9349,
      "step": 13000
    },
    {
      "epoch": 69.57,
      "grad_norm": 0.8872360587120056,
      "learning_rate": 1.3223145911963573e-05,
      "loss": 0.9763,
      "step": 13010
    },
    {
      "epoch": 69.63,
      "grad_norm": 0.7579847574234009,
      "learning_rate": 1.318028718775175e-05,
      "loss": 0.8781,
      "step": 13020
    },
    {
      "epoch": 69.68,
      "grad_norm": 1.9096691608428955,
      "learning_rate": 1.3137479463246876e-05,
      "loss": 0.9368,
      "step": 13030
    },
    {
      "epoch": 69.73,
      "grad_norm": 1.1234172582626343,
      "learning_rate": 1.3094722859268847e-05,
      "loss": 0.964,
      "step": 13040
    },
    {
      "epoch": 69.79,
      "grad_norm": 1.3551145792007446,
      "learning_rate": 1.3052017496493318e-05,
      "loss": 0.9103,
      "step": 13050
    },
    {
      "epoch": 69.84,
      "grad_norm": 0.7721837759017944,
      "learning_rate": 1.3009363495451316e-05,
      "loss": 0.8494,
      "step": 13060
    },
    {
      "epoch": 69.89,
      "grad_norm": 0.9947192072868347,
      "learning_rate": 1.2966760976528901e-05,
      "loss": 0.8377,
      "step": 13070
    },
    {
      "epoch": 69.95,
      "grad_norm": 1.1960171461105347,
      "learning_rate": 1.2924210059966825e-05,
      "loss": 0.9184,
      "step": 13080
    },
    {
      "epoch": 70.0,
      "grad_norm": 1.1571608781814575,
      "learning_rate": 1.2881710865860218e-05,
      "loss": 1.0244,
      "step": 13090
    },
    {
      "epoch": 70.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4406095743179321,
      "eval_runtime": 1.2223,
      "eval_samples_per_second": 26.999,
      "eval_steps_per_second": 2.454,
      "step": 13090
    },
    {
      "epoch": 70.05,
      "grad_norm": 0.7952848672866821,
      "learning_rate": 1.2839263514158206e-05,
      "loss": 0.8925,
      "step": 13100
    },
    {
      "epoch": 70.11,
      "grad_norm": 1.1490508317947388,
      "learning_rate": 1.2796868124663609e-05,
      "loss": 0.9433,
      "step": 13110
    },
    {
      "epoch": 70.16,
      "grad_norm": 0.7529363036155701,
      "learning_rate": 1.275452481703259e-05,
      "loss": 0.9792,
      "step": 13120
    },
    {
      "epoch": 70.21,
      "grad_norm": 0.6987478733062744,
      "learning_rate": 1.2712233710774308e-05,
      "loss": 0.8992,
      "step": 13130
    },
    {
      "epoch": 70.27,
      "grad_norm": 0.8318353891372681,
      "learning_rate": 1.266999492525061e-05,
      "loss": 0.9155,
      "step": 13140
    },
    {
      "epoch": 70.32,
      "grad_norm": 1.4090005159378052,
      "learning_rate": 1.2627808579675622e-05,
      "loss": 0.8864,
      "step": 13150
    },
    {
      "epoch": 70.37,
      "grad_norm": 0.7588842511177063,
      "learning_rate": 1.2585674793115547e-05,
      "loss": 0.8957,
      "step": 13160
    },
    {
      "epoch": 70.43,
      "grad_norm": 1.118234395980835,
      "learning_rate": 1.2543593684488167e-05,
      "loss": 0.9302,
      "step": 13170
    },
    {
      "epoch": 70.48,
      "grad_norm": 0.9671347141265869,
      "learning_rate": 1.2501565372562629e-05,
      "loss": 0.8435,
      "step": 13180
    },
    {
      "epoch": 70.53,
      "grad_norm": 0.932879626750946,
      "learning_rate": 1.2459589975959063e-05,
      "loss": 0.9871,
      "step": 13190
    },
    {
      "epoch": 70.59,
      "grad_norm": 2.0284578800201416,
      "learning_rate": 1.241766761314824e-05,
      "loss": 1.002,
      "step": 13200
    },
    {
      "epoch": 70.64,
      "grad_norm": 1.0434430837631226,
      "learning_rate": 1.2375798402451261e-05,
      "loss": 0.8926,
      "step": 13210
    },
    {
      "epoch": 70.7,
      "grad_norm": 0.9610213041305542,
      "learning_rate": 1.2333982462039203e-05,
      "loss": 0.8977,
      "step": 13220
    },
    {
      "epoch": 70.75,
      "grad_norm": 1.373793601989746,
      "learning_rate": 1.2292219909932797e-05,
      "loss": 0.8244,
      "step": 13230
    },
    {
      "epoch": 70.8,
      "grad_norm": 1.3865928649902344,
      "learning_rate": 1.2250510864002088e-05,
      "loss": 0.9613,
      "step": 13240
    },
    {
      "epoch": 70.86,
      "grad_norm": 1.075998306274414,
      "learning_rate": 1.2208855441966125e-05,
      "loss": 0.8769,
      "step": 13250
    },
    {
      "epoch": 70.91,
      "grad_norm": 1.6359645128250122,
      "learning_rate": 1.2167253761392556e-05,
      "loss": 0.9134,
      "step": 13260
    },
    {
      "epoch": 70.96,
      "grad_norm": 0.9822260141372681,
      "learning_rate": 1.2125705939697435e-05,
      "loss": 0.8962,
      "step": 13270
    },
    {
      "epoch": 71.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4124442338943481,
      "eval_runtime": 1.1701,
      "eval_samples_per_second": 28.204,
      "eval_steps_per_second": 2.564,
      "step": 13277
    },
    {
      "epoch": 71.02,
      "grad_norm": 0.8813604116439819,
      "learning_rate": 1.2084212094144717e-05,
      "loss": 0.8315,
      "step": 13280
    },
    {
      "epoch": 71.07,
      "grad_norm": 0.9122923612594604,
      "learning_rate": 1.204277234184609e-05,
      "loss": 0.8838,
      "step": 13290
    },
    {
      "epoch": 71.12,
      "grad_norm": 0.8084050416946411,
      "learning_rate": 1.2001386799760515e-05,
      "loss": 0.9172,
      "step": 13300
    },
    {
      "epoch": 71.18,
      "grad_norm": 0.7613868713378906,
      "learning_rate": 1.1960055584693975e-05,
      "loss": 0.9494,
      "step": 13310
    },
    {
      "epoch": 71.23,
      "grad_norm": 1.104982852935791,
      "learning_rate": 1.1918778813299121e-05,
      "loss": 0.9373,
      "step": 13320
    },
    {
      "epoch": 71.28,
      "grad_norm": 1.69149649143219,
      "learning_rate": 1.1877556602074943e-05,
      "loss": 0.8673,
      "step": 13330
    },
    {
      "epoch": 71.34,
      "grad_norm": 0.7474653124809265,
      "learning_rate": 1.1836389067366435e-05,
      "loss": 0.846,
      "step": 13340
    },
    {
      "epoch": 71.39,
      "grad_norm": 1.317137598991394,
      "learning_rate": 1.1795276325364277e-05,
      "loss": 0.9093,
      "step": 13350
    },
    {
      "epoch": 71.44,
      "grad_norm": 1.028013825416565,
      "learning_rate": 1.1754218492104503e-05,
      "loss": 1.0084,
      "step": 13360
    },
    {
      "epoch": 71.5,
      "grad_norm": 1.3274593353271484,
      "learning_rate": 1.171321568346817e-05,
      "loss": 0.9834,
      "step": 13370
    },
    {
      "epoch": 71.55,
      "grad_norm": 0.883423388004303,
      "learning_rate": 1.167226801518105e-05,
      "loss": 0.8102,
      "step": 13380
    },
    {
      "epoch": 71.6,
      "grad_norm": 1.2413939237594604,
      "learning_rate": 1.1631375602813243e-05,
      "loss": 0.853,
      "step": 13390
    },
    {
      "epoch": 71.66,
      "grad_norm": 1.3100461959838867,
      "learning_rate": 1.1590538561778969e-05,
      "loss": 0.9665,
      "step": 13400
    },
    {
      "epoch": 71.71,
      "grad_norm": 1.3281172513961792,
      "learning_rate": 1.1549757007336078e-05,
      "loss": 0.9073,
      "step": 13410
    },
    {
      "epoch": 71.76,
      "grad_norm": 0.8488175272941589,
      "learning_rate": 1.1509031054585916e-05,
      "loss": 0.8817,
      "step": 13420
    },
    {
      "epoch": 71.82,
      "grad_norm": 0.867338240146637,
      "learning_rate": 1.1468360818472805e-05,
      "loss": 0.8973,
      "step": 13430
    },
    {
      "epoch": 71.87,
      "grad_norm": 1.1567548513412476,
      "learning_rate": 1.1427746413783875e-05,
      "loss": 0.8876,
      "step": 13440
    },
    {
      "epoch": 71.93,
      "grad_norm": 1.0303107500076294,
      "learning_rate": 1.1387187955148656e-05,
      "loss": 0.9571,
      "step": 13450
    },
    {
      "epoch": 71.98,
      "grad_norm": 1.0907937288284302,
      "learning_rate": 1.1346685557038778e-05,
      "loss": 0.8796,
      "step": 13460
    },
    {
      "epoch": 72.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.398689866065979,
      "eval_runtime": 1.355,
      "eval_samples_per_second": 24.354,
      "eval_steps_per_second": 2.214,
      "step": 13464
    },
    {
      "epoch": 72.03,
      "grad_norm": 0.8480098843574524,
      "learning_rate": 1.1306239333767648e-05,
      "loss": 0.932,
      "step": 13470
    },
    {
      "epoch": 72.09,
      "grad_norm": 1.1282250881195068,
      "learning_rate": 1.1265849399490127e-05,
      "loss": 0.9881,
      "step": 13480
    },
    {
      "epoch": 72.14,
      "grad_norm": 0.6815395951271057,
      "learning_rate": 1.1225515868202207e-05,
      "loss": 0.9694,
      "step": 13490
    },
    {
      "epoch": 72.19,
      "grad_norm": 0.9614047408103943,
      "learning_rate": 1.1185238853740682e-05,
      "loss": 0.9704,
      "step": 13500
    },
    {
      "epoch": 72.25,
      "grad_norm": 0.8222736120223999,
      "learning_rate": 1.1145018469782858e-05,
      "loss": 0.9749,
      "step": 13510
    },
    {
      "epoch": 72.3,
      "grad_norm": 0.8273333311080933,
      "learning_rate": 1.1104854829846147e-05,
      "loss": 0.907,
      "step": 13520
    },
    {
      "epoch": 72.35,
      "grad_norm": 1.0976653099060059,
      "learning_rate": 1.1064748047287902e-05,
      "loss": 0.9074,
      "step": 13530
    },
    {
      "epoch": 72.41,
      "grad_norm": 0.736031174659729,
      "learning_rate": 1.1024698235304903e-05,
      "loss": 0.934,
      "step": 13540
    },
    {
      "epoch": 72.46,
      "grad_norm": 0.9992401003837585,
      "learning_rate": 1.0984705506933229e-05,
      "loss": 0.8482,
      "step": 13550
    },
    {
      "epoch": 72.51,
      "grad_norm": 1.445454478263855,
      "learning_rate": 1.0944769975047765e-05,
      "loss": 0.8683,
      "step": 13560
    },
    {
      "epoch": 72.57,
      "grad_norm": 1.2989333868026733,
      "learning_rate": 1.0904891752362016e-05,
      "loss": 0.8109,
      "step": 13570
    },
    {
      "epoch": 72.62,
      "grad_norm": 0.9366593360900879,
      "learning_rate": 1.0865070951427727e-05,
      "loss": 0.8993,
      "step": 13580
    },
    {
      "epoch": 72.67,
      "grad_norm": 0.7403424382209778,
      "learning_rate": 1.0825307684634572e-05,
      "loss": 0.8605,
      "step": 13590
    },
    {
      "epoch": 72.73,
      "grad_norm": 1.1437175273895264,
      "learning_rate": 1.0785602064209844e-05,
      "loss": 0.8635,
      "step": 13600
    },
    {
      "epoch": 72.78,
      "grad_norm": 1.3848397731781006,
      "learning_rate": 1.0745954202218136e-05,
      "loss": 0.9647,
      "step": 13610
    },
    {
      "epoch": 72.83,
      "grad_norm": 1.3731592893600464,
      "learning_rate": 1.0706364210561023e-05,
      "loss": 0.8612,
      "step": 13620
    },
    {
      "epoch": 72.89,
      "grad_norm": 0.7446209788322449,
      "learning_rate": 1.0666832200976754e-05,
      "loss": 0.9035,
      "step": 13630
    },
    {
      "epoch": 72.94,
      "grad_norm": 2.0032401084899902,
      "learning_rate": 1.0627358285039925e-05,
      "loss": 0.9368,
      "step": 13640
    },
    {
      "epoch": 72.99,
      "grad_norm": 1.1063644886016846,
      "learning_rate": 1.0587942574161148e-05,
      "loss": 0.8509,
      "step": 13650
    },
    {
      "epoch": 73.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3746412992477417,
      "eval_runtime": 1.2214,
      "eval_samples_per_second": 27.019,
      "eval_steps_per_second": 2.456,
      "step": 13651
    },
    {
      "epoch": 73.05,
      "grad_norm": 1.1587285995483398,
      "learning_rate": 1.0548585179586817e-05,
      "loss": 0.9417,
      "step": 13660
    },
    {
      "epoch": 73.1,
      "grad_norm": 1.0223222970962524,
      "learning_rate": 1.0509286212398664e-05,
      "loss": 0.976,
      "step": 13670
    },
    {
      "epoch": 73.16,
      "grad_norm": 0.5983777642250061,
      "learning_rate": 1.047004578351356e-05,
      "loss": 0.913,
      "step": 13680
    },
    {
      "epoch": 73.21,
      "grad_norm": 0.7655584812164307,
      "learning_rate": 1.0430864003683149e-05,
      "loss": 0.8501,
      "step": 13690
    },
    {
      "epoch": 73.26,
      "grad_norm": 1.1230838298797607,
      "learning_rate": 1.039174098349354e-05,
      "loss": 0.8284,
      "step": 13700
    },
    {
      "epoch": 73.32,
      "grad_norm": 0.7523314356803894,
      "learning_rate": 1.0352676833365008e-05,
      "loss": 0.9567,
      "step": 13710
    },
    {
      "epoch": 73.37,
      "grad_norm": 0.7243618369102478,
      "learning_rate": 1.0313671663551665e-05,
      "loss": 0.9567,
      "step": 13720
    },
    {
      "epoch": 73.42,
      "grad_norm": 0.7348161935806274,
      "learning_rate": 1.0274725584141161e-05,
      "loss": 0.936,
      "step": 13730
    },
    {
      "epoch": 73.48,
      "grad_norm": 1.0384998321533203,
      "learning_rate": 1.0235838705054374e-05,
      "loss": 0.8263,
      "step": 13740
    },
    {
      "epoch": 73.53,
      "grad_norm": 0.9339461922645569,
      "learning_rate": 1.0197011136045088e-05,
      "loss": 0.9322,
      "step": 13750
    },
    {
      "epoch": 73.58,
      "grad_norm": 0.9816316366195679,
      "learning_rate": 1.0158242986699695e-05,
      "loss": 0.8247,
      "step": 13760
    },
    {
      "epoch": 73.64,
      "grad_norm": 1.072754144668579,
      "learning_rate": 1.0119534366436902e-05,
      "loss": 0.9701,
      "step": 13770
    },
    {
      "epoch": 73.69,
      "grad_norm": 1.0335067510604858,
      "learning_rate": 1.0080885384507341e-05,
      "loss": 0.9061,
      "step": 13780
    },
    {
      "epoch": 73.74,
      "grad_norm": 0.8284117579460144,
      "learning_rate": 1.0042296149993405e-05,
      "loss": 0.802,
      "step": 13790
    },
    {
      "epoch": 73.8,
      "grad_norm": 1.1917285919189453,
      "learning_rate": 1.000376677180879e-05,
      "loss": 0.9188,
      "step": 13800
    },
    {
      "epoch": 73.85,
      "grad_norm": 0.693397581577301,
      "learning_rate": 9.965297358698285e-06,
      "loss": 0.8297,
      "step": 13810
    },
    {
      "epoch": 73.9,
      "grad_norm": 1.1469135284423828,
      "learning_rate": 9.92688801923743e-06,
      "loss": 0.928,
      "step": 13820
    },
    {
      "epoch": 73.96,
      "grad_norm": 1.380302906036377,
      "learning_rate": 9.888538861832204e-06,
      "loss": 1.0061,
      "step": 13830
    },
    {
      "epoch": 74.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.439904808998108,
      "eval_runtime": 1.218,
      "eval_samples_per_second": 27.094,
      "eval_steps_per_second": 2.463,
      "step": 13838
    },
    {
      "epoch": 74.01,
      "grad_norm": 1.2457040548324585,
      "learning_rate": 9.85024999471875e-06,
      "loss": 0.9082,
      "step": 13840
    },
    {
      "epoch": 74.06,
      "grad_norm": 1.3509633541107178,
      "learning_rate": 9.812021525963028e-06,
      "loss": 0.9618,
      "step": 13850
    },
    {
      "epoch": 74.12,
      "grad_norm": 1.0078208446502686,
      "learning_rate": 9.773853563460541e-06,
      "loss": 0.9208,
      "step": 13860
    },
    {
      "epoch": 74.17,
      "grad_norm": 1.4596589803695679,
      "learning_rate": 9.735746214936013e-06,
      "loss": 1.085,
      "step": 13870
    },
    {
      "epoch": 74.22,
      "grad_norm": 1.136323094367981,
      "learning_rate": 9.697699587943112e-06,
      "loss": 0.7678,
      "step": 13880
    },
    {
      "epoch": 74.28,
      "grad_norm": 0.8023539781570435,
      "learning_rate": 9.659713789864077e-06,
      "loss": 0.9999,
      "step": 13890
    },
    {
      "epoch": 74.33,
      "grad_norm": 1.320296049118042,
      "learning_rate": 9.62178892790954e-06,
      "loss": 0.9215,
      "step": 13900
    },
    {
      "epoch": 74.39,
      "grad_norm": 1.1886699199676514,
      "learning_rate": 9.583925109118062e-06,
      "loss": 0.9058,
      "step": 13910
    },
    {
      "epoch": 74.44,
      "grad_norm": 1.0575270652770996,
      "learning_rate": 9.546122440356002e-06,
      "loss": 0.9052,
      "step": 13920
    },
    {
      "epoch": 74.49,
      "grad_norm": 1.2582801580429077,
      "learning_rate": 9.50838102831706e-06,
      "loss": 0.844,
      "step": 13930
    },
    {
      "epoch": 74.55,
      "grad_norm": 1.157357096672058,
      "learning_rate": 9.470700979522084e-06,
      "loss": 0.9004,
      "step": 13940
    },
    {
      "epoch": 74.6,
      "grad_norm": 0.8335347175598145,
      "learning_rate": 9.433082400318718e-06,
      "loss": 0.9009,
      "step": 13950
    },
    {
      "epoch": 74.65,
      "grad_norm": 1.4800593852996826,
      "learning_rate": 9.395525396881123e-06,
      "loss": 0.8567,
      "step": 13960
    },
    {
      "epoch": 74.71,
      "grad_norm": 0.775231122970581,
      "learning_rate": 9.358030075209661e-06,
      "loss": 0.8053,
      "step": 13970
    },
    {
      "epoch": 74.76,
      "grad_norm": 0.9573671817779541,
      "learning_rate": 9.320596541130606e-06,
      "loss": 0.8652,
      "step": 13980
    },
    {
      "epoch": 74.81,
      "grad_norm": 0.9168169498443604,
      "learning_rate": 9.283224900295855e-06,
      "loss": 0.842,
      "step": 13990
    },
    {
      "epoch": 74.87,
      "grad_norm": 0.9675271511077881,
      "learning_rate": 9.245915258182602e-06,
      "loss": 0.958,
      "step": 14000
    },
    {
      "epoch": 74.92,
      "grad_norm": 1.0183899402618408,
      "learning_rate": 9.20866772009307e-06,
      "loss": 0.9306,
      "step": 14010
    },
    {
      "epoch": 74.97,
      "grad_norm": 1.1289513111114502,
      "learning_rate": 9.171482391154173e-06,
      "loss": 0.9123,
      "step": 14020
    },
    {
      "epoch": 75.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4067707061767578,
      "eval_runtime": 1.3721,
      "eval_samples_per_second": 24.052,
      "eval_steps_per_second": 2.187,
      "step": 14025
    },
    {
      "epoch": 75.03,
      "grad_norm": 0.9780113101005554,
      "learning_rate": 9.134359376317302e-06,
      "loss": 0.8385,
      "step": 14030
    },
    {
      "epoch": 75.08,
      "grad_norm": 1.871816635131836,
      "learning_rate": 9.0972987803579e-06,
      "loss": 0.9357,
      "step": 14040
    },
    {
      "epoch": 75.13,
      "grad_norm": 0.970511257648468,
      "learning_rate": 9.060300707875321e-06,
      "loss": 0.861,
      "step": 14050
    },
    {
      "epoch": 75.19,
      "grad_norm": 0.9911666512489319,
      "learning_rate": 9.023365263292384e-06,
      "loss": 0.8699,
      "step": 14060
    },
    {
      "epoch": 75.24,
      "grad_norm": 1.66132390499115,
      "learning_rate": 8.98649255085518e-06,
      "loss": 0.8408,
      "step": 14070
    },
    {
      "epoch": 75.29,
      "grad_norm": 0.7976709604263306,
      "learning_rate": 8.949682674632743e-06,
      "loss": 0.9423,
      "step": 14080
    },
    {
      "epoch": 75.35,
      "grad_norm": 0.9125333428382874,
      "learning_rate": 8.912935738516763e-06,
      "loss": 0.803,
      "step": 14090
    },
    {
      "epoch": 75.4,
      "grad_norm": 0.8652144074440002,
      "learning_rate": 8.876251846221272e-06,
      "loss": 0.8913,
      "step": 14100
    },
    {
      "epoch": 75.45,
      "grad_norm": 0.9919486045837402,
      "learning_rate": 8.839631101282393e-06,
      "loss": 0.9422,
      "step": 14110
    },
    {
      "epoch": 75.51,
      "grad_norm": 1.2737386226654053,
      "learning_rate": 8.803073607057996e-06,
      "loss": 0.9548,
      "step": 14120
    },
    {
      "epoch": 75.56,
      "grad_norm": 1.2198271751403809,
      "learning_rate": 8.766579466727456e-06,
      "loss": 0.9741,
      "step": 14130
    },
    {
      "epoch": 75.61,
      "grad_norm": 1.9913324117660522,
      "learning_rate": 8.730148783291329e-06,
      "loss": 0.9991,
      "step": 14140
    },
    {
      "epoch": 75.67,
      "grad_norm": 0.8826116919517517,
      "learning_rate": 8.693781659571049e-06,
      "loss": 1.0304,
      "step": 14150
    },
    {
      "epoch": 75.72,
      "grad_norm": 0.645530104637146,
      "learning_rate": 8.657478198208716e-06,
      "loss": 0.8888,
      "step": 14160
    },
    {
      "epoch": 75.78,
      "grad_norm": 1.0326462984085083,
      "learning_rate": 8.621238501666683e-06,
      "loss": 0.9988,
      "step": 14170
    },
    {
      "epoch": 75.83,
      "grad_norm": 0.9935339689254761,
      "learning_rate": 8.5850626722274e-06,
      "loss": 0.8984,
      "step": 14180
    },
    {
      "epoch": 75.88,
      "grad_norm": 1.454581618309021,
      "learning_rate": 8.548950811993e-06,
      "loss": 0.9111,
      "step": 14190
    },
    {
      "epoch": 75.94,
      "grad_norm": 0.9165312647819519,
      "learning_rate": 8.512903022885107e-06,
      "loss": 0.864,
      "step": 14200
    },
    {
      "epoch": 75.99,
      "grad_norm": 0.9137063026428223,
      "learning_rate": 8.4769194066445e-06,
      "loss": 0.9065,
      "step": 14210
    },
    {
      "epoch": 76.0,
      "eval_accuracy": 0.48484848484848486,
      "eval_loss": 1.3721907138824463,
      "eval_runtime": 1.2341,
      "eval_samples_per_second": 26.739,
      "eval_steps_per_second": 2.431,
      "step": 14212
    },
    {
      "epoch": 76.04,
      "grad_norm": 1.0581047534942627,
      "learning_rate": 8.441000064830836e-06,
      "loss": 0.9728,
      "step": 14220
    },
    {
      "epoch": 76.1,
      "grad_norm": 0.9328869581222534,
      "learning_rate": 8.405145098822373e-06,
      "loss": 0.7833,
      "step": 14230
    },
    {
      "epoch": 76.15,
      "grad_norm": 0.7819300293922424,
      "learning_rate": 8.369354609815665e-06,
      "loss": 0.9048,
      "step": 14240
    },
    {
      "epoch": 76.2,
      "grad_norm": 0.9476251602172852,
      "learning_rate": 8.333628698825296e-06,
      "loss": 0.9974,
      "step": 14250
    },
    {
      "epoch": 76.26,
      "grad_norm": 1.2401710748672485,
      "learning_rate": 8.29796746668358e-06,
      "loss": 0.9064,
      "step": 14260
    },
    {
      "epoch": 76.31,
      "grad_norm": 0.769805908203125,
      "learning_rate": 8.262371014040294e-06,
      "loss": 0.7958,
      "step": 14270
    },
    {
      "epoch": 76.36,
      "grad_norm": 1.1645673513412476,
      "learning_rate": 8.226839441362342e-06,
      "loss": 1.0032,
      "step": 14280
    },
    {
      "epoch": 76.42,
      "grad_norm": 1.2382100820541382,
      "learning_rate": 8.191372848933585e-06,
      "loss": 0.9507,
      "step": 14290
    },
    {
      "epoch": 76.47,
      "grad_norm": 0.9644703269004822,
      "learning_rate": 8.155971336854407e-06,
      "loss": 0.8967,
      "step": 14300
    },
    {
      "epoch": 76.52,
      "grad_norm": 1.4186314344406128,
      "learning_rate": 8.12063500504156e-06,
      "loss": 0.9447,
      "step": 14310
    },
    {
      "epoch": 76.58,
      "grad_norm": 1.0212119817733765,
      "learning_rate": 8.085363953227812e-06,
      "loss": 0.7626,
      "step": 14320
    },
    {
      "epoch": 76.63,
      "grad_norm": 1.1321487426757812,
      "learning_rate": 8.050158280961694e-06,
      "loss": 0.8488,
      "step": 14330
    },
    {
      "epoch": 76.68,
      "grad_norm": 1.1252880096435547,
      "learning_rate": 8.015018087607208e-06,
      "loss": 0.8962,
      "step": 14340
    },
    {
      "epoch": 76.74,
      "grad_norm": 1.5766903162002563,
      "learning_rate": 7.979943472343543e-06,
      "loss": 0.9281,
      "step": 14350
    },
    {
      "epoch": 76.79,
      "grad_norm": 0.8369399309158325,
      "learning_rate": 7.944934534164813e-06,
      "loss": 0.9745,
      "step": 14360
    },
    {
      "epoch": 76.84,
      "grad_norm": 0.9038348197937012,
      "learning_rate": 7.909991371879762e-06,
      "loss": 0.8689,
      "step": 14370
    },
    {
      "epoch": 76.9,
      "grad_norm": 1.1608848571777344,
      "learning_rate": 7.875114084111478e-06,
      "loss": 0.8859,
      "step": 14380
    },
    {
      "epoch": 76.95,
      "grad_norm": 1.1699867248535156,
      "learning_rate": 7.840302769297138e-06,
      "loss": 0.881,
      "step": 14390
    },
    {
      "epoch": 77.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4006038904190063,
      "eval_runtime": 1.1843,
      "eval_samples_per_second": 27.865,
      "eval_steps_per_second": 2.533,
      "step": 14399
    },
    {
      "epoch": 77.01,
      "grad_norm": 1.051487684249878,
      "learning_rate": 7.805557525687727e-06,
      "loss": 0.9721,
      "step": 14400
    },
    {
      "epoch": 77.06,
      "grad_norm": 1.132468581199646,
      "learning_rate": 7.770878451347708e-06,
      "loss": 0.9374,
      "step": 14410
    },
    {
      "epoch": 77.11,
      "grad_norm": 0.9857737421989441,
      "learning_rate": 7.736265644154853e-06,
      "loss": 0.8609,
      "step": 14420
    },
    {
      "epoch": 77.17,
      "grad_norm": 0.88675457239151,
      "learning_rate": 7.70171920179985e-06,
      "loss": 0.897,
      "step": 14430
    },
    {
      "epoch": 77.22,
      "grad_norm": 1.1130292415618896,
      "learning_rate": 7.667239221786102e-06,
      "loss": 0.8386,
      "step": 14440
    },
    {
      "epoch": 77.27,
      "grad_norm": 0.9866640567779541,
      "learning_rate": 7.632825801429433e-06,
      "loss": 1.0733,
      "step": 14450
    },
    {
      "epoch": 77.33,
      "grad_norm": 0.9991300106048584,
      "learning_rate": 7.598479037857795e-06,
      "loss": 1.0505,
      "step": 14460
    },
    {
      "epoch": 77.38,
      "grad_norm": 1.0507826805114746,
      "learning_rate": 7.564199028011021e-06,
      "loss": 0.8933,
      "step": 14470
    },
    {
      "epoch": 77.43,
      "grad_norm": 1.4718279838562012,
      "learning_rate": 7.529985868640537e-06,
      "loss": 0.924,
      "step": 14480
    },
    {
      "epoch": 77.49,
      "grad_norm": 1.3940693140029907,
      "learning_rate": 7.4958396563090876e-06,
      "loss": 0.9193,
      "step": 14490
    },
    {
      "epoch": 77.54,
      "grad_norm": 0.9197521209716797,
      "learning_rate": 7.46176048739047e-06,
      "loss": 0.8632,
      "step": 14500
    },
    {
      "epoch": 77.59,
      "grad_norm": 0.9250284433364868,
      "learning_rate": 7.427748458069265e-06,
      "loss": 0.8207,
      "step": 14510
    },
    {
      "epoch": 77.65,
      "grad_norm": 1.0612983703613281,
      "learning_rate": 7.393803664340532e-06,
      "loss": 0.9886,
      "step": 14520
    },
    {
      "epoch": 77.7,
      "grad_norm": 1.2444136142730713,
      "learning_rate": 7.359926202009613e-06,
      "loss": 0.8578,
      "step": 14530
    },
    {
      "epoch": 77.75,
      "grad_norm": 0.8353762030601501,
      "learning_rate": 7.326116166691762e-06,
      "loss": 0.906,
      "step": 14540
    },
    {
      "epoch": 77.81,
      "grad_norm": 0.9548288583755493,
      "learning_rate": 7.292373653811982e-06,
      "loss": 0.8665,
      "step": 14550
    },
    {
      "epoch": 77.86,
      "grad_norm": 0.916886568069458,
      "learning_rate": 7.258698758604649e-06,
      "loss": 0.9337,
      "step": 14560
    },
    {
      "epoch": 77.91,
      "grad_norm": 0.8291250467300415,
      "learning_rate": 7.22509157611333e-06,
      "loss": 0.7854,
      "step": 14570
    },
    {
      "epoch": 77.97,
      "grad_norm": 1.5406030416488647,
      "learning_rate": 7.191552201190471e-06,
      "loss": 0.8633,
      "step": 14580
    },
    {
      "epoch": 78.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3962939977645874,
      "eval_runtime": 1.2203,
      "eval_samples_per_second": 27.042,
      "eval_steps_per_second": 2.458,
      "step": 14586
    },
    {
      "epoch": 78.02,
      "grad_norm": 1.2695103883743286,
      "learning_rate": 7.1580807284971386e-06,
      "loss": 0.8465,
      "step": 14590
    },
    {
      "epoch": 78.07,
      "grad_norm": 1.3470038175582886,
      "learning_rate": 7.124677252502751e-06,
      "loss": 0.9182,
      "step": 14600
    },
    {
      "epoch": 78.13,
      "grad_norm": 1.1567732095718384,
      "learning_rate": 7.091341867484821e-06,
      "loss": 0.834,
      "step": 14610
    },
    {
      "epoch": 78.18,
      "grad_norm": 0.9661362767219543,
      "learning_rate": 7.058074667528672e-06,
      "loss": 0.8367,
      "step": 14620
    },
    {
      "epoch": 78.24,
      "grad_norm": 1.016910433769226,
      "learning_rate": 7.024875746527191e-06,
      "loss": 0.8547,
      "step": 14630
    },
    {
      "epoch": 78.29,
      "grad_norm": 1.0380852222442627,
      "learning_rate": 6.99174519818056e-06,
      "loss": 0.8437,
      "step": 14640
    },
    {
      "epoch": 78.34,
      "grad_norm": 0.9872055649757385,
      "learning_rate": 6.958683115995953e-06,
      "loss": 0.9108,
      "step": 14650
    },
    {
      "epoch": 78.4,
      "grad_norm": 0.9365540742874146,
      "learning_rate": 6.92568959328737e-06,
      "loss": 0.9618,
      "step": 14660
    },
    {
      "epoch": 78.45,
      "grad_norm": 0.6269148588180542,
      "learning_rate": 6.892764723175231e-06,
      "loss": 0.9607,
      "step": 14670
    },
    {
      "epoch": 78.5,
      "grad_norm": 1.0933071374893188,
      "learning_rate": 6.859908598586272e-06,
      "loss": 0.7903,
      "step": 14680
    },
    {
      "epoch": 78.56,
      "grad_norm": 1.055513620376587,
      "learning_rate": 6.827121312253139e-06,
      "loss": 1.037,
      "step": 14690
    },
    {
      "epoch": 78.61,
      "grad_norm": 1.5267109870910645,
      "learning_rate": 6.79440295671422e-06,
      "loss": 0.8907,
      "step": 14700
    },
    {
      "epoch": 78.66,
      "grad_norm": 1.205776572227478,
      "learning_rate": 6.76175362431335e-06,
      "loss": 0.9365,
      "step": 14710
    },
    {
      "epoch": 78.72,
      "grad_norm": 1.2419670820236206,
      "learning_rate": 6.72917340719955e-06,
      "loss": 0.9542,
      "step": 14720
    },
    {
      "epoch": 78.77,
      "grad_norm": 0.7599920034408569,
      "learning_rate": 6.696662397326775e-06,
      "loss": 0.8786,
      "step": 14730
    },
    {
      "epoch": 78.82,
      "grad_norm": 1.183388113975525,
      "learning_rate": 6.664220686453649e-06,
      "loss": 0.8509,
      "step": 14740
    },
    {
      "epoch": 78.88,
      "grad_norm": 0.6213520169258118,
      "learning_rate": 6.631848366143205e-06,
      "loss": 0.8979,
      "step": 14750
    },
    {
      "epoch": 78.93,
      "grad_norm": 0.9526179432868958,
      "learning_rate": 6.599545527762631e-06,
      "loss": 0.9036,
      "step": 14760
    },
    {
      "epoch": 78.98,
      "grad_norm": 1.165330171585083,
      "learning_rate": 6.56731226248302e-06,
      "loss": 0.9684,
      "step": 14770
    },
    {
      "epoch": 79.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.4043469429016113,
      "eval_runtime": 1.1791,
      "eval_samples_per_second": 27.988,
      "eval_steps_per_second": 2.544,
      "step": 14773
    },
    {
      "epoch": 79.04,
      "grad_norm": 1.2785844802856445,
      "learning_rate": 6.535148661279067e-06,
      "loss": 0.9648,
      "step": 14780
    },
    {
      "epoch": 79.09,
      "grad_norm": 0.6939456462860107,
      "learning_rate": 6.5030548149289066e-06,
      "loss": 0.8835,
      "step": 14790
    },
    {
      "epoch": 79.14,
      "grad_norm": 1.1434565782546997,
      "learning_rate": 6.471030814013738e-06,
      "loss": 0.965,
      "step": 14800
    },
    {
      "epoch": 79.2,
      "grad_norm": 0.9518351554870605,
      "learning_rate": 6.439076748917684e-06,
      "loss": 0.9163,
      "step": 14810
    },
    {
      "epoch": 79.25,
      "grad_norm": 0.7388201355934143,
      "learning_rate": 6.407192709827432e-06,
      "loss": 0.8004,
      "step": 14820
    },
    {
      "epoch": 79.3,
      "grad_norm": 0.7790269255638123,
      "learning_rate": 6.3753787867320625e-06,
      "loss": 1.0464,
      "step": 14830
    },
    {
      "epoch": 79.36,
      "grad_norm": 0.8831649422645569,
      "learning_rate": 6.3436350694227454e-06,
      "loss": 0.9382,
      "step": 14840
    },
    {
      "epoch": 79.41,
      "grad_norm": 0.8509622812271118,
      "learning_rate": 6.311961647492516e-06,
      "loss": 0.9496,
      "step": 14850
    },
    {
      "epoch": 79.47,
      "grad_norm": 0.7895591259002686,
      "learning_rate": 6.280358610335997e-06,
      "loss": 0.9291,
      "step": 14860
    },
    {
      "epoch": 79.52,
      "grad_norm": 1.5257847309112549,
      "learning_rate": 6.248826047149162e-06,
      "loss": 0.8969,
      "step": 14870
    },
    {
      "epoch": 79.57,
      "grad_norm": 1.025288701057434,
      "learning_rate": 6.217364046929082e-06,
      "loss": 0.8302,
      "step": 14880
    },
    {
      "epoch": 79.63,
      "grad_norm": 1.395444631576538,
      "learning_rate": 6.1859726984736655e-06,
      "loss": 0.8498,
      "step": 14890
    },
    {
      "epoch": 79.68,
      "grad_norm": 0.7056431770324707,
      "learning_rate": 6.154652090381435e-06,
      "loss": 0.8963,
      "step": 14900
    },
    {
      "epoch": 79.73,
      "grad_norm": 1.6359398365020752,
      "learning_rate": 6.123402311051209e-06,
      "loss": 0.9686,
      "step": 14910
    },
    {
      "epoch": 79.79,
      "grad_norm": 1.0897127389907837,
      "learning_rate": 6.092223448681971e-06,
      "loss": 0.9077,
      "step": 14920
    },
    {
      "epoch": 79.84,
      "grad_norm": 1.5122660398483276,
      "learning_rate": 6.061115591272478e-06,
      "loss": 0.8918,
      "step": 14930
    },
    {
      "epoch": 79.89,
      "grad_norm": 0.8436965346336365,
      "learning_rate": 6.03007882662113e-06,
      "loss": 0.9074,
      "step": 14940
    },
    {
      "epoch": 79.95,
      "grad_norm": 0.7330672144889832,
      "learning_rate": 5.9991132423256565e-06,
      "loss": 0.9734,
      "step": 14950
    },
    {
      "epoch": 80.0,
      "grad_norm": 1.8423469066619873,
      "learning_rate": 5.9682189257828954e-06,
      "loss": 0.94,
      "step": 14960
    },
    {
      "epoch": 80.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3737012147903442,
      "eval_runtime": 1.1872,
      "eval_samples_per_second": 27.795,
      "eval_steps_per_second": 2.527,
      "step": 14960
    },
    {
      "epoch": 80.05,
      "grad_norm": 1.1527137756347656,
      "learning_rate": 5.937395964188536e-06,
      "loss": 0.9858,
      "step": 14970
    },
    {
      "epoch": 80.11,
      "grad_norm": 1.3654435873031616,
      "learning_rate": 5.906644444536882e-06,
      "loss": 0.9067,
      "step": 14980
    },
    {
      "epoch": 80.16,
      "grad_norm": 0.8928994536399841,
      "learning_rate": 5.87596445362059e-06,
      "loss": 0.8707,
      "step": 14990
    },
    {
      "epoch": 80.21,
      "grad_norm": 1.1103360652923584,
      "learning_rate": 5.845356078030447e-06,
      "loss": 0.8912,
      "step": 15000
    },
    {
      "epoch": 80.27,
      "grad_norm": 0.9583021402359009,
      "learning_rate": 5.814819404155104e-06,
      "loss": 0.8702,
      "step": 15010
    },
    {
      "epoch": 80.32,
      "grad_norm": 1.460249423980713,
      "learning_rate": 5.784354518180848e-06,
      "loss": 0.9397,
      "step": 15020
    },
    {
      "epoch": 80.37,
      "grad_norm": 0.8426933288574219,
      "learning_rate": 5.753961506091359e-06,
      "loss": 0.8294,
      "step": 15030
    },
    {
      "epoch": 80.43,
      "grad_norm": 0.8736411333084106,
      "learning_rate": 5.723640453667425e-06,
      "loss": 0.9495,
      "step": 15040
    },
    {
      "epoch": 80.48,
      "grad_norm": 1.089463710784912,
      "learning_rate": 5.693391446486802e-06,
      "loss": 0.8474,
      "step": 15050
    },
    {
      "epoch": 80.53,
      "grad_norm": 1.4191195964813232,
      "learning_rate": 5.663214569923837e-06,
      "loss": 0.8914,
      "step": 15060
    },
    {
      "epoch": 80.59,
      "grad_norm": 1.2529624700546265,
      "learning_rate": 5.6331099091493435e-06,
      "loss": 0.8946,
      "step": 15070
    },
    {
      "epoch": 80.64,
      "grad_norm": 1.1968203783035278,
      "learning_rate": 5.603077549130295e-06,
      "loss": 1.0545,
      "step": 15080
    },
    {
      "epoch": 80.7,
      "grad_norm": 1.1266602277755737,
      "learning_rate": 5.573117574629607e-06,
      "loss": 0.807,
      "step": 15090
    },
    {
      "epoch": 80.75,
      "grad_norm": 0.9697204232215881,
      "learning_rate": 5.5432300702059e-06,
      "loss": 0.832,
      "step": 15100
    },
    {
      "epoch": 80.8,
      "grad_norm": 1.9037997722625732,
      "learning_rate": 5.51341512021325e-06,
      "loss": 1.0576,
      "step": 15110
    },
    {
      "epoch": 80.86,
      "grad_norm": 0.8535979986190796,
      "learning_rate": 5.483672808800959e-06,
      "loss": 1.0352,
      "step": 15120
    },
    {
      "epoch": 80.91,
      "grad_norm": 0.8803690075874329,
      "learning_rate": 5.454003219913312e-06,
      "loss": 0.8993,
      "step": 15130
    },
    {
      "epoch": 80.96,
      "grad_norm": 0.9868786931037903,
      "learning_rate": 5.424406437289357e-06,
      "loss": 0.8676,
      "step": 15140
    },
    {
      "epoch": 81.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3814592361450195,
      "eval_runtime": 1.1497,
      "eval_samples_per_second": 28.703,
      "eval_steps_per_second": 2.609,
      "step": 15147
    },
    {
      "epoch": 81.02,
      "grad_norm": 0.7465299367904663,
      "learning_rate": 5.394882544462617e-06,
      "loss": 0.7866,
      "step": 15150
    },
    {
      "epoch": 81.07,
      "grad_norm": 1.1103225946426392,
      "learning_rate": 5.365431624760948e-06,
      "loss": 0.9695,
      "step": 15160
    },
    {
      "epoch": 81.12,
      "grad_norm": 1.0625519752502441,
      "learning_rate": 5.336053761306192e-06,
      "loss": 0.8791,
      "step": 15170
    },
    {
      "epoch": 81.18,
      "grad_norm": 0.9015143513679504,
      "learning_rate": 5.3067490370140475e-06,
      "loss": 0.9006,
      "step": 15180
    },
    {
      "epoch": 81.23,
      "grad_norm": 0.7897782325744629,
      "learning_rate": 5.27751753459374e-06,
      "loss": 0.9084,
      "step": 15190
    },
    {
      "epoch": 81.28,
      "grad_norm": 0.8704388737678528,
      "learning_rate": 5.2483593365478705e-06,
      "loss": 0.902,
      "step": 15200
    },
    {
      "epoch": 81.34,
      "grad_norm": 0.7404307126998901,
      "learning_rate": 5.219274525172124e-06,
      "loss": 0.9459,
      "step": 15210
    },
    {
      "epoch": 81.39,
      "grad_norm": 0.7828346490859985,
      "learning_rate": 5.190263182555076e-06,
      "loss": 0.8683,
      "step": 15220
    },
    {
      "epoch": 81.44,
      "grad_norm": 0.9937474727630615,
      "learning_rate": 5.161325390577936e-06,
      "loss": 0.907,
      "step": 15230
    },
    {
      "epoch": 81.5,
      "grad_norm": 1.31710684299469,
      "learning_rate": 5.132461230914327e-06,
      "loss": 0.897,
      "step": 15240
    },
    {
      "epoch": 81.55,
      "grad_norm": 0.9319556355476379,
      "learning_rate": 5.1036707850300495e-06,
      "loss": 0.8547,
      "step": 15250
    },
    {
      "epoch": 81.6,
      "grad_norm": 1.5161011219024658,
      "learning_rate": 5.074954134182862e-06,
      "loss": 0.8379,
      "step": 15260
    },
    {
      "epoch": 81.66,
      "grad_norm": 0.8879026770591736,
      "learning_rate": 5.046311359422251e-06,
      "loss": 1.0347,
      "step": 15270
    },
    {
      "epoch": 81.71,
      "grad_norm": 0.759087860584259,
      "learning_rate": 5.017742541589161e-06,
      "loss": 0.8849,
      "step": 15280
    },
    {
      "epoch": 81.76,
      "grad_norm": 1.2827239036560059,
      "learning_rate": 4.989247761315856e-06,
      "loss": 0.8776,
      "step": 15290
    },
    {
      "epoch": 81.82,
      "grad_norm": 0.7864162921905518,
      "learning_rate": 4.960827099025584e-06,
      "loss": 0.8785,
      "step": 15300
    },
    {
      "epoch": 81.87,
      "grad_norm": 2.1578938961029053,
      "learning_rate": 4.932480634932457e-06,
      "loss": 0.902,
      "step": 15310
    },
    {
      "epoch": 81.93,
      "grad_norm": 0.8203622102737427,
      "learning_rate": 4.904208449041117e-06,
      "loss": 0.9125,
      "step": 15320
    },
    {
      "epoch": 81.98,
      "grad_norm": 0.9930400848388672,
      "learning_rate": 4.876010621146596e-06,
      "loss": 0.8638,
      "step": 15330
    },
    {
      "epoch": 82.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.3965798616409302,
      "eval_runtime": 1.162,
      "eval_samples_per_second": 28.398,
      "eval_steps_per_second": 2.582,
      "step": 15334
    },
    {
      "epoch": 82.03,
      "grad_norm": 1.4780871868133545,
      "learning_rate": 4.847887230834056e-06,
      "loss": 0.9436,
      "step": 15340
    },
    {
      "epoch": 82.09,
      "grad_norm": 0.8479720950126648,
      "learning_rate": 4.819838357478564e-06,
      "loss": 0.8902,
      "step": 15350
    },
    {
      "epoch": 82.14,
      "grad_norm": 1.5410274267196655,
      "learning_rate": 4.7918640802448696e-06,
      "loss": 0.9022,
      "step": 15360
    },
    {
      "epoch": 82.19,
      "grad_norm": 1.006075382232666,
      "learning_rate": 4.763964478087183e-06,
      "loss": 0.8791,
      "step": 15370
    },
    {
      "epoch": 82.25,
      "grad_norm": 1.109540343284607,
      "learning_rate": 4.736139629748962e-06,
      "loss": 0.9309,
      "step": 15380
    },
    {
      "epoch": 82.3,
      "grad_norm": 0.6601468324661255,
      "learning_rate": 4.708389613762666e-06,
      "loss": 0.8364,
      "step": 15390
    },
    {
      "epoch": 82.35,
      "grad_norm": 0.6888267993927002,
      "learning_rate": 4.680714508449563e-06,
      "loss": 0.9292,
      "step": 15400
    },
    {
      "epoch": 82.41,
      "grad_norm": 1.0623764991760254,
      "learning_rate": 4.653114391919466e-06,
      "loss": 0.9476,
      "step": 15410
    },
    {
      "epoch": 82.46,
      "grad_norm": 1.6252317428588867,
      "learning_rate": 4.625589342070593e-06,
      "loss": 0.889,
      "step": 15420
    },
    {
      "epoch": 82.51,
      "grad_norm": 0.9153058528900146,
      "learning_rate": 4.598139436589238e-06,
      "loss": 0.891,
      "step": 15430
    },
    {
      "epoch": 82.57,
      "grad_norm": 1.1321181058883667,
      "learning_rate": 4.570764752949642e-06,
      "loss": 0.8389,
      "step": 15440
    },
    {
      "epoch": 82.62,
      "grad_norm": 0.9800272583961487,
      "learning_rate": 4.54346536841373e-06,
      "loss": 0.9523,
      "step": 15450
    },
    {
      "epoch": 82.67,
      "grad_norm": 1.65186607837677,
      "learning_rate": 4.516241360030912e-06,
      "loss": 0.9422,
      "step": 15460
    },
    {
      "epoch": 82.73,
      "grad_norm": 0.9645957946777344,
      "learning_rate": 4.489092804637846e-06,
      "loss": 0.9708,
      "step": 15470
    },
    {
      "epoch": 82.78,
      "grad_norm": 0.8139657378196716,
      "learning_rate": 4.462019778858243e-06,
      "loss": 0.9048,
      "step": 15480
    },
    {
      "epoch": 82.83,
      "grad_norm": 1.2652286291122437,
      "learning_rate": 4.43502235910263e-06,
      "loss": 1.0038,
      "step": 15490
    },
    {
      "epoch": 82.89,
      "grad_norm": 1.4561580419540405,
      "learning_rate": 4.40810062156816e-06,
      "loss": 0.9099,
      "step": 15500
    },
    {
      "epoch": 82.94,
      "grad_norm": 0.9606526494026184,
      "learning_rate": 4.381254642238361e-06,
      "loss": 0.8466,
      "step": 15510
    },
    {
      "epoch": 82.99,
      "grad_norm": 0.8003670573234558,
      "learning_rate": 4.354484496882961e-06,
      "loss": 0.8195,
      "step": 15520
    },
    {
      "epoch": 83.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4109565019607544,
      "eval_runtime": 1.2495,
      "eval_samples_per_second": 26.411,
      "eval_steps_per_second": 2.401,
      "step": 15521
    },
    {
      "epoch": 83.05,
      "grad_norm": 0.7915807962417603,
      "learning_rate": 4.327790261057646e-06,
      "loss": 0.8769,
      "step": 15530
    },
    {
      "epoch": 83.1,
      "grad_norm": 0.7951882481575012,
      "learning_rate": 4.301172010103844e-06,
      "loss": 0.8579,
      "step": 15540
    },
    {
      "epoch": 83.16,
      "grad_norm": 1.2272447347640991,
      "learning_rate": 4.27462981914856e-06,
      "loss": 0.8319,
      "step": 15550
    },
    {
      "epoch": 83.21,
      "grad_norm": 1.3175394535064697,
      "learning_rate": 4.2481637631040895e-06,
      "loss": 0.8797,
      "step": 15560
    },
    {
      "epoch": 83.26,
      "grad_norm": 0.8811212778091431,
      "learning_rate": 4.221773916667868e-06,
      "loss": 0.9145,
      "step": 15570
    },
    {
      "epoch": 83.32,
      "grad_norm": 1.4439189434051514,
      "learning_rate": 4.195460354322226e-06,
      "loss": 0.9523,
      "step": 15580
    },
    {
      "epoch": 83.37,
      "grad_norm": 1.0441991090774536,
      "learning_rate": 4.169223150334206e-06,
      "loss": 0.9549,
      "step": 15590
    },
    {
      "epoch": 83.42,
      "grad_norm": 0.6893610954284668,
      "learning_rate": 4.143062378755322e-06,
      "loss": 0.9536,
      "step": 15600
    },
    {
      "epoch": 83.48,
      "grad_norm": 0.8255407810211182,
      "learning_rate": 4.116978113421377e-06,
      "loss": 0.9128,
      "step": 15610
    },
    {
      "epoch": 83.53,
      "grad_norm": 1.1144887208938599,
      "learning_rate": 4.090970427952239e-06,
      "loss": 0.8584,
      "step": 15620
    },
    {
      "epoch": 83.58,
      "grad_norm": 1.0551955699920654,
      "learning_rate": 4.065039395751639e-06,
      "loss": 0.9379,
      "step": 15630
    },
    {
      "epoch": 83.64,
      "grad_norm": 1.0508661270141602,
      "learning_rate": 4.039185090006968e-06,
      "loss": 0.964,
      "step": 15640
    },
    {
      "epoch": 83.69,
      "grad_norm": 0.9472659230232239,
      "learning_rate": 4.0134075836890415e-06,
      "loss": 0.8519,
      "step": 15650
    },
    {
      "epoch": 83.74,
      "grad_norm": 1.0225154161453247,
      "learning_rate": 3.987706949551962e-06,
      "loss": 0.9493,
      "step": 15660
    },
    {
      "epoch": 83.8,
      "grad_norm": 1.1664762496948242,
      "learning_rate": 3.962083260132816e-06,
      "loss": 0.9244,
      "step": 15670
    },
    {
      "epoch": 83.85,
      "grad_norm": 0.8815213441848755,
      "learning_rate": 3.936536587751578e-06,
      "loss": 0.9708,
      "step": 15680
    },
    {
      "epoch": 83.9,
      "grad_norm": 1.1631337404251099,
      "learning_rate": 3.911067004510799e-06,
      "loss": 0.8914,
      "step": 15690
    },
    {
      "epoch": 83.96,
      "grad_norm": 1.5434234142303467,
      "learning_rate": 3.885674582295485e-06,
      "loss": 0.9366,
      "step": 15700
    },
    {
      "epoch": 84.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.365744709968567,
      "eval_runtime": 1.1733,
      "eval_samples_per_second": 28.126,
      "eval_steps_per_second": 2.557,
      "step": 15708
    },
    {
      "epoch": 84.01,
      "grad_norm": 1.0679118633270264,
      "learning_rate": 3.86035939277286e-06,
      "loss": 0.9144,
      "step": 15710
    },
    {
      "epoch": 84.06,
      "grad_norm": 0.9662187099456787,
      "learning_rate": 3.835121507392157e-06,
      "loss": 0.933,
      "step": 15720
    },
    {
      "epoch": 84.12,
      "grad_norm": 1.271429419517517,
      "learning_rate": 3.80996099738444e-06,
      "loss": 0.8564,
      "step": 15730
    },
    {
      "epoch": 84.17,
      "grad_norm": 0.9178835153579712,
      "learning_rate": 3.7848779337623824e-06,
      "loss": 0.8805,
      "step": 15740
    },
    {
      "epoch": 84.22,
      "grad_norm": 1.3803788423538208,
      "learning_rate": 3.7598723873200727e-06,
      "loss": 0.8304,
      "step": 15750
    },
    {
      "epoch": 84.28,
      "grad_norm": 0.8639649152755737,
      "learning_rate": 3.7349444286328207e-06,
      "loss": 0.91,
      "step": 15760
    },
    {
      "epoch": 84.33,
      "grad_norm": 1.6322485208511353,
      "learning_rate": 3.710094128056958e-06,
      "loss": 0.9489,
      "step": 15770
    },
    {
      "epoch": 84.39,
      "grad_norm": 0.8407437205314636,
      "learning_rate": 3.6853215557296067e-06,
      "loss": 0.9056,
      "step": 15780
    },
    {
      "epoch": 84.44,
      "grad_norm": 1.4216681718826294,
      "learning_rate": 3.66062678156856e-06,
      "loss": 0.8688,
      "step": 15790
    },
    {
      "epoch": 84.49,
      "grad_norm": 1.0641162395477295,
      "learning_rate": 3.6360098752719792e-06,
      "loss": 0.9318,
      "step": 15800
    },
    {
      "epoch": 84.55,
      "grad_norm": 0.7505508661270142,
      "learning_rate": 3.6114709063183037e-06,
      "loss": 0.9571,
      "step": 15810
    },
    {
      "epoch": 84.6,
      "grad_norm": 0.8499890565872192,
      "learning_rate": 3.587009943965963e-06,
      "loss": 0.8356,
      "step": 15820
    },
    {
      "epoch": 84.65,
      "grad_norm": 0.7949763536453247,
      "learning_rate": 3.5626270572532427e-06,
      "loss": 0.9317,
      "step": 15830
    },
    {
      "epoch": 84.71,
      "grad_norm": 1.2315773963928223,
      "learning_rate": 3.538322314998066e-06,
      "loss": 0.929,
      "step": 15840
    },
    {
      "epoch": 84.76,
      "grad_norm": 1.2759655714035034,
      "learning_rate": 3.5140957857978036e-06,
      "loss": 0.9462,
      "step": 15850
    },
    {
      "epoch": 84.81,
      "grad_norm": 1.643829107284546,
      "learning_rate": 3.4899475380290593e-06,
      "loss": 0.9748,
      "step": 15860
    },
    {
      "epoch": 84.87,
      "grad_norm": 1.1190710067749023,
      "learning_rate": 3.465877639847532e-06,
      "loss": 0.9344,
      "step": 15870
    },
    {
      "epoch": 84.92,
      "grad_norm": 1.0877399444580078,
      "learning_rate": 3.4418861591877583e-06,
      "loss": 0.9049,
      "step": 15880
    },
    {
      "epoch": 84.97,
      "grad_norm": 1.4192696809768677,
      "learning_rate": 3.4179731637629665e-06,
      "loss": 0.9529,
      "step": 15890
    },
    {
      "epoch": 85.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3867706060409546,
      "eval_runtime": 1.1814,
      "eval_samples_per_second": 27.934,
      "eval_steps_per_second": 2.539,
      "step": 15895
    },
    {
      "epoch": 85.03,
      "grad_norm": 0.8926023244857788,
      "learning_rate": 3.3941387210648654e-06,
      "loss": 0.8497,
      "step": 15900
    },
    {
      "epoch": 85.08,
      "grad_norm": 0.8909028172492981,
      "learning_rate": 3.3703828983634372e-06,
      "loss": 0.8838,
      "step": 15910
    },
    {
      "epoch": 85.13,
      "grad_norm": 0.7950834035873413,
      "learning_rate": 3.346705762706813e-06,
      "loss": 0.8985,
      "step": 15920
    },
    {
      "epoch": 85.19,
      "grad_norm": 0.9291608929634094,
      "learning_rate": 3.323107380920988e-06,
      "loss": 0.9221,
      "step": 15930
    },
    {
      "epoch": 85.24,
      "grad_norm": 1.042755126953125,
      "learning_rate": 3.299587819609727e-06,
      "loss": 0.9434,
      "step": 15940
    },
    {
      "epoch": 85.29,
      "grad_norm": 1.1155091524124146,
      "learning_rate": 3.2761471451543054e-06,
      "loss": 0.8863,
      "step": 15950
    },
    {
      "epoch": 85.35,
      "grad_norm": 1.094356656074524,
      "learning_rate": 3.252785423713354e-06,
      "loss": 0.9361,
      "step": 15960
    },
    {
      "epoch": 85.4,
      "grad_norm": 1.2092359066009521,
      "learning_rate": 3.2295027212226775e-06,
      "loss": 0.8547,
      "step": 15970
    },
    {
      "epoch": 85.45,
      "grad_norm": 0.7761606574058533,
      "learning_rate": 3.2062991033950557e-06,
      "loss": 0.9067,
      "step": 15980
    },
    {
      "epoch": 85.51,
      "grad_norm": 1.1451588869094849,
      "learning_rate": 3.183174635720043e-06,
      "loss": 0.8989,
      "step": 15990
    },
    {
      "epoch": 85.56,
      "grad_norm": 1.1802705526351929,
      "learning_rate": 3.1601293834638314e-06,
      "loss": 0.8695,
      "step": 16000
    },
    {
      "epoch": 85.61,
      "grad_norm": 0.7849507927894592,
      "learning_rate": 3.1371634116690135e-06,
      "loss": 0.9689,
      "step": 16010
    },
    {
      "epoch": 85.67,
      "grad_norm": 0.8523563742637634,
      "learning_rate": 3.1142767851544373e-06,
      "loss": 0.8597,
      "step": 16020
    },
    {
      "epoch": 85.72,
      "grad_norm": 1.1895318031311035,
      "learning_rate": 3.0914695685149987e-06,
      "loss": 0.8306,
      "step": 16030
    },
    {
      "epoch": 85.78,
      "grad_norm": 0.7723575234413147,
      "learning_rate": 3.0687418261214525e-06,
      "loss": 0.8903,
      "step": 16040
    },
    {
      "epoch": 85.83,
      "grad_norm": 0.8773337602615356,
      "learning_rate": 3.0460936221202925e-06,
      "loss": 0.8926,
      "step": 16050
    },
    {
      "epoch": 85.88,
      "grad_norm": 0.893444836139679,
      "learning_rate": 3.0235250204334734e-06,
      "loss": 0.9832,
      "step": 16060
    },
    {
      "epoch": 85.94,
      "grad_norm": 1.1448618173599243,
      "learning_rate": 3.0010360847583136e-06,
      "loss": 0.8903,
      "step": 16070
    },
    {
      "epoch": 85.99,
      "grad_norm": 1.0707321166992188,
      "learning_rate": 2.978626878567269e-06,
      "loss": 0.9297,
      "step": 16080
    },
    {
      "epoch": 86.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3989927768707275,
      "eval_runtime": 1.1945,
      "eval_samples_per_second": 27.626,
      "eval_steps_per_second": 2.511,
      "step": 16082
    },
    {
      "epoch": 86.04,
      "grad_norm": 1.0920511484146118,
      "learning_rate": 2.956297465107775e-06,
      "loss": 0.9712,
      "step": 16090
    },
    {
      "epoch": 86.1,
      "grad_norm": 1.3063020706176758,
      "learning_rate": 2.9340479074020586e-06,
      "loss": 0.8261,
      "step": 16100
    },
    {
      "epoch": 86.15,
      "grad_norm": 0.7676613330841064,
      "learning_rate": 2.911878268246966e-06,
      "loss": 0.9012,
      "step": 16110
    },
    {
      "epoch": 86.2,
      "grad_norm": 1.6614662408828735,
      "learning_rate": 2.889788610213766e-06,
      "loss": 0.9563,
      "step": 16120
    },
    {
      "epoch": 86.26,
      "grad_norm": 1.0720574855804443,
      "learning_rate": 2.867778995648024e-06,
      "loss": 0.9127,
      "step": 16130
    },
    {
      "epoch": 86.31,
      "grad_norm": 0.9241171479225159,
      "learning_rate": 2.8458494866693484e-06,
      "loss": 0.9656,
      "step": 16140
    },
    {
      "epoch": 86.36,
      "grad_norm": 0.6883230209350586,
      "learning_rate": 2.824000145171299e-06,
      "loss": 0.968,
      "step": 16150
    },
    {
      "epoch": 86.42,
      "grad_norm": 1.0672978162765503,
      "learning_rate": 2.8022310328211543e-06,
      "loss": 0.955,
      "step": 16160
    },
    {
      "epoch": 86.47,
      "grad_norm": 1.0326035022735596,
      "learning_rate": 2.780542211059736e-06,
      "loss": 0.9249,
      "step": 16170
    },
    {
      "epoch": 86.52,
      "grad_norm": 1.3809367418289185,
      "learning_rate": 2.7589337411013e-06,
      "loss": 0.8968,
      "step": 16180
    },
    {
      "epoch": 86.58,
      "grad_norm": 1.0060253143310547,
      "learning_rate": 2.737405683933273e-06,
      "loss": 0.9467,
      "step": 16190
    },
    {
      "epoch": 86.63,
      "grad_norm": 0.9738895893096924,
      "learning_rate": 2.715958100316152e-06,
      "loss": 0.8738,
      "step": 16200
    },
    {
      "epoch": 86.68,
      "grad_norm": 0.6084879636764526,
      "learning_rate": 2.694591050783301e-06,
      "loss": 0.8735,
      "step": 16210
    },
    {
      "epoch": 86.74,
      "grad_norm": 0.8795205354690552,
      "learning_rate": 2.6733045956407776e-06,
      "loss": 0.8428,
      "step": 16220
    },
    {
      "epoch": 86.79,
      "grad_norm": 1.215421438217163,
      "learning_rate": 2.652098794967188e-06,
      "loss": 0.9335,
      "step": 16230
    },
    {
      "epoch": 86.84,
      "grad_norm": 0.9876059889793396,
      "learning_rate": 2.6309737086134892e-06,
      "loss": 0.8257,
      "step": 16240
    },
    {
      "epoch": 86.9,
      "grad_norm": 1.0360602140426636,
      "learning_rate": 2.609929396202814e-06,
      "loss": 0.8658,
      "step": 16250
    },
    {
      "epoch": 86.95,
      "grad_norm": 1.963927984237671,
      "learning_rate": 2.5889659171303635e-06,
      "loss": 0.9865,
      "step": 16260
    },
    {
      "epoch": 87.0,
      "eval_accuracy": 0.48484848484848486,
      "eval_loss": 1.3805979490280151,
      "eval_runtime": 1.2653,
      "eval_samples_per_second": 26.081,
      "eval_steps_per_second": 2.371,
      "step": 16269
    },
    {
      "epoch": 87.01,
      "grad_norm": 0.7870656251907349,
      "learning_rate": 2.568083330563152e-06,
      "loss": 0.8549,
      "step": 16270
    },
    {
      "epoch": 87.06,
      "grad_norm": 0.9666106104850769,
      "learning_rate": 2.5472816954399056e-06,
      "loss": 0.9166,
      "step": 16280
    },
    {
      "epoch": 87.11,
      "grad_norm": 0.6450876593589783,
      "learning_rate": 2.5265610704708827e-06,
      "loss": 0.8273,
      "step": 16290
    },
    {
      "epoch": 87.17,
      "grad_norm": 1.184354543685913,
      "learning_rate": 2.5059215141376678e-06,
      "loss": 0.9727,
      "step": 16300
    },
    {
      "epoch": 87.22,
      "grad_norm": 1.0650615692138672,
      "learning_rate": 2.4853630846930833e-06,
      "loss": 0.8581,
      "step": 16310
    },
    {
      "epoch": 87.27,
      "grad_norm": 1.3442732095718384,
      "learning_rate": 2.4648858401609373e-06,
      "loss": 0.8648,
      "step": 16320
    },
    {
      "epoch": 87.33,
      "grad_norm": 1.2018144130706787,
      "learning_rate": 2.4444898383359225e-06,
      "loss": 0.8699,
      "step": 16330
    },
    {
      "epoch": 87.38,
      "grad_norm": 0.9110594391822815,
      "learning_rate": 2.424175136783436e-06,
      "loss": 0.8661,
      "step": 16340
    },
    {
      "epoch": 87.43,
      "grad_norm": 1.2359576225280762,
      "learning_rate": 2.4039417928394083e-06,
      "loss": 0.9741,
      "step": 16350
    },
    {
      "epoch": 87.49,
      "grad_norm": 1.0144717693328857,
      "learning_rate": 2.383789863610153e-06,
      "loss": 1.0154,
      "step": 16360
    },
    {
      "epoch": 87.54,
      "grad_norm": 0.679324746131897,
      "learning_rate": 2.363719405972194e-06,
      "loss": 0.8553,
      "step": 16370
    },
    {
      "epoch": 87.59,
      "grad_norm": 1.2985265254974365,
      "learning_rate": 2.3437304765721e-06,
      "loss": 0.9066,
      "step": 16380
    },
    {
      "epoch": 87.65,
      "grad_norm": 1.1579126119613647,
      "learning_rate": 2.3238231318263686e-06,
      "loss": 0.9477,
      "step": 16390
    },
    {
      "epoch": 87.7,
      "grad_norm": 0.9373109936714172,
      "learning_rate": 2.3039974279212004e-06,
      "loss": 0.9288,
      "step": 16400
    },
    {
      "epoch": 87.75,
      "grad_norm": 0.6288182735443115,
      "learning_rate": 2.2842534208123883e-06,
      "loss": 0.8319,
      "step": 16410
    },
    {
      "epoch": 87.81,
      "grad_norm": 0.9891378879547119,
      "learning_rate": 2.2645911662251518e-06,
      "loss": 0.9731,
      "step": 16420
    },
    {
      "epoch": 87.86,
      "grad_norm": 0.9575372338294983,
      "learning_rate": 2.245010719653953e-06,
      "loss": 0.9836,
      "step": 16430
    },
    {
      "epoch": 87.91,
      "grad_norm": 0.8566427826881409,
      "learning_rate": 2.2255121363623926e-06,
      "loss": 0.9285,
      "step": 16440
    },
    {
      "epoch": 87.97,
      "grad_norm": 1.221970796585083,
      "learning_rate": 2.2060954713829793e-06,
      "loss": 0.8446,
      "step": 16450
    },
    {
      "epoch": 88.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3806496858596802,
      "eval_runtime": 1.2884,
      "eval_samples_per_second": 25.613,
      "eval_steps_per_second": 2.328,
      "step": 16456
    },
    {
      "epoch": 88.02,
      "grad_norm": 1.1573280096054077,
      "learning_rate": 2.1867607795170544e-06,
      "loss": 0.8436,
      "step": 16460
    },
    {
      "epoch": 88.07,
      "grad_norm": 0.8927496671676636,
      "learning_rate": 2.1675081153345775e-06,
      "loss": 0.8659,
      "step": 16470
    },
    {
      "epoch": 88.13,
      "grad_norm": 1.030190348625183,
      "learning_rate": 2.1483375331740084e-06,
      "loss": 0.8587,
      "step": 16480
    },
    {
      "epoch": 88.18,
      "grad_norm": 1.5261814594268799,
      "learning_rate": 2.129249087142116e-06,
      "loss": 0.9751,
      "step": 16490
    },
    {
      "epoch": 88.24,
      "grad_norm": 1.3173232078552246,
      "learning_rate": 2.110242831113884e-06,
      "loss": 0.9042,
      "step": 16500
    },
    {
      "epoch": 88.29,
      "grad_norm": 1.7766106128692627,
      "learning_rate": 2.0913188187322922e-06,
      "loss": 0.9959,
      "step": 16510
    },
    {
      "epoch": 88.34,
      "grad_norm": 1.1520169973373413,
      "learning_rate": 2.072477103408226e-06,
      "loss": 0.9534,
      "step": 16520
    },
    {
      "epoch": 88.4,
      "grad_norm": 1.1011232137680054,
      "learning_rate": 2.0537177383202662e-06,
      "loss": 0.8953,
      "step": 16530
    },
    {
      "epoch": 88.45,
      "grad_norm": 1.110757827758789,
      "learning_rate": 2.035040776414587e-06,
      "loss": 0.8237,
      "step": 16540
    },
    {
      "epoch": 88.5,
      "grad_norm": 0.8382008671760559,
      "learning_rate": 2.0164462704048045e-06,
      "loss": 0.8918,
      "step": 16550
    },
    {
      "epoch": 88.56,
      "grad_norm": 1.270961880683899,
      "learning_rate": 1.9979342727717666e-06,
      "loss": 0.8423,
      "step": 16560
    },
    {
      "epoch": 88.61,
      "grad_norm": 0.9389255046844482,
      "learning_rate": 1.9795048357635038e-06,
      "loss": 0.8852,
      "step": 16570
    },
    {
      "epoch": 88.66,
      "grad_norm": 1.5711233615875244,
      "learning_rate": 1.9611580113949903e-06,
      "loss": 0.8826,
      "step": 16580
    },
    {
      "epoch": 88.72,
      "grad_norm": 1.490826964378357,
      "learning_rate": 1.9428938514480486e-06,
      "loss": 0.8662,
      "step": 16590
    },
    {
      "epoch": 88.77,
      "grad_norm": 1.6715017557144165,
      "learning_rate": 1.9247124074711945e-06,
      "loss": 0.9391,
      "step": 16600
    },
    {
      "epoch": 88.82,
      "grad_norm": 0.9141826629638672,
      "learning_rate": 1.906613730779487e-06,
      "loss": 0.9795,
      "step": 16610
    },
    {
      "epoch": 88.88,
      "grad_norm": 0.8802061080932617,
      "learning_rate": 1.888597872454368e-06,
      "loss": 0.9016,
      "step": 16620
    },
    {
      "epoch": 88.93,
      "grad_norm": 0.7464277148246765,
      "learning_rate": 1.8706648833435626e-06,
      "loss": 0.8889,
      "step": 16630
    },
    {
      "epoch": 88.98,
      "grad_norm": 1.3512042760849,
      "learning_rate": 1.852814814060872e-06,
      "loss": 0.9218,
      "step": 16640
    },
    {
      "epoch": 89.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4016999006271362,
      "eval_runtime": 1.1683,
      "eval_samples_per_second": 28.246,
      "eval_steps_per_second": 2.568,
      "step": 16643
    },
    {
      "epoch": 89.04,
      "grad_norm": 1.4205803871154785,
      "learning_rate": 1.835047714986101e-06,
      "loss": 1.0256,
      "step": 16650
    },
    {
      "epoch": 89.09,
      "grad_norm": 1.133632779121399,
      "learning_rate": 1.8173636362648557e-06,
      "loss": 0.9354,
      "step": 16660
    },
    {
      "epoch": 89.14,
      "grad_norm": 1.294317364692688,
      "learning_rate": 1.7997626278084302e-06,
      "loss": 0.9934,
      "step": 16670
    },
    {
      "epoch": 89.2,
      "grad_norm": 1.1940687894821167,
      "learning_rate": 1.7822447392936842e-06,
      "loss": 0.901,
      "step": 16680
    },
    {
      "epoch": 89.25,
      "grad_norm": 1.144025206565857,
      "learning_rate": 1.7648100201628422e-06,
      "loss": 0.9937,
      "step": 16690
    },
    {
      "epoch": 89.3,
      "grad_norm": 1.2660366296768188,
      "learning_rate": 1.747458519623428e-06,
      "loss": 0.953,
      "step": 16700
    },
    {
      "epoch": 89.36,
      "grad_norm": 0.8924720883369446,
      "learning_rate": 1.7301902866480694e-06,
      "loss": 1.0062,
      "step": 16710
    },
    {
      "epoch": 89.41,
      "grad_norm": 0.9671584963798523,
      "learning_rate": 1.7130053699743916e-06,
      "loss": 0.8108,
      "step": 16720
    },
    {
      "epoch": 89.47,
      "grad_norm": 0.848966121673584,
      "learning_rate": 1.6959038181048604e-06,
      "loss": 0.9845,
      "step": 16730
    },
    {
      "epoch": 89.52,
      "grad_norm": 1.047905445098877,
      "learning_rate": 1.678885679306668e-06,
      "loss": 0.8816,
      "step": 16740
    },
    {
      "epoch": 89.57,
      "grad_norm": 0.7435301542282104,
      "learning_rate": 1.6619510016115565e-06,
      "loss": 0.7944,
      "step": 16750
    },
    {
      "epoch": 89.63,
      "grad_norm": 0.9954517483711243,
      "learning_rate": 1.6450998328157475e-06,
      "loss": 0.8815,
      "step": 16760
    },
    {
      "epoch": 89.68,
      "grad_norm": 0.8423842191696167,
      "learning_rate": 1.6283322204797244e-06,
      "loss": 0.9025,
      "step": 16770
    },
    {
      "epoch": 89.73,
      "grad_norm": 0.7806405425071716,
      "learning_rate": 1.6116482119281836e-06,
      "loss": 0.8529,
      "step": 16780
    },
    {
      "epoch": 89.79,
      "grad_norm": 0.9063516855239868,
      "learning_rate": 1.595047854249826e-06,
      "loss": 0.9159,
      "step": 16790
    },
    {
      "epoch": 89.84,
      "grad_norm": 1.2809057235717773,
      "learning_rate": 1.578531194297267e-06,
      "loss": 0.8961,
      "step": 16800
    },
    {
      "epoch": 89.89,
      "grad_norm": 1.1938250064849854,
      "learning_rate": 1.5620982786869187e-06,
      "loss": 0.9431,
      "step": 16810
    },
    {
      "epoch": 89.95,
      "grad_norm": 0.9619331359863281,
      "learning_rate": 1.545749153798799e-06,
      "loss": 0.8703,
      "step": 16820
    },
    {
      "epoch": 90.0,
      "grad_norm": 1.408066987991333,
      "learning_rate": 1.5294838657764522e-06,
      "loss": 0.9173,
      "step": 16830
    },
    {
      "epoch": 90.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3959071636199951,
      "eval_runtime": 1.2866,
      "eval_samples_per_second": 25.65,
      "eval_steps_per_second": 2.332,
      "step": 16830
    },
    {
      "epoch": 90.05,
      "grad_norm": 1.2694270610809326,
      "learning_rate": 1.5133024605268054e-06,
      "loss": 0.9449,
      "step": 16840
    },
    {
      "epoch": 90.11,
      "grad_norm": 1.3860708475112915,
      "learning_rate": 1.497204983720031e-06,
      "loss": 1.0474,
      "step": 16850
    },
    {
      "epoch": 90.16,
      "grad_norm": 0.7448433041572571,
      "learning_rate": 1.481191480789422e-06,
      "loss": 0.9325,
      "step": 16860
    },
    {
      "epoch": 90.21,
      "grad_norm": 1.270509123802185,
      "learning_rate": 1.465261996931276e-06,
      "loss": 0.8745,
      "step": 16870
    },
    {
      "epoch": 90.27,
      "grad_norm": 1.1797428131103516,
      "learning_rate": 1.449416577104734e-06,
      "loss": 0.8848,
      "step": 16880
    },
    {
      "epoch": 90.32,
      "grad_norm": 1.1394829750061035,
      "learning_rate": 1.4336552660317026e-06,
      "loss": 0.8687,
      "step": 16890
    },
    {
      "epoch": 90.37,
      "grad_norm": 1.235798954963684,
      "learning_rate": 1.4179781081966777e-06,
      "loss": 0.8802,
      "step": 16900
    },
    {
      "epoch": 90.43,
      "grad_norm": 0.8006685972213745,
      "learning_rate": 1.4023851478466576e-06,
      "loss": 0.9205,
      "step": 16910
    },
    {
      "epoch": 90.48,
      "grad_norm": 0.6802676320075989,
      "learning_rate": 1.3868764289909943e-06,
      "loss": 0.9225,
      "step": 16920
    },
    {
      "epoch": 90.53,
      "grad_norm": 1.1533722877502441,
      "learning_rate": 1.3714519954012746e-06,
      "loss": 0.905,
      "step": 16930
    },
    {
      "epoch": 90.59,
      "grad_norm": 1.5686264038085938,
      "learning_rate": 1.3561118906112272e-06,
      "loss": 0.8891,
      "step": 16940
    },
    {
      "epoch": 90.64,
      "grad_norm": 1.1264184713363647,
      "learning_rate": 1.340856157916532e-06,
      "loss": 0.8749,
      "step": 16950
    },
    {
      "epoch": 90.7,
      "grad_norm": 1.3629523515701294,
      "learning_rate": 1.32568484037476e-06,
      "loss": 1.0008,
      "step": 16960
    },
    {
      "epoch": 90.75,
      "grad_norm": 1.0053565502166748,
      "learning_rate": 1.3105979808052324e-06,
      "loss": 0.8578,
      "step": 16970
    },
    {
      "epoch": 90.8,
      "grad_norm": 0.8683646321296692,
      "learning_rate": 1.2955956217888914e-06,
      "loss": 0.8684,
      "step": 16980
    },
    {
      "epoch": 90.86,
      "grad_norm": 0.9128271341323853,
      "learning_rate": 1.2806778056681893e-06,
      "loss": 1.0208,
      "step": 16990
    },
    {
      "epoch": 90.91,
      "grad_norm": 1.0827401876449585,
      "learning_rate": 1.2658445745469607e-06,
      "loss": 0.7959,
      "step": 17000
    },
    {
      "epoch": 90.96,
      "grad_norm": 1.227754831314087,
      "learning_rate": 1.2510959702903036e-06,
      "loss": 0.9118,
      "step": 17010
    },
    {
      "epoch": 91.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3902603387832642,
      "eval_runtime": 1.2492,
      "eval_samples_per_second": 26.417,
      "eval_steps_per_second": 2.402,
      "step": 17017
    },
    {
      "epoch": 91.02,
      "grad_norm": 1.2093424797058105,
      "learning_rate": 1.23643203452449e-06,
      "loss": 0.8913,
      "step": 17020
    },
    {
      "epoch": 91.07,
      "grad_norm": 1.8625903129577637,
      "learning_rate": 1.221852808636799e-06,
      "loss": 0.8985,
      "step": 17030
    },
    {
      "epoch": 91.12,
      "grad_norm": 0.8587633967399597,
      "learning_rate": 1.207358333775433e-06,
      "loss": 1.0088,
      "step": 17040
    },
    {
      "epoch": 91.18,
      "grad_norm": 0.8423651456832886,
      "learning_rate": 1.192948650849405e-06,
      "loss": 0.858,
      "step": 17050
    },
    {
      "epoch": 91.23,
      "grad_norm": 1.029429316520691,
      "learning_rate": 1.1786238005283973e-06,
      "loss": 1.0336,
      "step": 17060
    },
    {
      "epoch": 91.28,
      "grad_norm": 0.9454956650733948,
      "learning_rate": 1.164383823242677e-06,
      "loss": 0.9672,
      "step": 17070
    },
    {
      "epoch": 91.34,
      "grad_norm": 1.2770034074783325,
      "learning_rate": 1.1502287591829524e-06,
      "loss": 0.9017,
      "step": 17080
    },
    {
      "epoch": 91.39,
      "grad_norm": 0.8497073650360107,
      "learning_rate": 1.1361586483002797e-06,
      "loss": 1.0364,
      "step": 17090
    },
    {
      "epoch": 91.44,
      "grad_norm": 0.8405956625938416,
      "learning_rate": 1.122173530305949e-06,
      "loss": 0.8604,
      "step": 17100
    },
    {
      "epoch": 91.5,
      "grad_norm": 0.7938619256019592,
      "learning_rate": 1.1082734446713622e-06,
      "loss": 0.8243,
      "step": 17110
    },
    {
      "epoch": 91.55,
      "grad_norm": 0.7715607285499573,
      "learning_rate": 1.0944584306279219e-06,
      "loss": 0.9284,
      "step": 17120
    },
    {
      "epoch": 91.6,
      "grad_norm": 1.2991211414337158,
      "learning_rate": 1.080728527166945e-06,
      "loss": 0.8219,
      "step": 17130
    },
    {
      "epoch": 91.66,
      "grad_norm": 1.0499848127365112,
      "learning_rate": 1.067083773039504e-06,
      "loss": 0.8775,
      "step": 17140
    },
    {
      "epoch": 91.71,
      "grad_norm": 1.3435927629470825,
      "learning_rate": 1.0535242067563795e-06,
      "loss": 0.8133,
      "step": 17150
    },
    {
      "epoch": 91.76,
      "grad_norm": 0.8245609402656555,
      "learning_rate": 1.040049866587893e-06,
      "loss": 1.0043,
      "step": 17160
    },
    {
      "epoch": 91.82,
      "grad_norm": 0.7064393162727356,
      "learning_rate": 1.0266607905638422e-06,
      "loss": 0.8842,
      "step": 17170
    },
    {
      "epoch": 91.87,
      "grad_norm": 1.0318973064422607,
      "learning_rate": 1.0133570164733638e-06,
      "loss": 0.9524,
      "step": 17180
    },
    {
      "epoch": 91.93,
      "grad_norm": 0.7579448819160461,
      "learning_rate": 1.000138581864849e-06,
      "loss": 0.835,
      "step": 17190
    },
    {
      "epoch": 91.98,
      "grad_norm": 0.8712974786758423,
      "learning_rate": 9.870055240458232e-07,
      "loss": 0.9323,
      "step": 17200
    },
    {
      "epoch": 92.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3968373537063599,
      "eval_runtime": 1.2041,
      "eval_samples_per_second": 27.407,
      "eval_steps_per_second": 2.492,
      "step": 17204
    },
    {
      "epoch": 92.03,
      "grad_norm": 1.7161188125610352,
      "learning_rate": 9.739578800828479e-07,
      "loss": 0.9156,
      "step": 17210
    },
    {
      "epoch": 92.09,
      "grad_norm": 1.0006394386291504,
      "learning_rate": 9.6099568680141e-07,
      "loss": 0.9276,
      "step": 17220
    },
    {
      "epoch": 92.14,
      "grad_norm": 1.109391212463379,
      "learning_rate": 9.481189807858289e-07,
      "loss": 0.9388,
      "step": 17230
    },
    {
      "epoch": 92.19,
      "grad_norm": 1.0249236822128296,
      "learning_rate": 9.353277983791368e-07,
      "loss": 0.859,
      "step": 17240
    },
    {
      "epoch": 92.25,
      "grad_norm": 0.8788481950759888,
      "learning_rate": 9.22622175682987e-07,
      "loss": 0.8502,
      "step": 17250
    },
    {
      "epoch": 92.3,
      "grad_norm": 1.6610064506530762,
      "learning_rate": 9.100021485575621e-07,
      "loss": 0.9453,
      "step": 17260
    },
    {
      "epoch": 92.35,
      "grad_norm": 1.0889652967453003,
      "learning_rate": 8.974677526214399e-07,
      "loss": 0.9025,
      "step": 17270
    },
    {
      "epoch": 92.41,
      "grad_norm": 0.7286486625671387,
      "learning_rate": 8.850190232515404e-07,
      "loss": 0.9039,
      "step": 17280
    },
    {
      "epoch": 92.46,
      "grad_norm": 1.239048719406128,
      "learning_rate": 8.726559955829737e-07,
      "loss": 0.9641,
      "step": 17290
    },
    {
      "epoch": 92.51,
      "grad_norm": 0.9935368895530701,
      "learning_rate": 8.603787045089774e-07,
      "loss": 0.8646,
      "step": 17300
    },
    {
      "epoch": 92.57,
      "grad_norm": 1.1213411092758179,
      "learning_rate": 8.481871846808126e-07,
      "loss": 0.8852,
      "step": 17310
    },
    {
      "epoch": 92.62,
      "grad_norm": 0.7363156676292419,
      "learning_rate": 8.360814705076526e-07,
      "loss": 0.8763,
      "step": 17320
    },
    {
      "epoch": 92.67,
      "grad_norm": 1.8777751922607422,
      "learning_rate": 8.240615961565001e-07,
      "loss": 0.9206,
      "step": 17330
    },
    {
      "epoch": 92.73,
      "grad_norm": 0.9105457663536072,
      "learning_rate": 8.121275955520792e-07,
      "loss": 0.891,
      "step": 17340
    },
    {
      "epoch": 92.78,
      "grad_norm": 0.6954162120819092,
      "learning_rate": 8.002795023767488e-07,
      "loss": 1.0123,
      "step": 17350
    },
    {
      "epoch": 92.83,
      "grad_norm": 1.1299444437026978,
      "learning_rate": 7.885173500704022e-07,
      "loss": 0.884,
      "step": 17360
    },
    {
      "epoch": 92.89,
      "grad_norm": 0.788418173789978,
      "learning_rate": 7.768411718303801e-07,
      "loss": 0.9611,
      "step": 17370
    },
    {
      "epoch": 92.94,
      "grad_norm": 1.0654979944229126,
      "learning_rate": 7.652510006113562e-07,
      "loss": 0.9175,
      "step": 17380
    },
    {
      "epoch": 92.99,
      "grad_norm": 1.3657982349395752,
      "learning_rate": 7.537468691252782e-07,
      "loss": 0.8661,
      "step": 17390
    },
    {
      "epoch": 93.0,
      "eval_accuracy": 0.45454545454545453,
      "eval_loss": 1.3752692937850952,
      "eval_runtime": 1.22,
      "eval_samples_per_second": 27.048,
      "eval_steps_per_second": 2.459,
      "step": 17391
    },
    {
      "epoch": 93.05,
      "grad_norm": 1.3243639469146729,
      "learning_rate": 7.423288098412396e-07,
      "loss": 0.8632,
      "step": 17400
    },
    {
      "epoch": 93.1,
      "grad_norm": 1.0397084951400757,
      "learning_rate": 7.309968549854204e-07,
      "loss": 0.8769,
      "step": 17410
    },
    {
      "epoch": 93.16,
      "grad_norm": 1.1266858577728271,
      "learning_rate": 7.197510365409693e-07,
      "loss": 0.9017,
      "step": 17420
    },
    {
      "epoch": 93.21,
      "grad_norm": 0.6760213375091553,
      "learning_rate": 7.08591386247924e-07,
      "loss": 0.8981,
      "step": 17430
    },
    {
      "epoch": 93.26,
      "grad_norm": 1.1071358919143677,
      "learning_rate": 6.975179356031348e-07,
      "loss": 0.9755,
      "step": 17440
    },
    {
      "epoch": 93.32,
      "grad_norm": 0.8846127986907959,
      "learning_rate": 6.865307158601501e-07,
      "loss": 0.9042,
      "step": 17450
    },
    {
      "epoch": 93.37,
      "grad_norm": 1.8860139846801758,
      "learning_rate": 6.756297580291469e-07,
      "loss": 0.9339,
      "step": 17460
    },
    {
      "epoch": 93.42,
      "grad_norm": 1.0161468982696533,
      "learning_rate": 6.648150928768408e-07,
      "loss": 0.8913,
      "step": 17470
    },
    {
      "epoch": 93.48,
      "grad_norm": 0.7142757177352905,
      "learning_rate": 6.540867509263887e-07,
      "loss": 0.8888,
      "step": 17480
    },
    {
      "epoch": 93.53,
      "grad_norm": 1.3219636678695679,
      "learning_rate": 6.43444762457316e-07,
      "loss": 0.9359,
      "step": 17490
    },
    {
      "epoch": 93.58,
      "grad_norm": 0.7972387075424194,
      "learning_rate": 6.328891575054264e-07,
      "loss": 0.8743,
      "step": 17500
    },
    {
      "epoch": 93.64,
      "grad_norm": 0.7254283428192139,
      "learning_rate": 6.224199658627048e-07,
      "loss": 0.8675,
      "step": 17510
    },
    {
      "epoch": 93.69,
      "grad_norm": 0.922814130783081,
      "learning_rate": 6.120372170772652e-07,
      "loss": 0.9093,
      "step": 17520
    },
    {
      "epoch": 93.74,
      "grad_norm": 0.9220100045204163,
      "learning_rate": 6.017409404532187e-07,
      "loss": 0.8985,
      "step": 17530
    },
    {
      "epoch": 93.8,
      "grad_norm": 1.4148238897323608,
      "learning_rate": 5.915311650506461e-07,
      "loss": 1.0027,
      "step": 17540
    },
    {
      "epoch": 93.85,
      "grad_norm": 0.8926424384117126,
      "learning_rate": 5.814079196854692e-07,
      "loss": 0.8742,
      "step": 17550
    },
    {
      "epoch": 93.9,
      "grad_norm": 1.1519408226013184,
      "learning_rate": 5.713712329293956e-07,
      "loss": 0.8831,
      "step": 17560
    },
    {
      "epoch": 93.96,
      "grad_norm": 1.19341242313385,
      "learning_rate": 5.614211331098351e-07,
      "loss": 0.9141,
      "step": 17570
    },
    {
      "epoch": 94.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.3858948945999146,
      "eval_runtime": 1.1738,
      "eval_samples_per_second": 28.113,
      "eval_steps_per_second": 2.556,
      "step": 17578
    },
    {
      "epoch": 94.01,
      "grad_norm": 0.9921354055404663,
      "learning_rate": 5.515576483098098e-07,
      "loss": 0.8958,
      "step": 17580
    },
    {
      "epoch": 94.06,
      "grad_norm": 0.8764972686767578,
      "learning_rate": 5.417808063678774e-07,
      "loss": 0.9252,
      "step": 17590
    },
    {
      "epoch": 94.12,
      "grad_norm": 1.1674556732177734,
      "learning_rate": 5.320906348780693e-07,
      "loss": 0.8375,
      "step": 17600
    },
    {
      "epoch": 94.17,
      "grad_norm": 1.0642403364181519,
      "learning_rate": 5.224871611897893e-07,
      "loss": 0.9313,
      "step": 17610
    },
    {
      "epoch": 94.22,
      "grad_norm": 1.2293633222579956,
      "learning_rate": 5.129704124077414e-07,
      "loss": 0.8794,
      "step": 17620
    },
    {
      "epoch": 94.28,
      "grad_norm": 0.9123471975326538,
      "learning_rate": 5.03540415391874e-07,
      "loss": 0.9487,
      "step": 17630
    },
    {
      "epoch": 94.33,
      "grad_norm": 1.426861047744751,
      "learning_rate": 4.94197196757272e-07,
      "loss": 1.0174,
      "step": 17640
    },
    {
      "epoch": 94.39,
      "grad_norm": 0.8614670634269714,
      "learning_rate": 4.849407828741124e-07,
      "loss": 0.8698,
      "step": 17650
    },
    {
      "epoch": 94.44,
      "grad_norm": 1.0384100675582886,
      "learning_rate": 4.7577119986756676e-07,
      "loss": 0.9696,
      "step": 17660
    },
    {
      "epoch": 94.49,
      "grad_norm": 0.8066587448120117,
      "learning_rate": 4.666884736177421e-07,
      "loss": 0.8461,
      "step": 17670
    },
    {
      "epoch": 94.55,
      "grad_norm": 1.306188702583313,
      "learning_rate": 4.576926297595943e-07,
      "loss": 0.8834,
      "step": 17680
    },
    {
      "epoch": 94.6,
      "grad_norm": 1.0046244859695435,
      "learning_rate": 4.487836936828728e-07,
      "loss": 0.9042,
      "step": 17690
    },
    {
      "epoch": 94.65,
      "grad_norm": 1.0126861333847046,
      "learning_rate": 4.3996169053203e-07,
      "loss": 0.9679,
      "step": 17700
    },
    {
      "epoch": 94.71,
      "grad_norm": 0.8780336380004883,
      "learning_rate": 4.312266452061696e-07,
      "loss": 0.8355,
      "step": 17710
    },
    {
      "epoch": 94.76,
      "grad_norm": 0.9989269971847534,
      "learning_rate": 4.22578582358963e-07,
      "loss": 0.8918,
      "step": 17720
    },
    {
      "epoch": 94.81,
      "grad_norm": 0.9309195280075073,
      "learning_rate": 4.1401752639858016e-07,
      "loss": 1.0867,
      "step": 17730
    },
    {
      "epoch": 94.87,
      "grad_norm": 1.4476318359375,
      "learning_rate": 4.05543501487627e-07,
      "loss": 0.9237,
      "step": 17740
    },
    {
      "epoch": 94.92,
      "grad_norm": 0.7614614963531494,
      "learning_rate": 3.9715653154307613e-07,
      "loss": 0.9101,
      "step": 17750
    },
    {
      "epoch": 94.97,
      "grad_norm": 0.727039098739624,
      "learning_rate": 3.8885664023619386e-07,
      "loss": 0.8606,
      "step": 17760
    },
    {
      "epoch": 95.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3948602676391602,
      "eval_runtime": 1.1977,
      "eval_samples_per_second": 27.552,
      "eval_steps_per_second": 2.505,
      "step": 17765
    },
    {
      "epoch": 95.03,
      "grad_norm": 1.1441808938980103,
      "learning_rate": 3.8064385099247437e-07,
      "loss": 1.0268,
      "step": 17770
    },
    {
      "epoch": 95.08,
      "grad_norm": 0.7532866597175598,
      "learning_rate": 3.7251818699158763e-07,
      "loss": 0.7606,
      "step": 17780
    },
    {
      "epoch": 95.13,
      "grad_norm": 0.8890023827552795,
      "learning_rate": 3.644796711672928e-07,
      "loss": 0.9593,
      "step": 17790
    },
    {
      "epoch": 95.19,
      "grad_norm": 0.8029434084892273,
      "learning_rate": 3.5652832620738235e-07,
      "loss": 0.9563,
      "step": 17800
    },
    {
      "epoch": 95.24,
      "grad_norm": 1.4195353984832764,
      "learning_rate": 3.4866417455362354e-07,
      "loss": 0.9753,
      "step": 17810
    },
    {
      "epoch": 95.29,
      "grad_norm": 0.8238121867179871,
      "learning_rate": 3.408872384016888e-07,
      "loss": 0.8248,
      "step": 17820
    },
    {
      "epoch": 95.35,
      "grad_norm": 0.8127976655960083,
      "learning_rate": 3.331975397010967e-07,
      "loss": 0.8935,
      "step": 17830
    },
    {
      "epoch": 95.4,
      "grad_norm": 1.283902883529663,
      "learning_rate": 3.2559510015514257e-07,
      "loss": 0.9399,
      "step": 17840
    },
    {
      "epoch": 95.45,
      "grad_norm": 1.2944791316986084,
      "learning_rate": 3.180799412208536e-07,
      "loss": 0.8609,
      "step": 17850
    },
    {
      "epoch": 95.51,
      "grad_norm": 1.0425372123718262,
      "learning_rate": 3.1065208410890195e-07,
      "loss": 0.8758,
      "step": 17860
    },
    {
      "epoch": 95.56,
      "grad_norm": 0.9722619652748108,
      "learning_rate": 3.033115497835734e-07,
      "loss": 0.8618,
      "step": 17870
    },
    {
      "epoch": 95.61,
      "grad_norm": 0.6573357582092285,
      "learning_rate": 2.9605835896268777e-07,
      "loss": 0.9304,
      "step": 17880
    },
    {
      "epoch": 95.67,
      "grad_norm": 0.909795880317688,
      "learning_rate": 2.888925321175538e-07,
      "loss": 0.889,
      "step": 17890
    },
    {
      "epoch": 95.72,
      "grad_norm": 1.198448657989502,
      "learning_rate": 2.818140894728927e-07,
      "loss": 0.9283,
      "step": 17900
    },
    {
      "epoch": 95.78,
      "grad_norm": 0.8125998973846436,
      "learning_rate": 2.7482305100681726e-07,
      "loss": 0.9456,
      "step": 17910
    },
    {
      "epoch": 95.83,
      "grad_norm": 1.2987141609191895,
      "learning_rate": 2.6791943645072465e-07,
      "loss": 0.9561,
      "step": 17920
    },
    {
      "epoch": 95.88,
      "grad_norm": 1.284971833229065,
      "learning_rate": 2.611032652892892e-07,
      "loss": 0.8971,
      "step": 17930
    },
    {
      "epoch": 95.94,
      "grad_norm": 1.172877311706543,
      "learning_rate": 2.543745567603721e-07,
      "loss": 0.9089,
      "step": 17940
    },
    {
      "epoch": 95.99,
      "grad_norm": 0.8394883871078491,
      "learning_rate": 2.47733329854994e-07,
      "loss": 0.8983,
      "step": 17950
    },
    {
      "epoch": 96.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.4187114238739014,
      "eval_runtime": 1.4042,
      "eval_samples_per_second": 23.501,
      "eval_steps_per_second": 2.136,
      "step": 17952
    },
    {
      "epoch": 96.04,
      "grad_norm": 1.3839447498321533,
      "learning_rate": 2.411796033172514e-07,
      "loss": 0.9693,
      "step": 17960
    },
    {
      "epoch": 96.1,
      "grad_norm": 1.2749099731445312,
      "learning_rate": 2.3471339564430302e-07,
      "loss": 0.8099,
      "step": 17970
    },
    {
      "epoch": 96.15,
      "grad_norm": 1.0780609846115112,
      "learning_rate": 2.2833472508627244e-07,
      "loss": 0.9253,
      "step": 17980
    },
    {
      "epoch": 96.2,
      "grad_norm": 1.452898383140564,
      "learning_rate": 2.2204360964624136e-07,
      "loss": 0.9034,
      "step": 17990
    },
    {
      "epoch": 96.26,
      "grad_norm": 0.9877240657806396,
      "learning_rate": 2.1584006708015926e-07,
      "loss": 0.8483,
      "step": 18000
    },
    {
      "epoch": 96.31,
      "grad_norm": 0.7760390043258667,
      "learning_rate": 2.0972411489681916e-07,
      "loss": 0.8808,
      "step": 18010
    },
    {
      "epoch": 96.36,
      "grad_norm": 0.9429829716682434,
      "learning_rate": 2.036957703578056e-07,
      "loss": 0.829,
      "step": 18020
    },
    {
      "epoch": 96.42,
      "grad_norm": 1.349020004272461,
      "learning_rate": 1.9775505047743211e-07,
      "loss": 1.0217,
      "step": 18030
    },
    {
      "epoch": 96.47,
      "grad_norm": 1.2239431142807007,
      "learning_rate": 1.919019720226997e-07,
      "loss": 0.963,
      "step": 18040
    },
    {
      "epoch": 96.52,
      "grad_norm": 0.8184213042259216,
      "learning_rate": 1.8613655151325862e-07,
      "loss": 0.8006,
      "step": 18050
    },
    {
      "epoch": 96.58,
      "grad_norm": 0.7241829037666321,
      "learning_rate": 1.804588052213528e-07,
      "loss": 0.9442,
      "step": 18060
    },
    {
      "epoch": 96.63,
      "grad_norm": 1.1343507766723633,
      "learning_rate": 1.7486874917177486e-07,
      "loss": 0.8742,
      "step": 18070
    },
    {
      "epoch": 96.68,
      "grad_norm": 1.0625005960464478,
      "learning_rate": 1.6936639914182095e-07,
      "loss": 0.8519,
      "step": 18080
    },
    {
      "epoch": 96.74,
      "grad_norm": 0.8415389657020569,
      "learning_rate": 1.639517706612456e-07,
      "loss": 0.8947,
      "step": 18090
    },
    {
      "epoch": 96.79,
      "grad_norm": 1.082522988319397,
      "learning_rate": 1.5862487901222368e-07,
      "loss": 0.8513,
      "step": 18100
    },
    {
      "epoch": 96.84,
      "grad_norm": 1.0276859998703003,
      "learning_rate": 1.5338573922929825e-07,
      "loss": 0.903,
      "step": 18110
    },
    {
      "epoch": 96.9,
      "grad_norm": 1.215345859527588,
      "learning_rate": 1.4823436609934585e-07,
      "loss": 1.012,
      "step": 18120
    },
    {
      "epoch": 96.95,
      "grad_norm": 0.9547162055969238,
      "learning_rate": 1.4317077416153499e-07,
      "loss": 0.8848,
      "step": 18130
    },
    {
      "epoch": 97.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.3876153230667114,
      "eval_runtime": 1.1645,
      "eval_samples_per_second": 28.338,
      "eval_steps_per_second": 2.576,
      "step": 18139
    },
    {
      "epoch": 97.01,
      "grad_norm": 0.7154603600502014,
      "learning_rate": 1.3819497770726706e-07,
      "loss": 0.8349,
      "step": 18140
    },
    {
      "epoch": 97.06,
      "grad_norm": 1.0487241744995117,
      "learning_rate": 1.3330699078017289e-07,
      "loss": 0.9581,
      "step": 18150
    },
    {
      "epoch": 97.11,
      "grad_norm": 0.8797714114189148,
      "learning_rate": 1.2850682717602952e-07,
      "loss": 0.8779,
      "step": 18160
    },
    {
      "epoch": 97.17,
      "grad_norm": 0.7922282218933105,
      "learning_rate": 1.2379450044275666e-07,
      "loss": 0.966,
      "step": 18170
    },
    {
      "epoch": 97.22,
      "grad_norm": 1.3217825889587402,
      "learning_rate": 1.1917002388035781e-07,
      "loss": 0.8792,
      "step": 18180
    },
    {
      "epoch": 97.27,
      "grad_norm": 1.0433458089828491,
      "learning_rate": 1.1463341054089582e-07,
      "loss": 0.94,
      "step": 18190
    },
    {
      "epoch": 97.33,
      "grad_norm": 0.8962709307670593,
      "learning_rate": 1.1018467322843755e-07,
      "loss": 0.8428,
      "step": 18200
    },
    {
      "epoch": 97.38,
      "grad_norm": 0.7256751656532288,
      "learning_rate": 1.0582382449904684e-07,
      "loss": 0.8967,
      "step": 18210
    },
    {
      "epoch": 97.43,
      "grad_norm": 1.1065484285354614,
      "learning_rate": 1.0155087666071511e-07,
      "loss": 0.8672,
      "step": 18220
    },
    {
      "epoch": 97.49,
      "grad_norm": 1.1751023530960083,
      "learning_rate": 9.736584177335444e-08,
      "loss": 0.9236,
      "step": 18230
    },
    {
      "epoch": 97.54,
      "grad_norm": 0.8838192224502563,
      "learning_rate": 9.326873164875252e-08,
      "loss": 0.8861,
      "step": 18240
    },
    {
      "epoch": 97.59,
      "grad_norm": 0.6358389258384705,
      "learning_rate": 8.925955785052745e-08,
      "loss": 0.8802,
      "step": 18250
    },
    {
      "epoch": 97.65,
      "grad_norm": 0.8120447397232056,
      "learning_rate": 8.533833169412434e-08,
      "loss": 0.9154,
      "step": 18260
    },
    {
      "epoch": 97.7,
      "grad_norm": 0.7468269467353821,
      "learning_rate": 8.150506424675283e-08,
      "loss": 0.9275,
      "step": 18270
    },
    {
      "epoch": 97.75,
      "grad_norm": 1.2087081670761108,
      "learning_rate": 7.775976632737325e-08,
      "loss": 0.8651,
      "step": 18280
    },
    {
      "epoch": 97.81,
      "grad_norm": 0.8018743395805359,
      "learning_rate": 7.41024485066688e-08,
      "loss": 0.925,
      "step": 18290
    },
    {
      "epoch": 97.86,
      "grad_norm": 1.2578879594802856,
      "learning_rate": 7.053312110699359e-08,
      "loss": 0.8127,
      "step": 18300
    },
    {
      "epoch": 97.91,
      "grad_norm": 0.9711631536483765,
      "learning_rate": 6.705179420237253e-08,
      "loss": 0.8914,
      "step": 18310
    },
    {
      "epoch": 97.97,
      "grad_norm": 1.32654869556427,
      "learning_rate": 6.365847761845636e-08,
      "loss": 0.8168,
      "step": 18320
    },
    {
      "epoch": 98.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4228874444961548,
      "eval_runtime": 1.1773,
      "eval_samples_per_second": 28.03,
      "eval_steps_per_second": 2.548,
      "step": 18326
    },
    {
      "epoch": 98.02,
      "grad_norm": 0.750697672367096,
      "learning_rate": 6.035318093249378e-08,
      "loss": 0.9799,
      "step": 18330
    },
    {
      "epoch": 98.07,
      "grad_norm": 0.9296233654022217,
      "learning_rate": 5.713591347330377e-08,
      "loss": 0.8888,
      "step": 18340
    },
    {
      "epoch": 98.13,
      "grad_norm": 1.3543968200683594,
      "learning_rate": 5.400668432126166e-08,
      "loss": 0.8902,
      "step": 18350
    },
    {
      "epoch": 98.18,
      "grad_norm": 1.73911452293396,
      "learning_rate": 5.0965502308261e-08,
      "loss": 0.9233,
      "step": 18360
    },
    {
      "epoch": 98.24,
      "grad_norm": 0.9337003827095032,
      "learning_rate": 4.8012376017689265e-08,
      "loss": 0.8851,
      "step": 18370
    },
    {
      "epoch": 98.29,
      "grad_norm": 0.9965265989303589,
      "learning_rate": 4.51473137844105e-08,
      "loss": 0.904,
      "step": 18380
    },
    {
      "epoch": 98.34,
      "grad_norm": 1.1078124046325684,
      "learning_rate": 4.237032369473412e-08,
      "loss": 0.8675,
      "step": 18390
    },
    {
      "epoch": 98.4,
      "grad_norm": 1.2124102115631104,
      "learning_rate": 3.9681413586404455e-08,
      "loss": 0.8645,
      "step": 18400
    },
    {
      "epoch": 98.45,
      "grad_norm": 0.8829870223999023,
      "learning_rate": 3.7080591048555686e-08,
      "loss": 0.9555,
      "step": 18410
    },
    {
      "epoch": 98.5,
      "grad_norm": 0.9660593271255493,
      "learning_rate": 3.456786342172225e-08,
      "loss": 0.9675,
      "step": 18420
    },
    {
      "epoch": 98.56,
      "grad_norm": 0.7738850116729736,
      "learning_rate": 3.2143237797786774e-08,
      "loss": 0.8544,
      "step": 18430
    },
    {
      "epoch": 98.61,
      "grad_norm": 1.1837899684906006,
      "learning_rate": 2.980672101997664e-08,
      "loss": 0.9451,
      "step": 18440
    },
    {
      "epoch": 98.66,
      "grad_norm": 0.6461033225059509,
      "learning_rate": 2.755831968285008e-08,
      "loss": 0.82,
      "step": 18450
    },
    {
      "epoch": 98.72,
      "grad_norm": 0.7836885452270508,
      "learning_rate": 2.539804013226149e-08,
      "loss": 0.835,
      "step": 18460
    },
    {
      "epoch": 98.77,
      "grad_norm": 0.7971333265304565,
      "learning_rate": 2.3325888465351025e-08,
      "loss": 0.7629,
      "step": 18470
    },
    {
      "epoch": 98.82,
      "grad_norm": 1.208333969116211,
      "learning_rate": 2.1341870530534185e-08,
      "loss": 0.9172,
      "step": 18480
    },
    {
      "epoch": 98.88,
      "grad_norm": 0.989744246006012,
      "learning_rate": 1.9445991927477537e-08,
      "loss": 0.9473,
      "step": 18490
    },
    {
      "epoch": 98.93,
      "grad_norm": 1.2879090309143066,
      "learning_rate": 1.7638258007077885e-08,
      "loss": 0.913,
      "step": 18500
    },
    {
      "epoch": 98.98,
      "grad_norm": 1.023201584815979,
      "learning_rate": 1.5918673871458817e-08,
      "loss": 0.9419,
      "step": 18510
    },
    {
      "epoch": 99.0,
      "eval_accuracy": 0.3939393939393939,
      "eval_loss": 1.3987311124801636,
      "eval_runtime": 1.4951,
      "eval_samples_per_second": 22.072,
      "eval_steps_per_second": 2.007,
      "step": 18513
    },
    {
      "epoch": 99.04,
      "grad_norm": 0.9544779062271118,
      "learning_rate": 1.4287244373953346e-08,
      "loss": 0.8631,
      "step": 18520
    },
    {
      "epoch": 99.09,
      "grad_norm": 1.0484838485717773,
      "learning_rate": 1.2743974119086565e-08,
      "loss": 0.9689,
      "step": 18530
    },
    {
      "epoch": 99.14,
      "grad_norm": 1.1572762727737427,
      "learning_rate": 1.1288867462558305e-08,
      "loss": 0.9373,
      "step": 18540
    },
    {
      "epoch": 99.2,
      "grad_norm": 1.0356841087341309,
      "learning_rate": 9.921928511246597e-09,
      "loss": 0.9265,
      "step": 18550
    },
    {
      "epoch": 99.25,
      "grad_norm": 1.116532564163208,
      "learning_rate": 8.643161123176451e-09,
      "loss": 0.8529,
      "step": 18560
    },
    {
      "epoch": 99.3,
      "grad_norm": 1.2862356901168823,
      "learning_rate": 7.452568907526796e-09,
      "loss": 0.8649,
      "step": 18570
    },
    {
      "epoch": 99.36,
      "grad_norm": 1.0055506229400635,
      "learning_rate": 6.350155224606191e-09,
      "loss": 0.9507,
      "step": 18580
    },
    {
      "epoch": 99.41,
      "grad_norm": 1.3442039489746094,
      "learning_rate": 5.335923185852826e-09,
      "loss": 0.7917,
      "step": 18590
    },
    {
      "epoch": 99.47,
      "grad_norm": 1.1889632940292358,
      "learning_rate": 4.409875653820644e-09,
      "loss": 0.9568,
      "step": 18600
    },
    {
      "epoch": 99.52,
      "grad_norm": 0.8522132635116577,
      "learning_rate": 3.5720152421758743e-09,
      "loss": 0.8186,
      "step": 18610
    },
    {
      "epoch": 99.57,
      "grad_norm": 0.7270700931549072,
      "learning_rate": 2.8223443156796814e-09,
      "loss": 1.0618,
      "step": 18620
    },
    {
      "epoch": 99.63,
      "grad_norm": 0.9544993042945862,
      "learning_rate": 2.160864990195105e-09,
      "loss": 0.9759,
      "step": 18630
    },
    {
      "epoch": 99.68,
      "grad_norm": 1.4157334566116333,
      "learning_rate": 1.5875791326731837e-09,
      "loss": 0.8785,
      "step": 18640
    },
    {
      "epoch": 99.73,
      "grad_norm": 0.9280116558074951,
      "learning_rate": 1.1024883611460146e-09,
      "loss": 0.9025,
      "step": 18650
    },
    {
      "epoch": 99.79,
      "grad_norm": 0.7767950296401978,
      "learning_rate": 7.055940447267539e-10,
      "loss": 0.8843,
      "step": 18660
    },
    {
      "epoch": 99.84,
      "grad_norm": 1.1408352851867676,
      "learning_rate": 3.968973036061474e-10,
      "loss": 0.8712,
      "step": 18670
    },
    {
      "epoch": 99.89,
      "grad_norm": 1.6350613832473755,
      "learning_rate": 1.763990090490608e-10,
      "loss": 0.8833,
      "step": 18680
    },
    {
      "epoch": 99.95,
      "grad_norm": 1.1667468547821045,
      "learning_rate": 4.409978337713283e-11,
      "loss": 0.9353,
      "step": 18690
    },
    {
      "epoch": 100.0,
      "grad_norm": 1.8219096660614014,
      "learning_rate": 0.0,
      "loss": 0.8537,
      "step": 18700
    },
    {
      "epoch": 100.0,
      "eval_accuracy": 0.42424242424242425,
      "eval_loss": 1.4132897853851318,
      "eval_runtime": 1.1626,
      "eval_samples_per_second": 28.385,
      "eval_steps_per_second": 2.58,
      "step": 18700
    }
  ],
  "logging_steps": 10,
  "max_steps": 18700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "total_flos": 6.331928745577882e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
